{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datapreprocessor.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Optional, Tuple, Any\n",
    "import logging\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import PowerTransformer, OrdinalEncoder, OneHotEncoder, StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, SMOTENC, SMOTEN, BorderlineSMOTE\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import probplot\n",
    "import joblib  # For saving/loading transformers\n",
    "from inspect import signature  # For parameter validation in SMOTE\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_type: str,\n",
    "        y_variable: List[str],\n",
    "        ordinal_categoricals: List[str],\n",
    "        nominal_categoricals: List[str],\n",
    "        numericals: List[str],\n",
    "        mode: str,  # 'train', 'predict', 'clustering'\n",
    "        options: Optional[Dict] = None,\n",
    "        debug: bool = False,\n",
    "        normalize_debug: bool = False,\n",
    "        normalize_graphs_output: bool = False,\n",
    "        graphs_output_dir: str = './plots',\n",
    "        transformers_dir: str = './transformers'\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the DataPreprocessor with model type and feature lists.\n",
    "\n",
    "        Args:\n",
    "            model_type (str): Type of the machine learning model (e.g., 'Logistic Regression').\n",
    "            y_variable (List[str]): List of target variable(s).\n",
    "            ordinal_categoricals (List[str]): List of ordinal categorical features.\n",
    "            nominal_categoricals (List[str]): List of nominal categorical features.\n",
    "            numericals (List[str]): List of numerical features.\n",
    "            mode (str): Operational mode ('train', 'predict', 'clustering').\n",
    "            options (Optional[Dict]): User-defined options for preprocessing steps.\n",
    "            debug (bool): General debug flag to control overall verbosity.\n",
    "            normalize_debug (bool): Flag to display normalization plots.\n",
    "            normalize_graphs_output (bool): Flag to save normalization plots.\n",
    "            graphs_output_dir (str): Directory to save plots.\n",
    "            transformers_dir (str): Directory to save/load transformers.\n",
    "        \"\"\"\n",
    "        self.model_type = model_type\n",
    "        self.y_variable = y_variable\n",
    "        self.ordinal_categoricals = ordinal_categoricals\n",
    "        self.nominal_categoricals = nominal_categoricals\n",
    "        self.numericals = numericals\n",
    "        self.mode = mode.lower()\n",
    "        if self.mode not in ['train', 'predict', 'clustering']:\n",
    "            raise ValueError(\"Mode must be one of 'train', 'predict', or 'clustering'.\")\n",
    "        self.options = options or {}\n",
    "        self.debug = debug\n",
    "        self.normalize_debug = normalize_debug\n",
    "        self.normalize_graphs_output = normalize_graphs_output\n",
    "        self.graphs_output_dir = graphs_output_dir\n",
    "        self.transformers_dir = transformers_dir\n",
    "\n",
    "        # Initialize categorical_indices to prevent AttributeError\n",
    "        self.categorical_indices = []\n",
    "\n",
    "        # Define model categories for accurate processing\n",
    "        self.model_category = self.map_model_type_to_category()\n",
    "\n",
    "        if self.model_category == 'unknown':\n",
    "            self.logger = logging.getLogger(self.__class__.__name__)\n",
    "            self.logger.error(f\"Model category for '{self.model_type}' is unknown. Check your configuration.\")\n",
    "            raise ValueError(f\"Model category for '{self.model_type}' is unknown. Check your configuration.\")\n",
    "\n",
    "        # Initialize y_variable based on mode and model category\n",
    "        if self.mode in ['train', 'predict'] and self.model_category in ['classification', 'regression']:\n",
    "            if not self.y_variable:\n",
    "                if self.mode == 'train':\n",
    "                    raise ValueError(\"Target variable 'y_variable' must be specified for supervised models in train mode.\")\n",
    "                # In predict mode, y_variable might not be present\n",
    "        else:\n",
    "            # For 'clustering' mode or unsupervised prediction\n",
    "            self.y_variable = []\n",
    "\n",
    "        # Initialize other variables\n",
    "        self.scaler = None\n",
    "        self.transformer = None\n",
    "        self.ordinal_encoder = None\n",
    "        self.nominal_encoder = None\n",
    "        self.preprocessor = None\n",
    "        self.smote = None\n",
    "        self.feature_reasons = {col: '' for col in self.ordinal_categoricals + self.nominal_categoricals + self.numericals}\n",
    "        self.preprocessing_steps = []\n",
    "        self.normality_results = {}\n",
    "        self.features_to_transform = []\n",
    "        self.nominal_encoded_feature_names = []\n",
    "        self.final_feature_order = []\n",
    "\n",
    "        # Initialize placeholders for clustering-specific transformers\n",
    "        self.cluster_transformers = {}\n",
    "        self.cluster_model = None\n",
    "        self.cluster_labels = None\n",
    "        self.silhouette_score = None\n",
    "\n",
    "        # Define default thresholds for SMOTE recommendations\n",
    "        self.imbalance_threshold = self.options.get('smote_recommendation', {}).get('imbalance_threshold', 0.1)\n",
    "        self.noise_threshold = self.options.get('smote_recommendation', {}).get('noise_threshold', 0.1)\n",
    "        self.overlap_threshold = self.options.get('smote_recommendation', {}).get('overlap_threshold', 0.1)\n",
    "        self.boundary_threshold = self.options.get('smote_recommendation', {}).get('boundary_threshold', 0.1)\n",
    "\n",
    "        self.pipeline = None  # Initialize pipeline\n",
    "\n",
    "        # Initialize logging\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.logger.setLevel(logging.DEBUG if self.debug else logging.INFO)\n",
    "        handler = logging.StreamHandler()\n",
    "        formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        if not self.logger.handlers:\n",
    "            self.logger.addHandler(handler)\n",
    "            \n",
    "        # Initialize feature_reasons with 'all_numericals' for clustering\n",
    "        self.feature_reasons = {col: '' for col in self.ordinal_categoricals + self.nominal_categoricals + self.numericals}\n",
    "        if self.model_category == 'clustering':\n",
    "            self.feature_reasons['all_numericals'] = ''\n",
    "\n",
    "    def get_debug_flag(self, flag_name: str) -> bool:\n",
    "        \"\"\"\n",
    "        Retrieve the value of a specific debug flag from the options.\n",
    "        Args:\n",
    "            flag_name (str): The name of the debug flag.\n",
    "        Returns:\n",
    "            bool: The value of the debug flag.\n",
    "        \"\"\"\n",
    "        return self.options.get(flag_name, False)\n",
    "\n",
    "    def _log(self, message: str, step: str, level: str = 'info'):\n",
    "        \"\"\"\n",
    "        Internal method to log messages based on the step-specific debug flags.\n",
    "        \n",
    "        Args:\n",
    "            message (str): The message to log.\n",
    "            step (str): The preprocessing step name.\n",
    "            level (str): The logging level ('info', 'debug', etc.).\n",
    "        \"\"\"\n",
    "        debug_flag = self.get_debug_flag(f'debug_{step}')\n",
    "        if debug_flag:\n",
    "            if level == 'debug':\n",
    "                self.logger.debug(message)\n",
    "            elif level == 'info':\n",
    "                self.logger.info(message)\n",
    "            elif level == 'warning':\n",
    "                self.logger.warning(message)\n",
    "            elif level == 'error':\n",
    "                self.logger.error(message)\n",
    "\n",
    "    def map_model_type_to_category(self) -> str:\n",
    "        \"\"\"\n",
    "        Map the model_type string to a predefined category based on keywords.\n",
    "\n",
    "        Returns:\n",
    "            str: The model category ('classification', 'regression', 'clustering', etc.).\n",
    "        \"\"\"\n",
    "        classification_keywords = ['classifier', 'classification', 'logistic', 'svm', 'support vector machine', 'knn', 'neural network']\n",
    "        regression_keywords = ['regressor', 'regression', 'linear', 'knn', 'neural network']  # Removed 'svm'\n",
    "        clustering_keywords = ['k-means', 'clustering', 'dbscan', 'kmodes', 'kprototypes']\n",
    "\n",
    "        model_type_lower = self.model_type.lower()\n",
    "\n",
    "        for keyword in classification_keywords:\n",
    "            if keyword in model_type_lower:\n",
    "                return 'classification'\n",
    "\n",
    "        for keyword in regression_keywords:\n",
    "            if keyword in model_type_lower:\n",
    "                return 'regression'\n",
    "\n",
    "        for keyword in clustering_keywords:\n",
    "            if keyword in model_type_lower:\n",
    "                return 'clustering'\n",
    "\n",
    "        return 'unknown'\n",
    "\n",
    "    def filter_columns(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        step_name = \"filter_columns\"\n",
    "        self.logger.info(f\"Step: {step_name}\")\n",
    "\n",
    "        # Combine all feature lists\n",
    "        desired_features = self.numericals + self.ordinal_categoricals + self.nominal_categoricals\n",
    "\n",
    "        # For 'train' and 'clustering' modes, handle y_variable appropriately\n",
    "        if self.mode == 'train':\n",
    "            # Ensure y_variable is present in the data but not included in features\n",
    "            if not all(col in df.columns for col in self.y_variable):\n",
    "                missing_y = [col for col in self.y_variable if col not in df.columns]\n",
    "                self.logger.error(f\"Target variable(s) {missing_y} not found in the input data.\")\n",
    "                raise ValueError(f\"Target variable(s) {missing_y} not found in the input data.\")\n",
    "            # Exclude y_variable from features\n",
    "            desired_features = [col for col in desired_features if col not in self.y_variable]\n",
    "            # Retain y_variable in the filtered DataFrame\n",
    "            filtered_df = df[desired_features + self.y_variable].copy()\n",
    "        else:\n",
    "            # For 'predict' and 'clustering' modes, exclude y_variable\n",
    "            filtered_df = df[desired_features].copy()\n",
    "\n",
    "        # Identify missing features in the input DataFrame\n",
    "        missing_features = [col for col in desired_features if col not in df.columns]\n",
    "        if missing_features:\n",
    "            self.logger.error(f\"The following required features are missing in the input data: {missing_features}\")\n",
    "            raise ValueError(f\"The following required features are missing in the input data: {missing_features}\")\n",
    "\n",
    "        # Log the filtering action\n",
    "        self.logger.info(f\"✅ Filtered DataFrame to include only specified features. Shape: {filtered_df.shape}\")\n",
    "        self.logger.debug(f\"Selected Features: {desired_features}\")\n",
    "        if self.mode == 'train':\n",
    "            self.logger.debug(f\"Retained Target Variable(s): {self.y_variable}\")\n",
    "\n",
    "        return filtered_df\n",
    "\n",
    "    def split_dataset(\n",
    "        self,\n",
    "        X: pd.DataFrame,\n",
    "        y: Optional[pd.Series] = None\n",
    "    ) -> Tuple[pd.DataFrame, Optional[pd.DataFrame], Optional[pd.Series], Optional[pd.Series]]:\n",
    "        \"\"\"\n",
    "        Split the dataset into training and testing sets while retaining original indices.\n",
    "\n",
    "        Args:\n",
    "            X (pd.DataFrame): Features.\n",
    "            y (Optional[pd.Series]): Target variable.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[pd.DataFrame, Optional[pd.DataFrame], Optional[pd.Series], Optional[pd.Series]]: X_train, X_test, y_train, y_test\n",
    "        \"\"\"\n",
    "        step_name = \"split_dataset\"\n",
    "        self.logger.info(\"Step: Split Dataset into Train and Test\")\n",
    "\n",
    "        # Debugging Statements\n",
    "        self._log(f\"Before Split - X shape: {X.shape}\", step_name, 'debug')\n",
    "        if y is not None:\n",
    "            self._log(f\"Before Split - y shape: {y.shape}\", step_name, 'debug')\n",
    "        else:\n",
    "            self._log(\"Before Split - y is None\", step_name, 'debug')\n",
    "\n",
    "        # Determine splitting based on mode\n",
    "        if self.mode == 'train' and self.model_category in ['classification', 'regression']:\n",
    "            if self.model_category == 'classification':\n",
    "                stratify = y if self.options.get('split_dataset', {}).get('stratify_for_classification', False) else None\n",
    "                test_size = self.options.get('split_dataset', {}).get('test_size', 0.2)\n",
    "                random_state = self.options.get('split_dataset', {}).get('random_state', 42)\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    X, y, \n",
    "                    test_size=test_size,\n",
    "                    stratify=stratify, \n",
    "                    random_state=random_state\n",
    "                )\n",
    "                self._log(\"Performed stratified split for classification.\", step_name, 'debug')\n",
    "            elif self.model_category == 'regression':\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    X, y, \n",
    "                    test_size=self.options.get('split_dataset', {}).get('test_size', 0.2),\n",
    "                    random_state=self.options.get('split_dataset', {}).get('random_state', 42)\n",
    "                )\n",
    "                self._log(\"Performed random split for regression.\", step_name, 'debug')\n",
    "        else:\n",
    "            # For 'predict' and 'clustering' modes or other categories\n",
    "            X_train = X.copy()\n",
    "            X_test = None\n",
    "            y_train = y.copy() if y is not None else None\n",
    "            y_test = None\n",
    "            self.logger.info(f\"No splitting performed for mode '{self.mode}' or model category '{self.model_category}'.\")\n",
    "\n",
    "        self.preprocessing_steps.append(\"Split Dataset into Train and Test\")\n",
    "\n",
    "        # Keep Indices Aligned Through Each Step\n",
    "        if X_test is not None and y_test is not None:\n",
    "            # Sort both X_test and y_test by index\n",
    "            X_test = X_test.sort_index()\n",
    "            y_test = y_test.sort_index()\n",
    "            self.logger.debug(\"Sorted X_test and y_test by index for alignment.\")\n",
    "\n",
    "        # Debugging: Log post-split shapes and index alignment\n",
    "        self._log(f\"After Split - X_train shape: {X_train.shape}, X_test shape: {X_test.shape if X_test is not None else 'N/A'}\", step_name, 'debug')\n",
    "        if self.model_category == 'classification' and y_train is not None and y_test is not None:\n",
    "            self.logger.debug(f\"Class distribution in y_train:\\n{y_train.value_counts(normalize=True)}\")\n",
    "            self.logger.debug(f\"Class distribution in y_test:\\n{y_test.value_counts(normalize=True)}\")\n",
    "        elif self.model_category == 'regression' and y_train is not None and y_test is not None:\n",
    "            self.logger.debug(f\"y_train statistics:\\n{y_train.describe()}\")\n",
    "            self.logger.debug(f\"y_test statistics:\\n{y_test.describe()}\")\n",
    "\n",
    "        # Check index alignment\n",
    "        if y_train is not None and X_train.index.equals(y_train.index):\n",
    "            self.logger.debug(\"X_train and y_train indices are aligned.\")\n",
    "        else:\n",
    "            self.logger.warning(\"X_train and y_train indices are misaligned.\")\n",
    "\n",
    "        if X_test is not None and y_test is not None and X_test.index.equals(y_test.index):\n",
    "            self.logger.debug(\"X_test and y_test indices are aligned.\")\n",
    "        elif X_test is not None and y_test is not None:\n",
    "            self.logger.warning(\"X_test and y_test indices are misaligned.\")\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def handle_missing_values(self, X_train: pd.DataFrame, X_test: Optional[pd.DataFrame] = None) -> Tuple[pd.DataFrame, Optional[pd.DataFrame]]:\n",
    "        \"\"\"\n",
    "        Handle missing values for numerical and categorical features based on user options.\n",
    "        \"\"\"\n",
    "        step_name = \"handle_missing_values\"\n",
    "        self.logger.info(\"Step: Handle Missing Values\")\n",
    "\n",
    "        # Fetch user-defined imputation options or set defaults\n",
    "        impute_options = self.options.get('handle_missing_values', {})\n",
    "        numerical_strategy = impute_options.get('numerical_strategy', {})\n",
    "        categorical_strategy = impute_options.get('categorical_strategy', {})\n",
    "\n",
    "        # Numerical Imputation\n",
    "        numerical_imputer = None\n",
    "        new_columns = []\n",
    "        if self.numericals:\n",
    "            if self.model_category in ['regression', 'classification', 'clustering']:\n",
    "                default_num_strategy = 'median'  # Changed to median as per preprocessor_config.yaml\n",
    "            else:\n",
    "                default_num_strategy = 'median'\n",
    "            num_strategy = numerical_strategy.get('strategy', default_num_strategy)\n",
    "            num_imputer_type = numerical_strategy.get('imputer', 'SimpleImputer')  # Can be 'SimpleImputer', 'KNNImputer', etc.\n",
    "\n",
    "            self._log(f\"Numerical Imputation Strategy: {num_strategy.capitalize()}, Imputer Type: {num_imputer_type}\", step_name, 'debug')\n",
    "\n",
    "            # Initialize numerical imputer based on user option\n",
    "            if num_imputer_type == 'SimpleImputer':\n",
    "                numerical_imputer = SimpleImputer(strategy=num_strategy)\n",
    "            elif num_imputer_type == 'KNNImputer':\n",
    "                knn_neighbors = numerical_strategy.get('knn_neighbors', 5)\n",
    "                numerical_imputer = KNNImputer(n_neighbors=knn_neighbors)\n",
    "            else:\n",
    "                self.logger.error(f\"Numerical imputer type '{num_imputer_type}' is not supported.\")\n",
    "                raise ValueError(f\"Numerical imputer type '{num_imputer_type}' is not supported.\")\n",
    "\n",
    "            # Fit and transform ONLY on X_train\n",
    "            X_train[self.numericals] = numerical_imputer.fit_transform(X_train[self.numericals])\n",
    "            self.numerical_imputer = numerical_imputer  # Assign to self for saving\n",
    "            self.feature_reasons.update({col: self.feature_reasons.get(col, '') + f'Numerical: {num_strategy.capitalize()} Imputation | ' for col in self.numericals})\n",
    "            new_columns.extend(self.numericals)\n",
    "\n",
    "            if X_test is not None:\n",
    "                # Transform ONLY on X_test without fitting\n",
    "                X_test[self.numericals] = numerical_imputer.transform(X_test[self.numericals])\n",
    "\n",
    "        # Categorical Imputation\n",
    "        categorical_imputer = None\n",
    "        all_categoricals = self.ordinal_categoricals + self.nominal_categoricals\n",
    "        if all_categoricals:\n",
    "            default_cat_strategy = 'most_frequent'\n",
    "            cat_strategy = categorical_strategy.get('strategy', default_cat_strategy)\n",
    "            cat_imputer_type = categorical_strategy.get('imputer', 'SimpleImputer')\n",
    "\n",
    "            self._log(f\"Categorical Imputation Strategy: {cat_strategy.capitalize()}, Imputer Type: {cat_imputer_type}\", step_name, 'debug')\n",
    "\n",
    "            # Initialize categorical imputer based on user option\n",
    "            if cat_imputer_type == 'SimpleImputer':\n",
    "                categorical_imputer = SimpleImputer(strategy=cat_strategy)\n",
    "            elif cat_imputer_type == 'ConstantImputer':\n",
    "                fill_value = categorical_strategy.get('fill_value', 'Missing')\n",
    "                categorical_imputer = SimpleImputer(strategy='constant', fill_value=fill_value)\n",
    "            else:\n",
    "                self.logger.error(f\"Categorical imputer type '{cat_imputer_type}' is not supported.\")\n",
    "                raise ValueError(f\"Categorical imputer type '{cat_imputer_type}' is not supported.\")\n",
    "\n",
    "            # Fit and transform ONLY on X_train\n",
    "            X_train[all_categoricals] = categorical_imputer.fit_transform(X_train[all_categoricals])\n",
    "            self.categorical_imputer = categorical_imputer  # Assign to self for saving\n",
    "            self.feature_reasons.update({\n",
    "                col: self.feature_reasons.get(col, '') + (f'Categorical: Constant Imputation (Value={categorical_strategy.get(\"fill_value\", \"Missing\")}) | ' if cat_imputer_type == 'ConstantImputer' else f'Categorical: {cat_strategy.capitalize()} Imputation | ')\n",
    "                for col in all_categoricals\n",
    "            })\n",
    "            new_columns.extend(all_categoricals)\n",
    "\n",
    "            if X_test is not None:\n",
    "                # Transform ONLY on X_test without fitting\n",
    "                X_test[all_categoricals] = categorical_imputer.transform(X_test[all_categoricals])\n",
    "\n",
    "        self.preprocessing_steps.append(\"Handle Missing Values\")\n",
    "\n",
    "        # Debugging: Log post-imputation shapes and missing values\n",
    "        self._log(f\"Completed: Handle Missing Values. Dataset shape after imputation: {X_train.shape}\", step_name, 'debug')\n",
    "        self._log(f\"Missing values after imputation in X_train:\\n{X_train.isnull().sum()}\", step_name, 'debug')\n",
    "        self._log(f\"New columns handled: {new_columns}\", step_name, 'debug')\n",
    "\n",
    "        return X_train, X_test\n",
    "\n",
    "    def handle_outliers(self, X_train: pd.DataFrame, y_train: Optional[pd.Series] = None) -> Tuple[pd.DataFrame, Optional[pd.Series]]:\n",
    "        \"\"\"\n",
    "        Handle outliers based on the model's sensitivity and user options.\n",
    "\n",
    "        Args:\n",
    "            X_train (pd.DataFrame): Training features.\n",
    "            y_train (pd.Series, optional): Training target.\n",
    "\n",
    "        Returns:\n",
    "            tuple: X_train without outliers and corresponding y_train.\n",
    "        \"\"\"\n",
    "        step_name = \"handle_outliers\"\n",
    "        self.logger.info(\"Step: Handle Outliers\")\n",
    "        self._log(\"Starting outlier handling.\", step_name, 'debug')\n",
    "\n",
    "        debug_flag = self.get_debug_flag('debug_handle_outliers')\n",
    "        initial_shape = X_train.shape[0]\n",
    "\n",
    "        # Fetch user-defined outlier handling options or set defaults\n",
    "        outlier_options = self.options.get('handle_outliers', {})\n",
    "        zscore_threshold = outlier_options.get('zscore_threshold', 3)\n",
    "        iqr_multiplier = outlier_options.get('iqr_multiplier', 1.5)\n",
    "        isolation_contamination = outlier_options.get('isolation_contamination', 0.05)\n",
    "\n",
    "        if self.model_category in ['regression', 'classification']:\n",
    "            self.logger.info(f\"Applying univariate outlier detection for {self.model_category}.\")\n",
    "            for col in self.numericals:\n",
    "                # Z-Score Filtering\n",
    "                apply_zscore = outlier_options.get('apply_zscore', True)\n",
    "                if apply_zscore:\n",
    "                    z_scores = np.abs((X_train[col] - X_train[col].mean()) / X_train[col].std())\n",
    "                    mask_z = z_scores < zscore_threshold\n",
    "                    removed_z = (~mask_z).sum()\n",
    "                    X_train = X_train[mask_z]\n",
    "                    if y_train is not None:\n",
    "                        y_train = y_train.loc[X_train.index]\n",
    "                    self.feature_reasons[col] += f'Outliers handled with Z-Score Filtering (threshold={zscore_threshold}) | '\n",
    "                    self._log(f\"Removed {removed_z} outliers from '{col}' using Z-Score Filtering.\", step_name, 'debug')\n",
    "\n",
    "                # IQR Filtering\n",
    "                apply_iqr = outlier_options.get('apply_iqr', True)\n",
    "                if apply_iqr:\n",
    "                    Q1 = X_train[col].quantile(0.25)\n",
    "                    Q3 = X_train[col].quantile(0.75)\n",
    "                    IQR = Q3 - Q1\n",
    "                    lower_bound = Q1 - iqr_multiplier * IQR\n",
    "                    upper_bound = Q3 + iqr_multiplier * IQR\n",
    "                    mask_iqr = (X_train[col] >= lower_bound) & (X_train[col] <= upper_bound)\n",
    "                    removed_iqr = (~mask_iqr).sum()\n",
    "                    X_train = X_train[mask_iqr]\n",
    "                    if y_train is not None:\n",
    "                        y_train = y_train.loc[X_train.index]\n",
    "                    self.feature_reasons[col] += f'Outliers handled with IQR Filtering (multiplier={iqr_multiplier}) | '\n",
    "                    self._log(f\"Removed {removed_iqr} outliers from '{col}' using IQR Filtering.\", step_name, 'debug')\n",
    "\n",
    "        elif self.model_category == 'clustering':\n",
    "            self.logger.info(\"Applying multivariate IsolationForest for clustering.\")\n",
    "            # Apply IsolationForest on all numerical features simultaneously\n",
    "            contamination = isolation_contamination\n",
    "            iso_forest = IsolationForest(contamination=contamination, random_state=42)\n",
    "            preds = iso_forest.fit_predict(X_train[self.numericals])\n",
    "            mask_iso = preds != -1\n",
    "            removed_iso = (preds == -1).sum()\n",
    "            X_train = X_train[mask_iso]\n",
    "            if y_train is not None:\n",
    "                y_train = y_train.loc[X_train.index]  # Should typically be None in clustering\n",
    "            self.feature_reasons['all_numericals'] += f'Outliers handled with Multivariate IsolationForest (contamination={contamination}) | '\n",
    "            self._log(f\"Removed {removed_iso} outliers using Multivariate IsolationForest.\", step_name, 'debug')\n",
    "\n",
    "        else:\n",
    "            self.logger.warning(f\"Model category '{self.model_category}' not recognized for outlier handling.\")\n",
    "\n",
    "        self.preprocessing_steps.append(\"Handle Outliers\")\n",
    "\n",
    "        # Completion Logging\n",
    "        self._log(f\"Completed: Handle Outliers. Initial samples: {initial_shape}, Final samples: {X_train.shape[0]}\", step_name, 'debug')\n",
    "        self._log(f\"Missing values after outlier handling in X_train:\\n{X_train.isnull().sum()}\", step_name, 'debug')\n",
    "\n",
    "        return X_train, y_train\n",
    "\n",
    "    def test_normality(self, X_train: pd.DataFrame) -> Dict[str, Dict]:\n",
    "        \"\"\"\n",
    "        Test normality for numerical features based on normality tests and user options.\n",
    "\n",
    "        Args:\n",
    "            X_train (pd.DataFrame): Training features.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, Dict]: Dictionary with normality test results for each numerical feature.\n",
    "        \"\"\"\n",
    "        step_name = \"Test for Normality\"\n",
    "        self.logger.info(f\"Step: {step_name}\")\n",
    "        debug_flag = self.get_debug_flag('debug_test_normality')\n",
    "        normality_results = {}\n",
    "\n",
    "        # Fetch user-defined normality test options or set defaults\n",
    "        normality_options = self.options.get('test_normality', {})\n",
    "        p_value_threshold = normality_options.get('p_value_threshold', 0.05)\n",
    "        skewness_threshold = normality_options.get('skewness_threshold', 1.0)\n",
    "        additional_tests = normality_options.get('additional_tests', [])  # e.g., ['anderson-darling']\n",
    "\n",
    "        for col in self.numericals:\n",
    "            data = X_train[col].dropna()\n",
    "            skewness = data.skew()\n",
    "            kurtosis = data.kurtosis()\n",
    "\n",
    "            # Determine which normality test to use based on sample size and user options\n",
    "            test_used = 'Shapiro-Wilk'\n",
    "            p_value = 0.0\n",
    "\n",
    "            if len(data) <= 5000:\n",
    "                from scipy.stats import shapiro\n",
    "                stat, p_val = shapiro(data)\n",
    "                test_used = 'Shapiro-Wilk'\n",
    "                p_value = p_val\n",
    "            else:\n",
    "                from scipy.stats import anderson\n",
    "                result = anderson(data)\n",
    "                test_used = 'Anderson-Darling'\n",
    "                # Determine p-value based on critical values\n",
    "                p_value = 0.0  # Default to 0\n",
    "                for cv, sig in zip(result.critical_values, result.significance_level):\n",
    "                    if result.statistic < cv:\n",
    "                        p_value = sig / 100\n",
    "                        break\n",
    "\n",
    "            # Apply user-defined or default criteria\n",
    "            if self.model_category in ['regression', 'classification', 'clustering']:\n",
    "                # Linear, Logistic Regression, and Clustering: Use p-value and skewness\n",
    "                needs_transform = (p_value < p_value_threshold) or (abs(skewness) > skewness_threshold)\n",
    "            else:\n",
    "                # Other models: Use skewness, and optionally p-values based on options\n",
    "                use_p_value = normality_options.get('use_p_value_other_models', False)\n",
    "                if use_p_value:\n",
    "                    needs_transform = (p_value < p_value_threshold) or (abs(skewness) > skewness_threshold)\n",
    "                else:\n",
    "                    needs_transform = abs(skewness) > skewness_threshold\n",
    "\n",
    "            normality_results[col] = {\n",
    "                'skewness': skewness,\n",
    "                'kurtosis': kurtosis,\n",
    "                'p_value': p_value,\n",
    "                'test_used': test_used,\n",
    "                'needs_transform': needs_transform\n",
    "            }\n",
    "\n",
    "            # Conditional Detailed Logging\n",
    "            if debug_flag:\n",
    "                self._log(f\"Feature '{col}': p-value={p_value:.4f}, skewness={skewness:.4f}, needs_transform={needs_transform}\", step_name, 'debug')\n",
    "\n",
    "        self.normality_results = normality_results\n",
    "        self.preprocessing_steps.append(step_name)\n",
    "\n",
    "        # Completion Logging\n",
    "        if debug_flag:\n",
    "            self._log(f\"Completed: {step_name}. Normality results computed.\", step_name, 'debug')\n",
    "        else:\n",
    "            self.logger.info(f\"Step '{step_name}' completed: Normality results computed.\")\n",
    "\n",
    "        return normality_results\n",
    "\n",
    "    def encode_categorical_variables(self, X_train: pd.DataFrame, X_test: Optional[pd.DataFrame] = None) -> Tuple[pd.DataFrame, Optional[pd.DataFrame]]:\n",
    "        \"\"\"\n",
    "        Encode categorical variables using user-specified encoding strategies.\n",
    "        \"\"\"\n",
    "        step_name = \"encode_categorical_variables\"\n",
    "        self.logger.info(\"Step: Encode Categorical Variables\")\n",
    "        self._log(\"Starting categorical variable encoding.\", step_name, 'debug')\n",
    "\n",
    "        # Fetch user-defined encoding options or set defaults\n",
    "        encoding_options = self.options.get('encode_categoricals', {})\n",
    "        ordinal_encoding = encoding_options.get('ordinal_encoding', 'OrdinalEncoder')  # Options: 'OrdinalEncoder', 'None'\n",
    "        nominal_encoding = encoding_options.get('nominal_encoding', 'OneHotEncoder')  # Changed from 'OneHotEncoder' to 'OrdinalEncoder'\n",
    "        handle_unknown = encoding_options.get('handle_unknown', 'use_encoded_value')  # Adjusted for OrdinalEncoder\n",
    "\n",
    "        # Determine if SMOTENC is being used\n",
    "        smote_variant = self.options.get('implement_smote', {}).get('variant', None)\n",
    "        if smote_variant == 'SMOTENC':\n",
    "            nominal_encoding = 'OrdinalEncoder'  # Ensure compatibility\n",
    "\n",
    "        transformers = []\n",
    "        new_columns = []\n",
    "        if self.ordinal_categoricals and ordinal_encoding != 'None':\n",
    "            if ordinal_encoding == 'OrdinalEncoder':\n",
    "                transformers.append(\n",
    "                    ('ordinal', OrdinalEncoder(), self.ordinal_categoricals)\n",
    "                )\n",
    "                self._log(f\"Added OrdinalEncoder for features: {self.ordinal_categoricals}\", step_name, 'debug')\n",
    "            else:\n",
    "                self.logger.error(f\"Ordinal encoding method '{ordinal_encoding}' is not supported.\")\n",
    "                raise ValueError(f\"Ordinal encoding method '{ordinal_encoding}' is not supported.\")\n",
    "        if self.nominal_categoricals and nominal_encoding != 'None':\n",
    "            if nominal_encoding == 'OrdinalEncoder':\n",
    "                transformers.append(\n",
    "                    ('nominal', OrdinalEncoder(handle_unknown=handle_unknown), self.nominal_categoricals)\n",
    "                )\n",
    "                self._log(f\"Added OrdinalEncoder for features: {self.nominal_categoricals}\", step_name, 'debug')\n",
    "            elif nominal_encoding == 'FrequencyEncoder':\n",
    "                # Custom Frequency Encoding\n",
    "                for col in self.nominal_categoricals:\n",
    "                    freq = X_train[col].value_counts(normalize=True)\n",
    "                    X_train[col] = X_train[col].map(freq)\n",
    "                    if X_test is not None:\n",
    "                        X_test[col] = X_test[col].map(freq).fillna(0)\n",
    "                    self.feature_reasons[col] += 'Encoded with Frequency Encoding | '\n",
    "                    self._log(f\"Applied Frequency Encoding to '{col}'.\", step_name, 'debug')\n",
    "            else:\n",
    "                self.logger.error(f\"Nominal encoding method '{nominal_encoding}' is not supported.\")\n",
    "                raise ValueError(f\"Nominal encoding method '{nominal_encoding}' is not supported.\")\n",
    "\n",
    "        if not transformers and 'FrequencyEncoder' not in nominal_encoding:\n",
    "            self.logger.info(\"No categorical variables to encode.\")\n",
    "            self.preprocessing_steps.append(\"Encode Categorical Variables\")\n",
    "            self._log(f\"Completed: Encode Categorical Variables. No encoding was applied.\", step_name, 'debug')\n",
    "            return X_train, X_test\n",
    "\n",
    "        if transformers:\n",
    "            self.preprocessor = ColumnTransformer(\n",
    "                transformers=transformers,\n",
    "                remainder='passthrough',\n",
    "                verbose_feature_names_out=False  # Disable prefixing\n",
    "            )\n",
    "\n",
    "            # Fit and transform training data\n",
    "            X_train_encoded = self.preprocessor.fit_transform(X_train)\n",
    "            self._log(\"Fitted and transformed X_train with ColumnTransformer.\", step_name, 'debug')\n",
    "\n",
    "            # Transform testing data\n",
    "            if X_test is not None:\n",
    "                X_test_encoded = self.preprocessor.transform(X_test)\n",
    "                self._log(\"Transformed X_test with fitted ColumnTransformer.\", step_name, 'debug')\n",
    "            else:\n",
    "                X_test_encoded = None\n",
    "\n",
    "            # Retrieve feature names after encoding\n",
    "            encoded_feature_names = []\n",
    "            if self.ordinal_categoricals and ordinal_encoding == 'OrdinalEncoder':\n",
    "                encoded_feature_names += self.ordinal_categoricals\n",
    "            if self.nominal_categoricals and nominal_encoding == 'OrdinalEncoder':\n",
    "                encoded_feature_names += self.nominal_categoricals\n",
    "            elif self.nominal_categoricals and nominal_encoding == 'FrequencyEncoder':\n",
    "                encoded_feature_names += self.nominal_categoricals\n",
    "            passthrough_features = [col for col in X_train.columns if col not in self.ordinal_categoricals + self.nominal_categoricals]\n",
    "            encoded_feature_names += passthrough_features\n",
    "            new_columns.extend(encoded_feature_names)\n",
    "\n",
    "            # Convert numpy arrays back to DataFrames\n",
    "            X_train_encoded_df = pd.DataFrame(X_train_encoded, columns=encoded_feature_names, index=X_train.index)\n",
    "            if X_test_encoded is not None:\n",
    "                X_test_encoded_df = pd.DataFrame(X_test_encoded, columns=encoded_feature_names, index=X_test.index)\n",
    "            else:\n",
    "                X_test_encoded_df = None\n",
    "\n",
    "            # Store encoders for inverse transformation\n",
    "            self.ordinal_encoder = self.preprocessor.named_transformers_.get('ordinal', None)\n",
    "            self.nominal_encoder = self.preprocessor.named_transformers_.get('nominal', None)\n",
    "\n",
    "            self.preprocessing_steps.append(\"Encode Categorical Variables\")\n",
    "            self._log(f\"Completed: Encode Categorical Variables. X_train_encoded shape: {X_train_encoded_df.shape}\", step_name, 'debug')\n",
    "            self._log(f\"Columns after encoding: {encoded_feature_names}\", step_name, 'debug')\n",
    "            self._log(f\"Sample of encoded X_train:\\n{X_train_encoded_df.head()}\", step_name, 'debug')\n",
    "            self._log(f\"New columns added: {new_columns}\", step_name, 'debug')\n",
    "\n",
    "            return X_train_encoded_df, X_test_encoded_df\n",
    "\n",
    "    def generate_recommendations(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Generate a table of preprocessing recommendations based on the model type, data, and user options.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing recommendations for each feature.\n",
    "        \"\"\"\n",
    "        step_name = \"Generate Preprocessor Recommendations\"\n",
    "        self.logger.info(f\"Step: {step_name}\")\n",
    "        debug_flag = self.get_debug_flag('debug_generate_recommendations')\n",
    "\n",
    "        # Generate recommendations based on feature reasons\n",
    "        recommendations = {}\n",
    "        for col in self.ordinal_categoricals + self.nominal_categoricals + self.numericals:\n",
    "            reasons = self.feature_reasons.get(col, '').strip(' | ')\n",
    "            recommendations[col] = reasons\n",
    "\n",
    "        recommendations_table = pd.DataFrame.from_dict(\n",
    "            recommendations, \n",
    "            orient='index', \n",
    "            columns=['Preprocessing Reason']\n",
    "        )\n",
    "        if debug_flag:\n",
    "            self.logger.debug(f\"Preprocessing Recommendations:\\n{recommendations_table}\")\n",
    "        else:\n",
    "            self.logger.info(\"Preprocessing Recommendations generated.\")\n",
    "\n",
    "        self.preprocessing_steps.append(step_name)\n",
    "\n",
    "        # Completion Logging\n",
    "        if debug_flag:\n",
    "            self._log(f\"Completed: {step_name}. Recommendations generated.\", step_name, 'debug')\n",
    "        else:\n",
    "            self.logger.info(f\"Step '{step_name}' completed: Recommendations generated.\")\n",
    "\n",
    "        return recommendations_table\n",
    "\n",
    "    def save_transformers(self):\n",
    "        step_name = \"Save Transformers\"\n",
    "        self.logger.info(f\"Step: {step_name}\")\n",
    "        debug_flag = self.get_debug_flag('debug_save_transformers')\n",
    "        \n",
    "        # Ensure the transformers directory exists\n",
    "        os.makedirs(self.transformers_dir, exist_ok=True)\n",
    "        transformers_path = os.path.join(self.transformers_dir, 'transformers.pkl')  # Consistent file path\n",
    "        \n",
    "        transformers = {\n",
    "            'numerical_imputer': getattr(self, 'numerical_imputer', None),\n",
    "            'categorical_imputer': getattr(self, 'categorical_imputer', None),\n",
    "            'preprocessor': self.pipeline,   # Includes all preprocessing steps\n",
    "            'smote': self.smote,\n",
    "            'final_feature_order': self.final_feature_order,\n",
    "            'categorical_indices': self.categorical_indices\n",
    "        }\n",
    "        try:\n",
    "            joblib.dump(transformers, transformers_path)\n",
    "            if debug_flag:\n",
    "                self._log(f\"Transformers saved at '{transformers_path}'.\", step_name, 'debug')\n",
    "            else:\n",
    "                self.logger.info(f\"Transformers saved at '{transformers_path}'.\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"❌ Failed to save transformers: {e}\")\n",
    "            raise\n",
    "\n",
    "        self.preprocessing_steps.append(step_name)\n",
    "\n",
    "    def load_transformers(self) -> dict:\n",
    "        step_name = \"Load Transformers\"\n",
    "        self.logger.info(f\"Step: {step_name}\")\n",
    "        debug_flag = self.get_debug_flag('debug_load_transformers')  # Assuming a step-specific debug flag\n",
    "        transformers_path = os.path.join(self.transformers_dir, 'transformers.pkl')  # Correct path\n",
    "\n",
    "        # Debug log\n",
    "        self.logger.debug(f\"Loading transformers from: {transformers_path}\")\n",
    "\n",
    "        if not os.path.exists(transformers_path):\n",
    "            self.logger.error(f\"❌ Transformers file not found at '{transformers_path}'. Cannot proceed with prediction.\")\n",
    "            raise FileNotFoundError(f\"Transformers file not found at '{transformers_path}'.\")\n",
    "\n",
    "        try:\n",
    "            transformers = joblib.load(transformers_path)\n",
    "\n",
    "            # Extract transformers\n",
    "            numerical_imputer = transformers.get('numerical_imputer')\n",
    "            categorical_imputer = transformers.get('categorical_imputer')\n",
    "            preprocessor = transformers.get('preprocessor')\n",
    "            smote = transformers.get('smote', None)\n",
    "            final_feature_order = transformers.get('final_feature_order', [])\n",
    "            categorical_indices = transformers.get('categorical_indices', [])\n",
    "            self.categorical_indices = categorical_indices  # Set the attribute\n",
    "\n",
    "            # **Post-Loading Debugging:**\n",
    "            if preprocessor is not None:\n",
    "                try:\n",
    "                    # Do not attempt to transform dummy data here\n",
    "                    self.logger.debug(f\"Pipeline loaded. Ready to transform new data.\")\n",
    "                except AttributeError as e:\n",
    "                    self.logger.error(f\"Pipeline's get_feature_names_out is not available: {e}\")\n",
    "                    expected_features = []\n",
    "            else:\n",
    "                self.logger.error(\"❌ Preprocessor is not loaded.\")\n",
    "                raise AttributeError(\"Preprocessor is not loaded.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"❌ Failed to load transformers: {e}\")\n",
    "            raise\n",
    "\n",
    "        self.preprocessing_steps.append(step_name)\n",
    "\n",
    "        # Additional checks\n",
    "        if preprocessor is None:\n",
    "            self.logger.error(\"❌ Preprocessor is not loaded.\")\n",
    "\n",
    "        if debug_flag:\n",
    "            self._log(f\"Transformers loaded successfully from '{transformers_path}'.\", step_name, 'debug')\n",
    "        else:\n",
    "            self.logger.info(f\"Transformers loaded successfully from '{transformers_path}'.\")\n",
    "\n",
    "        # Set the pipeline\n",
    "        self.pipeline = preprocessor\n",
    "\n",
    "        # Return the transformers as a dictionary\n",
    "        return {\n",
    "            'numerical_imputer': numerical_imputer,\n",
    "            'categorical_imputer': categorical_imputer,\n",
    "            'preprocessor': preprocessor,\n",
    "            'smote': smote,\n",
    "            'final_feature_order': final_feature_order,\n",
    "            'categorical_indices': categorical_indices\n",
    "        }\n",
    "\n",
    "    def apply_scaling(self, X_train: pd.DataFrame, X_test: Optional[pd.DataFrame] = None) -> Tuple[pd.DataFrame, Optional[pd.DataFrame]]:\n",
    "        \"\"\"\n",
    "        Apply scaling based on the model type and user options.\n",
    "\n",
    "        Args:\n",
    "            X_train (pd.DataFrame): Training features.\n",
    "            X_test (Optional[pd.DataFrame]): Testing features.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[pd.DataFrame, Optional[pd.DataFrame]]: Scaled X_train and X_test.\n",
    "        \"\"\"\n",
    "        step_name = \"Apply Scaling (If Needed by Model)\"\n",
    "        self.logger.info(f\"Step: {step_name}\")\n",
    "        debug_flag = self.get_debug_flag('debug_apply_scaling')\n",
    "\n",
    "        # Fetch user-defined scaling options or set defaults\n",
    "        scaling_options = self.options.get('apply_scaling', {})\n",
    "        scaling_method = scaling_options.get('method', None)  # 'StandardScaler', 'MinMaxScaler', 'RobustScaler', 'None'\n",
    "        features_to_scale = scaling_options.get('features', self.numericals)\n",
    "\n",
    "        scaler = None\n",
    "        scaling_type = 'None'\n",
    "\n",
    "        if scaling_method is None:\n",
    "            # Default scaling based on model category\n",
    "            if self.model_category in ['regression', 'classification', 'clustering']:\n",
    "                # For clustering, MinMaxScaler is generally preferred\n",
    "                if self.model_category == 'clustering':\n",
    "                    scaler = MinMaxScaler()\n",
    "                    scaling_type = 'MinMaxScaler'\n",
    "                else:\n",
    "                    scaler = StandardScaler()\n",
    "                    scaling_type = 'StandardScaler'\n",
    "            else:\n",
    "                scaler = None\n",
    "                scaling_type = 'None'\n",
    "        else:\n",
    "            # Normalize the scaling_method string to handle case-insensitivity\n",
    "            scaling_method_normalized = scaling_method.lower()\n",
    "            if scaling_method_normalized == 'standardscaler':\n",
    "                scaler = StandardScaler()\n",
    "                scaling_type = 'StandardScaler'\n",
    "            elif scaling_method_normalized == 'minmaxscaler':\n",
    "                scaler = MinMaxScaler()\n",
    "                scaling_type = 'MinMaxScaler'\n",
    "            elif scaling_method_normalized == 'robustscaler':\n",
    "                scaler = RobustScaler()\n",
    "                scaling_type = 'RobustScaler'\n",
    "            elif scaling_method_normalized == 'none':\n",
    "                scaler = None\n",
    "                scaling_type = 'None'\n",
    "            else:\n",
    "                self.logger.error(f\"Scaling method '{scaling_method}' is not supported.\")\n",
    "                raise ValueError(f\"Scaling method '{scaling_method}' is not supported.\")\n",
    "\n",
    "        # Apply scaling if scaler is defined\n",
    "        if scaler is not None and features_to_scale:\n",
    "            self.scaler = scaler\n",
    "            if debug_flag:\n",
    "                self._log(f\"Features to scale: {features_to_scale}\", step_name, 'debug')\n",
    "\n",
    "            # Check if features exist in the dataset\n",
    "            missing_features = [feat for feat in features_to_scale if feat not in X_train.columns]\n",
    "            if missing_features:\n",
    "                self.logger.error(f\"The following features specified for scaling are missing in the dataset: {missing_features}\")\n",
    "                raise KeyError(f\"The following features specified for scaling are missing in the dataset: {missing_features}\")\n",
    "\n",
    "            X_train[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
    "            if X_test is not None:\n",
    "                X_test[features_to_scale] = scaler.transform(X_test[features_to_scale])\n",
    "\n",
    "            for col in features_to_scale:\n",
    "                self.feature_reasons[col] += f'Scaling Applied: {scaling_type} | '\n",
    "\n",
    "            self.preprocessing_steps.append(step_name)\n",
    "            if debug_flag:\n",
    "                self._log(f\"Applied {scaling_type} to features: {features_to_scale}\", step_name, 'debug')\n",
    "                if hasattr(scaler, 'mean_'):\n",
    "                    self._log(f\"Scaler Parameters: mean={scaler.mean_}\", step_name, 'debug')\n",
    "                if hasattr(scaler, 'scale_'):\n",
    "                    self._log(f\"Scaler Parameters: scale={scaler.scale_}\", step_name, 'debug')\n",
    "                self._log(f\"Sample of scaled X_train:\\n{X_train[features_to_scale].head()}\", step_name, 'debug')\n",
    "                if X_test is not None:\n",
    "                    self._log(f\"Sample of scaled X_test:\\n{X_test[features_to_scale].head()}\", step_name, 'debug')\n",
    "            else:\n",
    "                self.logger.info(f\"Step '{step_name}' completed: Applied {scaling_type} to features: {features_to_scale}\")\n",
    "        else:\n",
    "            self.logger.info(\"No scaling applied based on user options or no features specified.\")\n",
    "            self.preprocessing_steps.append(step_name)\n",
    "            if debug_flag:\n",
    "                self._log(f\"Completed: {step_name}. No scaling was applied.\", step_name, 'debug')\n",
    "            else:\n",
    "                self.logger.info(f\"Step '{step_name}' completed: No scaling was applied.\")\n",
    "\n",
    "        return X_train, X_test\n",
    "\n",
    "    def determine_n_neighbors(self, minority_count: int, default_neighbors: int = 5) -> int:\n",
    "        \"\"\"\n",
    "        Determine the appropriate number of neighbors for SMOTE based on minority class size.\n",
    "\n",
    "        Args:\n",
    "            minority_count (int): Number of samples in the minority class.\n",
    "            default_neighbors (int): Default number of neighbors to use if possible.\n",
    "\n",
    "        Returns:\n",
    "            int: Determined number of neighbors for SMOTE.\n",
    "        \"\"\"\n",
    "        if minority_count <= 1:\n",
    "            raise ValueError(\"SMOTE cannot be applied when the minority class has less than 2 samples.\")\n",
    "        \n",
    "        # Ensure n_neighbors does not exceed minority_count - 1\n",
    "        n_neighbors = min(default_neighbors, minority_count - 1)\n",
    "        return n_neighbors\n",
    "\n",
    "    def implement_smote(self, X_train: pd.DataFrame, y_train: pd.Series) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "        \"\"\"\n",
    "        Implement SMOTE or its variants based on class imbalance with automated n_neighbors selection.\n",
    "\n",
    "        Args:\n",
    "            X_train (pd.DataFrame): Training features (transformed).\n",
    "            y_train (pd.Series): Training target.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[pd.DataFrame, pd.Series]: Resampled X_train and y_train.\n",
    "        \"\"\"\n",
    "        step_name = \"Implement SMOTE (Train Only)\"\n",
    "        self.logger.info(f\"Step: {step_name}\")\n",
    "\n",
    "        # Check if classification\n",
    "        if self.model_category != 'classification':\n",
    "            self.logger.info(\"SMOTE not applicable: Not a classification model.\")\n",
    "            self.preprocessing_steps.append(\"SMOTE Skipped\")\n",
    "            return X_train, y_train\n",
    "\n",
    "        # Calculate class distribution\n",
    "        class_counts = y_train.value_counts()\n",
    "        if len(class_counts) < 2:\n",
    "            self.logger.warning(\"SMOTE not applicable: Only one class present.\")\n",
    "            self.preprocessing_steps.append(\"SMOTE Skipped\")\n",
    "            return X_train, y_train\n",
    "\n",
    "        majority_class = class_counts.idxmax()\n",
    "        minority_class = class_counts.idxmin()\n",
    "        majority_count = class_counts.max()\n",
    "        minority_count = class_counts.min()\n",
    "        imbalance_ratio = minority_count / majority_count\n",
    "        self.logger.info(f\"Class Distribution before SMOTE: {class_counts.to_dict()}\")\n",
    "        self.logger.info(f\"Imbalance Ratio (Minority/Majority): {imbalance_ratio:.4f}\")\n",
    "\n",
    "        # Determine SMOTE variant based on dataset composition\n",
    "        has_numericals = len(self.numericals) > 0\n",
    "        has_categoricals = len(self.ordinal_categoricals) + len(self.nominal_categoricals) > 0\n",
    "\n",
    "        # Automatically select SMOTE variant\n",
    "        if has_numericals and has_categoricals:\n",
    "            smote_variant = 'SMOTENC'\n",
    "            self.logger.info(\"Dataset contains both numerical and categorical features. Using SMOTENC.\")\n",
    "        elif has_numericals and not has_categoricals:\n",
    "            smote_variant = 'SMOTE'\n",
    "            self.logger.info(\"Dataset contains only numerical features. Using SMOTE.\")\n",
    "        elif has_categoricals and not has_numericals:\n",
    "            smote_variant = 'SMOTEN'\n",
    "            self.logger.info(\"Dataset contains only categorical features. Using SMOTEN.\")\n",
    "        else:\n",
    "            smote_variant = 'SMOTE'  # Fallback\n",
    "            self.logger.info(\"Feature composition unclear. Using SMOTE as default.\")\n",
    "\n",
    "        # Initialize SMOTE based on the variant\n",
    "        try:\n",
    "            if smote_variant == 'SMOTENC':\n",
    "                if not self.categorical_indices:\n",
    "                    # Determine categorical indices if not already set\n",
    "                    categorical_features = []\n",
    "                    for name, transformer, features in self.pipeline.transformers_:\n",
    "                        if 'ord' in name or 'nominal' in name:\n",
    "                            if isinstance(transformer, Pipeline):\n",
    "                                encoder = transformer.named_steps.get('ordinal_encoder') or transformer.named_steps.get('onehot_encoder')\n",
    "                                if hasattr(encoder, 'categories_'):\n",
    "                                    # Calculate indices based on transformers order\n",
    "                                    # This can be complex; for simplicity, assuming categorical features are the first\n",
    "                                    categorical_features.extend(range(len(features)))\n",
    "                    self.categorical_indices = categorical_features\n",
    "                    self.logger.debug(f\"Categorical feature indices for SMOTENC: {self.categorical_indices}\")\n",
    "                n_neighbors = self.determine_n_neighbors(minority_count, default_neighbors=5)\n",
    "                smote = SMOTENC(categorical_features=self.categorical_indices, random_state=42, k_neighbors=n_neighbors)\n",
    "                self.logger.debug(f\"Initialized SMOTENC with categorical features indices: {self.categorical_indices} and n_neighbors={n_neighbors}\")\n",
    "            elif smote_variant == 'SMOTEN':\n",
    "                n_neighbors = self.determine_n_neighbors(minority_count, default_neighbors=5)\n",
    "                smote = SMOTEN(random_state=42, n_neighbors=n_neighbors)\n",
    "                self.logger.debug(f\"Initialized SMOTEN with n_neighbors={n_neighbors}\")\n",
    "            else:\n",
    "                n_neighbors = self.determine_n_neighbors(minority_count, default_neighbors=5)\n",
    "                smote = SMOTE(random_state=42, k_neighbors=n_neighbors)\n",
    "                self.logger.debug(f\"Initialized SMOTE with n_neighbors={n_neighbors}\")\n",
    "        except ValueError as ve:\n",
    "            self.logger.error(f\"❌ SMOTE initialization failed: {ve}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"❌ Unexpected error during SMOTE initialization: {e}\")\n",
    "            raise\n",
    "\n",
    "        # Apply SMOTE\n",
    "        try:\n",
    "            X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "            self.logger.info(f\"Applied {smote_variant}. Resampled dataset shape: {X_resampled.shape}\")\n",
    "            self.preprocessing_steps.append(\"Implement SMOTE\")\n",
    "            self.smote = smote  # Assign to self for saving\n",
    "            self.logger.debug(f\"Selected n_neighbors for SMOTE: {n_neighbors}\")\n",
    "            return X_resampled, y_resampled\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"❌ SMOTE application failed: {e}\")\n",
    "            raise\n",
    "\n",
    "    def inverse_transform_data(self, X_transformed: np.ndarray, original_data: Optional[pd.DataFrame] = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Perform inverse transformation on the transformed data to reconstruct original feature values.\n",
    "\n",
    "        Args:\n",
    "            X_transformed (np.ndarray): The transformed feature data.\n",
    "            original_data (Optional[pd.DataFrame]): The original data before transformation.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The inverse-transformed DataFrame including passthrough columns.\n",
    "        \"\"\"\n",
    "        if self.pipeline is None:\n",
    "            self.logger.error(\"Preprocessing pipeline has not been fitted. Cannot perform inverse transformation.\")\n",
    "            raise AttributeError(\"Preprocessing pipeline has not been fitted. Cannot perform inverse transformation.\")\n",
    "\n",
    "        preprocessor = self.pipeline\n",
    "        logger = logging.getLogger('InverseTransform')\n",
    "        if self.debug or self.get_debug_flag('debug_final_inverse_transformations'):\n",
    "            logger.setLevel(logging.DEBUG)\n",
    "        else:\n",
    "            logger.setLevel(logging.INFO)\n",
    "\n",
    "        logger.debug(f\"[DEBUG Inverse] Starting inverse transformation. Input shape: {X_transformed.shape}\")\n",
    "\n",
    "        # Initialize variables\n",
    "        inverse_data = {}\n",
    "        transformations_applied = False  # Flag to check if any transformations are applied\n",
    "        start_idx = 0  # Starting index for slicing\n",
    "\n",
    "        # Iterate over each transformer in the ColumnTransformer\n",
    "        for name, transformer, features in preprocessor.transformers_:\n",
    "            if name == 'remainder':\n",
    "                logger.debug(f\"[DEBUG Inverse] Skipping 'remainder' transformer (passthrough columns).\")\n",
    "                continue  # Skip passthrough columns\n",
    "\n",
    "            end_idx = start_idx + len(features)\n",
    "            logger.debug(f\"[DEBUG Inverse] Transformer '{name}' handling features {features} with slice {start_idx}:{end_idx}\")\n",
    "\n",
    "            # Check if the transformer has an inverse_transform method\n",
    "            if hasattr(transformer, 'named_steps'):\n",
    "                # Access the last step in the pipeline (e.g., scaler or encoder)\n",
    "                last_step = list(transformer.named_steps.keys())[-1]\n",
    "                inverse_transformer = transformer.named_steps[last_step]\n",
    "\n",
    "                if hasattr(inverse_transformer, 'inverse_transform'):\n",
    "                    transformed_slice = X_transformed[:, start_idx:end_idx]\n",
    "                    inverse_slice = inverse_transformer.inverse_transform(transformed_slice)\n",
    "\n",
    "                    # Assign inverse-transformed data to the corresponding feature names\n",
    "                    for idx, feature in enumerate(features):\n",
    "                        inverse_data[feature] = inverse_slice[:, idx]\n",
    "\n",
    "                    logger.debug(f\"[DEBUG Inverse] Applied inverse_transform on transformer '{last_step}' for features {features}.\")\n",
    "                    transformations_applied = True\n",
    "                else:\n",
    "                    logger.debug(f\"[DEBUG Inverse] Transformer '{last_step}' does not support inverse_transform. Skipping.\")\n",
    "            else:\n",
    "                logger.debug(f\"[DEBUG Inverse] Transformer '{name}' does not have 'named_steps'. Skipping.\")\n",
    "\n",
    "            start_idx = end_idx  # Update starting index for next transformer\n",
    "\n",
    "        # Convert the inverse_data dictionary to a DataFrame\n",
    "        if transformations_applied:\n",
    "            inverse_df = pd.DataFrame(inverse_data, index=original_data.index if original_data is not None else None)\n",
    "            logger.debug(f\"[DEBUG Inverse] Inverse DataFrame shape (transformed columns): {inverse_df.shape}\")\n",
    "            logger.debug(f\"[DEBUG Inverse] Sample of inverse-transformed data:\\n{inverse_df.head()}\")\n",
    "        else:\n",
    "            if original_data is not None:\n",
    "                logger.warning(\"⚠️ No reversible transformations were applied. Returning original data.\")\n",
    "                inverse_df = original_data.copy()\n",
    "                logger.debug(f\"[DEBUG Inverse] Returning a copy of original_data with shape: {inverse_df.shape}\")\n",
    "            else:\n",
    "                logger.error(\"❌ No transformations were applied and original_data was not provided. Cannot perform inverse transformation.\")\n",
    "                raise ValueError(\"No transformations were applied and original_data was not provided.\")\n",
    "\n",
    "        # Identify passthrough columns by excluding transformed features\n",
    "        if original_data is not None and transformations_applied:\n",
    "            transformed_features = set(inverse_data.keys())\n",
    "            all_original_features = set(original_data.columns)\n",
    "            passthrough_columns = list(all_original_features - transformed_features)\n",
    "            logger.debug(f\"[DEBUG Inverse] Inverse DataFrame columns before pass-through merge: {inverse_df.columns.tolist()}\")\n",
    "            logger.debug(f\"[DEBUG Inverse] all_original_features: {list(all_original_features)}\")\n",
    "            logger.debug(f\"[DEBUG Inverse] passthrough_columns: {passthrough_columns}\")\n",
    "\n",
    "            if passthrough_columns:\n",
    "                logger.debug(f\"[DEBUG Inverse] Passthrough columns to merge: {passthrough_columns}\")\n",
    "                passthrough_data = original_data[passthrough_columns].copy()\n",
    "                inverse_df = pd.concat([inverse_df, passthrough_data], axis=1)\n",
    "\n",
    "                # Ensure the final DataFrame has the same column order as original_data\n",
    "                inverse_df = inverse_df[original_data.columns]\n",
    "                logger.debug(f\"[DEBUG Inverse] Final inverse DataFrame shape: {inverse_df.shape}\")\n",
    "                \n",
    "                # Check for missing columns after inverse transform\n",
    "                expected_columns = set(original_data.columns)\n",
    "                final_columns = set(inverse_df.columns)\n",
    "                missing_after_inverse = expected_columns - final_columns\n",
    "\n",
    "                if missing_after_inverse:\n",
    "                    err_msg = (\n",
    "                    f\"Inverse transform error: The following columns are missing \"\n",
    "                    f\"after inverse transform: {missing_after_inverse}\"\n",
    "                    )\n",
    "                    logger.error(err_msg)\n",
    "                    raise ValueError(err_msg)\n",
    "            else:\n",
    "                logger.debug(\"[DEBUG Inverse] No passthrough columns to merge.\")\n",
    "        else:\n",
    "            logger.debug(\"[DEBUG Inverse] Either no original_data provided or no transformations were applied.\")\n",
    "\n",
    "        return inverse_df\n",
    "\n",
    "\n",
    "\n",
    "    def build_pipeline(self, X_train: pd.DataFrame) -> ColumnTransformer:\n",
    "        transformers = []\n",
    "\n",
    "        # Handle Numerical Features\n",
    "        if self.numericals:\n",
    "            numerical_strategy = self.options.get('handle_missing_values', {}).get('numerical_strategy', {}).get('strategy', 'median')\n",
    "            numerical_imputer = self.options.get('handle_missing_values', {}).get('numerical_strategy', {}).get('imputer', 'SimpleImputer')\n",
    "\n",
    "            if numerical_imputer == 'SimpleImputer':\n",
    "                num_imputer = SimpleImputer(strategy=numerical_strategy)\n",
    "            elif numerical_imputer == 'KNNImputer':\n",
    "                knn_neighbors = self.options.get('handle_missing_values', {}).get('numerical_strategy', {}).get('knn_neighbors', 5)\n",
    "                num_imputer = KNNImputer(n_neighbors=knn_neighbors)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported numerical imputer type: {numerical_imputer}\")\n",
    "\n",
    "            # Determine scaling method\n",
    "            scaling_method = self.options.get('apply_scaling', {}).get('method', None)\n",
    "            if scaling_method is None:\n",
    "                # Default scaling based on model category\n",
    "                if self.model_category in ['regression', 'classification', 'clustering']:\n",
    "                    # For clustering, MinMaxScaler is generally preferred\n",
    "                    if self.model_category == 'clustering':\n",
    "                        scaler = MinMaxScaler()\n",
    "                        scaling_type = 'MinMaxScaler'\n",
    "                    else:\n",
    "                        scaler = StandardScaler()\n",
    "                        scaling_type = 'StandardScaler'\n",
    "                else:\n",
    "                    scaler = 'passthrough'\n",
    "                    scaling_type = 'None'\n",
    "            else:\n",
    "                # Normalize the scaling_method string to handle case-insensitivity\n",
    "                scaling_method_normalized = scaling_method.lower()\n",
    "                if scaling_method_normalized == 'standardscaler':\n",
    "                    scaler = StandardScaler()\n",
    "                    scaling_type = 'StandardScaler'\n",
    "                elif scaling_method_normalized == 'minmaxscaler':\n",
    "                    scaler = MinMaxScaler()\n",
    "                    scaling_type = 'MinMaxScaler'\n",
    "                elif scaling_method_normalized == 'robustscaler':\n",
    "                    scaler = RobustScaler()\n",
    "                    scaling_type = 'RobustScaler'\n",
    "                elif scaling_method_normalized == 'none':\n",
    "                    scaler = 'passthrough'\n",
    "                    scaling_type = 'None'\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported scaling method: {scaling_method}\")\n",
    "\n",
    "            numerical_transformer = Pipeline(steps=[\n",
    "                ('imputer', num_imputer),\n",
    "                ('scaler', scaler)\n",
    "            ])\n",
    "\n",
    "            transformers.append(('num', numerical_transformer, self.numericals))\n",
    "            self.logger.debug(f\"Numerical transformer added with imputer '{numerical_imputer}' and scaler '{scaling_type}'.\")\n",
    "\n",
    "        # Handle Ordinal Categorical Features\n",
    "        if self.ordinal_categoricals:\n",
    "            ordinal_strategy = self.options.get('encode_categoricals', {}).get('ordinal_encoding', 'OrdinalEncoder')\n",
    "            if ordinal_strategy == 'OrdinalEncoder':\n",
    "                ordinal_transformer = Pipeline(steps=[\n",
    "                    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                    ('ordinal_encoder', OrdinalEncoder())\n",
    "                ])\n",
    "                transformers.append(('ord', ordinal_transformer, self.ordinal_categoricals))\n",
    "                self.logger.debug(\"Ordinal transformer added with OrdinalEncoder.\")\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported ordinal encoding strategy: {ordinal_strategy}\")\n",
    "\n",
    "        # Handle Nominal Categorical Features\n",
    "        if self.nominal_categoricals:\n",
    "            nominal_strategy = self.options.get('encode_categoricals', {}).get('nominal_encoding', 'OneHotEncoder')\n",
    "            if nominal_strategy == 'OneHotEncoder':\n",
    "                nominal_transformer = Pipeline(steps=[\n",
    "                    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                    ('onehot_encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "                ])\n",
    "                transformers.append(('nominal', nominal_transformer, self.nominal_categoricals))\n",
    "                self.logger.debug(\"Nominal transformer added with OneHotEncoder.\")\n",
    "            elif nominal_strategy == 'OrdinalEncoder':\n",
    "                nominal_transformer = Pipeline(steps=[\n",
    "                    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                    ('ordinal_encoder', OrdinalEncoder())\n",
    "                ])\n",
    "                transformers.append(('nominal_ord', nominal_transformer, self.nominal_categoricals))\n",
    "                self.logger.debug(\"Nominal transformer added with OrdinalEncoder.\")\n",
    "            elif nominal_strategy == 'FrequencyEncoder':\n",
    "                # Implement custom Frequency Encoding\n",
    "                for feature in self.nominal_categoricals:\n",
    "                    freq = X_train[feature].value_counts(normalize=True)\n",
    "                    X_train[feature] = X_train[feature].map(freq)\n",
    "                    self.feature_reasons[feature] += 'Frequency Encoding applied | '\n",
    "                    self.logger.debug(f\"Frequency Encoding applied to '{feature}'.\")\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported nominal encoding strategy: {nominal_strategy}\")\n",
    "\n",
    "        if not transformers and 'FrequencyEncoder' not in nominal_strategy:\n",
    "            self.logger.error(\"No transformers added to the pipeline. Check feature categorization and configuration.\")\n",
    "            raise ValueError(\"No transformers added to the pipeline. Check feature categorization and configuration.\")\n",
    "\n",
    "        preprocessor = ColumnTransformer(transformers=transformers, remainder='passthrough')\n",
    "        self.logger.debug(\"ColumnTransformer constructed with the following transformers:\")\n",
    "        for t in transformers:\n",
    "            self.logger.debug(t)\n",
    "\n",
    "        preprocessor.fit(X_train)\n",
    "        self.logger.info(\"✅ Preprocessor fitted on training data.\")\n",
    "\n",
    "        # Determine categorical feature indices for SMOTENC if needed\n",
    "        if self.options.get('implement_smote', {}).get('variant', None) == 'SMOTENC':\n",
    "            if not self.categorical_indices:\n",
    "                categorical_features = []\n",
    "                for name, transformer, features in preprocessor.transformers_:\n",
    "                    if 'ord' in name or 'nominal' in name:\n",
    "                        if isinstance(transformer, Pipeline):\n",
    "                            encoder = transformer.named_steps.get('ordinal_encoder') or transformer.named_steps.get('onehot_encoder')\n",
    "                            if hasattr(encoder, 'categories_'):\n",
    "                                # Calculate indices based on transformers order\n",
    "                                # This can be complex; for simplicity, assuming categorical features are the first\n",
    "                                categorical_features.extend(range(len(features)))\n",
    "                self.categorical_indices = categorical_features\n",
    "                self.logger.debug(f\"Categorical feature indices for SMOTENC: {self.categorical_indices}\")\n",
    "\n",
    "        return preprocessor\n",
    "\n",
    "\n",
    "    def preprocess_train(self, X: pd.DataFrame, y: pd.Series) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series, pd.DataFrame, Optional[pd.DataFrame]]:\n",
    "        # Step 1: Split Dataset\n",
    "        X_train_original, X_test_original, y_train_original, y_test = self.split_dataset(X, y)\n",
    "\n",
    "        # Step 2: Handle Missing Values\n",
    "        X_train_missing_values, X_test_missing_values = self.handle_missing_values(X_train_original, X_test_original)\n",
    "\n",
    "        # Step 3: Test for Normality\n",
    "        if self.model_category in ['regression', 'classification', 'clustering']:\n",
    "            self.test_normality(X_train_missing_values)\n",
    "\n",
    "        # Step 4: Handle Outliers\n",
    "        X_train_outliers_handled, y_train_outliers_handled = self.handle_outliers(X_train_missing_values, y_train_original)\n",
    "\n",
    "        # Retain a copy of X_test without outliers for reference\n",
    "        X_test_outliers_handled = X_test_missing_values.copy() if X_test_missing_values is not None else None\n",
    "\n",
    "        # Step 5: Generate Preprocessing Recommendations\n",
    "        recommendations = self.generate_recommendations()\n",
    "\n",
    "        # Step 6: Build and Fit the Pipeline\n",
    "        self.pipeline = self.build_pipeline(X_train_outliers_handled)\n",
    "\n",
    "        # Fit and transform training data using the pipeline\n",
    "        X_train_preprocessed = self.pipeline.fit_transform(X_train_outliers_handled)\n",
    "\n",
    "        # Transform test data\n",
    "        X_test_preprocessed = self.pipeline.transform(X_test_outliers_handled) if X_test_outliers_handled is not None else None\n",
    "\n",
    "        # Step 7: Implement SMOTE Variant (Train Only for Classification)\n",
    "        if self.model_category == 'classification':\n",
    "            try:\n",
    "                X_train_smoted, y_train_smoted = self.implement_smote(X_train_preprocessed, y_train_outliers_handled)\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"❌ SMOTE application failed: {e}\")\n",
    "                raise  # Reraise exception to prevent saving incomplete transformers\n",
    "        else:\n",
    "            X_train_smoted, y_train_smoted = X_train_preprocessed, y_train_outliers_handled\n",
    "            self.logger.info(\"⚠️ SMOTE not applied: Not a classification model.\")\n",
    "\n",
    "        # Step 8: Save Transformers (Including the Pipeline)\n",
    "        self.final_feature_order = list(self.pipeline.get_feature_names_out())\n",
    "        X_train_final = pd.DataFrame(X_train_smoted, columns=self.final_feature_order)\n",
    "        X_test_final = pd.DataFrame(X_test_preprocessed, columns=self.final_feature_order, index=X_test_original.index) if X_test_preprocessed is not None else None\n",
    "\n",
    "        try:\n",
    "            self.save_transformers()\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"❌ Saving transformers failed: {e}\")\n",
    "            raise  # Prevent further steps if saving fails\n",
    "\n",
    "        # Inverse transformations (optional, for interpretability)\n",
    "        try:\n",
    "            # Use the final test dataset (fully transformed) for inverse transformations\n",
    "            if X_test_final is not None:\n",
    "                X_test_inverse = self.inverse_transform_data(X_test_final.values, original_data=X_test_original)\n",
    "                self.logger.info(\"✅ Inverse transformations applied successfully.\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"❌ Inverse transformations failed: {e}\")\n",
    "            X_test_inverse = None\n",
    "\n",
    "        # Return processed datasets\n",
    "        return X_train_final, X_test_final, y_train_smoted, y_test, recommendations, X_test_inverse\n",
    "\n",
    "    def transform(self, X: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Transform new data using the fitted preprocessing pipeline.\n",
    "\n",
    "        Args:\n",
    "            X (pd.DataFrame): New data to transform.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Preprocessed data.\n",
    "        \"\"\"\n",
    "        if self.pipeline is None:\n",
    "            self.logger.error(\"Preprocessing pipeline has not been fitted. Cannot perform inverse transformation.\")\n",
    "            raise AttributeError(\"Preprocessing pipeline has not been fitted. Cannot perform inverse transformation.\")\n",
    "        self.logger.debug(\"Transforming new data.\")\n",
    "        X_preprocessed = self.pipeline.transform(X)\n",
    "        if self.debug:\n",
    "            self.logger.debug(f\"Transformed data shape: {X_preprocessed.shape}\")\n",
    "        else:\n",
    "            self.logger.info(\"Data transformed.\")\n",
    "        return X_preprocessed\n",
    "\n",
    "    def preprocess_predict(self, X: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, Optional[pd.DataFrame]]:\n",
    "        \"\"\"\n",
    "        Preprocess new data for prediction.\n",
    "\n",
    "        Args:\n",
    "            X (pd.DataFrame): New data for prediction.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[pd.DataFrame, pd.DataFrame, Optional[pd.DataFrame]]: X_preprocessed, recommendations, X_inversed\n",
    "        \"\"\"\n",
    "        step_name = \"Preprocess Predict\"\n",
    "        self.logger.info(f\"Step: {step_name}\")\n",
    "\n",
    "        # Log initial columns and feature count\n",
    "        self.logger.debug(f\"Initial columns in prediction data: {X.columns.tolist()}\")\n",
    "        self.logger.debug(f\"Initial number of features: {X.shape[1]}\")\n",
    "\n",
    "        # Load transformers\n",
    "        try:\n",
    "            transformers = self.load_transformers()\n",
    "            self.logger.debug(\"Transformers loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"❌ Failed to load transformers: {e}\")\n",
    "            raise\n",
    "\n",
    "        # Filter columns based on raw feature names\n",
    "        try:\n",
    "            X_filtered = self.filter_columns(X)\n",
    "            self.logger.debug(f\"Columns after filtering: {X_filtered.columns.tolist()}\")\n",
    "            self.logger.debug(f\"Number of features after filtering: {X_filtered.shape[1]}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"❌ Failed during column filtering: {e}\")\n",
    "            raise\n",
    "\n",
    "        # Handle missing values\n",
    "        try:\n",
    "            X_filtered, _ = self.handle_missing_values(X_filtered)\n",
    "            self.logger.debug(f\"Columns after handling missing values: {X_filtered.columns.tolist()}\")\n",
    "            self.logger.debug(f\"Number of features after handling missing values: {X_filtered.shape[1]}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"❌ Failed during missing value handling: {e}\")\n",
    "            raise\n",
    "\n",
    "        # Ensure all expected raw features are present\n",
    "        expected_raw_features = self.numericals + self.ordinal_categoricals + self.nominal_categoricals\n",
    "        provided_features = X_filtered.columns.tolist()\n",
    "\n",
    "        self.logger.debug(f\"Expected raw features: {expected_raw_features}\")\n",
    "        self.logger.debug(f\"Provided features: {provided_features}\")\n",
    "\n",
    "        missing_raw_features = set(expected_raw_features) - set(provided_features)\n",
    "        if missing_raw_features:\n",
    "            self.logger.error(f\"❌ Missing required raw feature columns in prediction data: {missing_raw_features}\")\n",
    "            raise ValueError(f\"Missing required raw feature columns in prediction data: {missing_raw_features}\")\n",
    "\n",
    "        # Handle unexpected columns (optional: ignore or log)\n",
    "        unexpected_features = set(provided_features) - set(expected_raw_features)\n",
    "        if unexpected_features:\n",
    "            self.logger.warning(f\"⚠️ Unexpected columns in prediction data that will be ignored: {unexpected_features}\")\n",
    "\n",
    "        # Ensure the order of columns matches the pipeline's expectation (optional)\n",
    "        X_filtered = X_filtered[expected_raw_features]\n",
    "        self.logger.debug(\"Reordered columns to match the pipeline's raw feature expectations.\")\n",
    "\n",
    "        # Transform data using the loaded pipeline\n",
    "        try:\n",
    "            X_preprocessed_np = self.pipeline.transform(X_filtered)\n",
    "            self.logger.debug(f\"Transformed data shape: {X_preprocessed_np.shape}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"❌ Transformation failed: {e}\")\n",
    "            raise\n",
    "\n",
    "        # Retrieve feature names from the pipeline or use stored final_feature_order\n",
    "        if hasattr(self.pipeline, 'get_feature_names_out'):\n",
    "            try:\n",
    "                columns = self.pipeline.get_feature_names_out()\n",
    "                self.logger.debug(f\"Derived feature names from pipeline: {columns.tolist()}\")\n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"Could not retrieve feature names from pipeline: {e}\")\n",
    "                columns = self.final_feature_order\n",
    "                self.logger.debug(f\"Using stored final_feature_order for column names: {columns}\")\n",
    "        else:\n",
    "            columns = self.final_feature_order\n",
    "            self.logger.debug(f\"Using stored final_feature_order for column names: {columns}\")\n",
    "\n",
    "        # Convert NumPy array back to DataFrame with correct column names\n",
    "        try:\n",
    "            X_preprocessed_df = pd.DataFrame(X_preprocessed_np, columns=columns, index=X_filtered.index)\n",
    "            self.logger.debug(f\"X_preprocessed_df columns: {X_preprocessed_df.columns.tolist()}\")\n",
    "            self.logger.debug(f\"Sample of X_preprocessed_df:\\n{X_preprocessed_df.head()}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"❌ Failed to convert transformed data to DataFrame: {e}\")\n",
    "            raise\n",
    "\n",
    "        # Inverse transform for interpretability (optional, for interpretability)\n",
    "        try:\n",
    "            self.logger.debug(f\"[DEBUG] Original data shape before inverse transform: {X.shape}\")\n",
    "            X_inversed = self.inverse_transform_data(X_preprocessed_np, original_data=X)\n",
    "            self.logger.debug(f\"[DEBUG] Inversed data shape: {X_inversed.shape}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"❌ Inverse transformation failed: {e}\")\n",
    "            X_inversed = None\n",
    "\n",
    "        # Generate recommendations (if applicable)\n",
    "        try:\n",
    "            recommendations = self.generate_recommendations()\n",
    "            self.logger.debug(\"Generated preprocessing recommendations.\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"❌ Failed to generate recommendations: {e}\")\n",
    "            recommendations = pd.DataFrame()\n",
    "\n",
    "        # Prepare outputs\n",
    "        return X_preprocessed_df, recommendations, X_inversed\n",
    "\n",
    "    def preprocess_clustering(self, X: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Preprocess data for clustering mode.\n",
    "\n",
    "        Args:\n",
    "            X (pd.DataFrame): Input features for clustering.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[pd.DataFrame, pd.DataFrame]: X_processed, recommendations.\n",
    "        \"\"\"\n",
    "        step_name = \"Preprocess Clustering\"\n",
    "        self.logger.info(f\"Step: {step_name}\")\n",
    "        debug_flag = self.get_debug_flag('debug_handle_missing_values')  # Use relevant debug flags\n",
    "\n",
    "        # Handle Missing Values\n",
    "        X_missing, _ = self.handle_missing_values(X, None)\n",
    "        self.logger.debug(f\"After handling missing values: X_missing.shape={X_missing.shape}\")\n",
    "\n",
    "        # Handle Outliers\n",
    "        X_outliers_handled, _ = self.handle_outliers(X_missing, None)\n",
    "        self.logger.debug(f\"After handling outliers: X_outliers_handled.shape={X_outliers_handled.shape}\")\n",
    "\n",
    "        # Test Normality (optional for clustering)\n",
    "        if self.model_category in ['clustering']:\n",
    "            self.logger.info(\"Skipping normality tests for clustering.\")\n",
    "        else:\n",
    "            self.test_normality(X_outliers_handled)\n",
    "\n",
    "        # Generate Preprocessing Recommendations\n",
    "        recommendations = self.generate_recommendations()\n",
    "\n",
    "        # Build and Fit the Pipeline\n",
    "        self.pipeline = self.build_pipeline(X_outliers_handled)\n",
    "        self.logger.debug(\"Pipeline built and fitted.\")\n",
    "\n",
    "        # Transform the data\n",
    "        X_processed = self.pipeline.transform(X_outliers_handled)\n",
    "        self.logger.debug(f\"After pipeline transform: X_processed.shape={X_processed.shape}\")\n",
    "\n",
    "        # Optionally, inverse transformations can be handled if necessary\n",
    "\n",
    "        # Save Transformers (if needed)\n",
    "        # Not strictly necessary for clustering unless you plan to apply the same preprocessing on new data\n",
    "        self.save_transformers()\n",
    "\n",
    "        self.logger.info(\"✅ Clustering data preprocessed successfully.\")\n",
    "\n",
    "        return X_processed, recommendations\n",
    "\n",
    "    def final_preprocessing(\n",
    "        self, \n",
    "        data: pd.DataFrame\n",
    "    ) -> Tuple:\n",
    "        \"\"\"\n",
    "        Execute the full preprocessing pipeline based on the mode.\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame): Input dataset containing features and possibly the target variable.\n",
    "\n",
    "        Returns:\n",
    "            Tuple: Depending on mode:\n",
    "                - 'train': X_train, X_test, y_train, y_test, recommendations, X_test_inverse\n",
    "                - 'predict': X_preprocessed, recommendations, X_inverse\n",
    "                - 'clustering': X_processed, recommendations\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"Starting: Final Preprocessing Pipeline in '{self.mode}' mode.\")\n",
    "\n",
    "        # Step 0: Filter Columns\n",
    "        try:\n",
    "            data = self.filter_columns(data)\n",
    "            self.logger.info(\"✅ Column filtering completed successfully.\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"❌ Column filtering failed: {e}\")\n",
    "            raise\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            # Ensure y_variable is present in the data\n",
    "            if not all(col in data.columns for col in self.y_variable):\n",
    "                missing_y = [col for col in self.y_variable if col not in data.columns]\n",
    "                raise ValueError(f\"Target variable(s) {missing_y} not found in the dataset.\")\n",
    "\n",
    "            # Separate X and y\n",
    "            X = data.drop(self.y_variable, axis=1)\n",
    "            y = data[self.y_variable].iloc[:, 0] if len(self.y_variable) == 1 else data[self.y_variable]\n",
    "\n",
    "            if y is None:\n",
    "                raise ValueError(\"Target variable 'y' must be provided in train mode.\")\n",
    "            return self.preprocess_train(X, y)\n",
    "\n",
    "        elif self.mode == 'predict':\n",
    "            # For predict mode, y_variable is not used\n",
    "            X = data.copy()\n",
    "            # Ensure that transformers are loaded\n",
    "            transformers_path = os.path.join(self.transformers_dir, 'transformers.pkl')\n",
    "            if not os.path.exists(transformers_path):\n",
    "                self.logger.error(f\"❌ Transformers file not found at '{self.transformers_dir}'. Cannot proceed with prediction.\")\n",
    "                raise FileNotFoundError(f\"Transformers file not found at '{self.transformers_dir}'.\")\n",
    "\n",
    "            # Preprocess the data\n",
    "            X_preprocessed, recommendations, X_inversed = self.preprocess_predict(X)\n",
    "            self.logger.info(\"✅ Preprocessing completed successfully in predict mode.\")\n",
    "\n",
    "            return X_preprocessed, recommendations, X_inversed\n",
    "\n",
    "        elif self.mode == 'clustering':\n",
    "            # Clustering mode: Use all data as X; y is not used\n",
    "            X = data.copy()\n",
    "            return self.preprocess_clustering(X)\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Mode '{self.mode}' is not implemented.\")\n",
    "\n",
    "    # Optionally, implement a method to display column info for debugging\n",
    "    def _debug_column_info(self, df: pd.DataFrame, step: str = \"Debug Column Info\"):\n",
    "        \"\"\"\n",
    "        Display information about DataFrame columns for debugging purposes.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to inspect.\n",
    "            step (str, optional): Description of the current step. Defaults to \"Debug Column Info\".\n",
    "        \"\"\"\n",
    "        self.logger.debug(f\"\\n📊 {step}: Column Information\")\n",
    "        for col in df.columns:\n",
    "            self.logger.debug(f\"Column '{col}': {df[col].dtype}, Unique Values: {df[col].nunique()}\")\n",
    "        self.logger.debug(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 18:08:12,872 [INFO] Mode: Clustering\n",
      "2025-01-09 18:08:12,873 [INFO] ---\n",
      "Processing Model: Random Forest (Tree Based Classifier)\n",
      "---\n",
      "2025-01-09 18:08:12,873 [INFO] Model Category: Classification\n",
      "2025-01-09 18:08:12,874 [INFO] Skipping non-clustering type Tree Based Classifier in 'clustering' mode.\n",
      "2025-01-09 18:08:12,874 [INFO] ---\n",
      "Processing Model: XGBoost (Tree Based Classifier)\n",
      "---\n",
      "2025-01-09 18:08:12,875 [INFO] Model Category: Classification\n",
      "2025-01-09 18:08:12,875 [INFO] Skipping non-clustering type Tree Based Classifier in 'clustering' mode.\n",
      "2025-01-09 18:08:12,876 [INFO] ---\n",
      "Processing Model: Decision Tree (Tree Based Classifier)\n",
      "---\n",
      "2025-01-09 18:08:12,876 [INFO] Model Category: Classification\n",
      "2025-01-09 18:08:12,876 [INFO] Skipping non-clustering type Tree Based Classifier in 'clustering' mode.\n",
      "2025-01-09 18:08:12,877 [INFO] ---\n",
      "Processing Model: Logistic Regression (Logistic Regression)\n",
      "---\n",
      "2025-01-09 18:08:12,877 [INFO] Model Category: Classification\n",
      "2025-01-09 18:08:12,878 [INFO] Skipping non-clustering type Logistic Regression in 'clustering' mode.\n",
      "2025-01-09 18:08:12,878 [INFO] ---\n",
      "Processing Model: K-Means (K-Means)\n",
      "---\n",
      "2025-01-09 18:08:12,879 [INFO] Model Category: Clustering\n",
      "2025-01-09 18:08:12,880 [INFO] ---\n",
      "Processing Model: K-Means (K-Means) in 'clustering' mode\n",
      "---\n",
      "2025-01-09 18:08:12,885 [INFO] ✅ Clustering input data loaded from '..\\..\\dataset\\test\\data\\final_ml_dataset.csv'.\n",
      "2025-01-09 18:08:12,885 [INFO] Starting: Final Preprocessing Pipeline in 'clustering' mode.\n",
      "2025-01-09 18:08:12,886 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:12,887 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 15)\n",
      "2025-01-09 18:08:12,887 [INFO] ✅ Column filtering completed successfully.\n",
      "2025-01-09 18:08:12,888 [INFO] Step: Preprocess Clustering\n",
      "2025-01-09 18:08:12,888 [INFO] Step: Handle Missing Values\n",
      "2025-01-09 18:08:12,894 [INFO] Step: Handle Outliers\n",
      "2025-01-09 18:08:12,894 [INFO] Applying multivariate IsolationForest for clustering.\n",
      "c:\\Users\\ghadf\\anaconda3\\envs\\data_science_ml_preprocessor\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-01-09 18:08:12,998 [INFO] Skipping normality tests for clustering.\n",
      "2025-01-09 18:08:12,999 [INFO] Step: Generate Preprocessor Recommendations\n",
      "2025-01-09 18:08:13,005 [INFO] ✅ Preprocessor fitted on training data.\n",
      "2025-01-09 18:08:13,008 [INFO] Step: Save Transformers\n",
      "2025-01-09 18:08:13,011 [INFO] Transformers saved at '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:13,011 [INFO] ✅ Clustering data preprocessed successfully.\n",
      "2025-01-09 18:08:13,011 [INFO] ✅ Preprocessing completed successfully in clustering mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training mode...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghadf\\anaconda3\\envs\\data_science_ml_preprocessor\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "2025-01-09 18:08:13,101 [INFO] ✅ K-Means clustering completed. Inertia: 39.11669530417219\n",
      "2025-01-09 18:08:13,103 [INFO] ✅ Clustering model K-Means saved to '..\\models\\K-Means\\trained_model.pkl'.\n",
      "2025-01-09 18:08:13,104 [INFO] ✅ All tasks completed successfully for clustering model 'K-Means'.\n",
      "2025-01-09 18:08:13,105 [INFO] ✅ All tasks completed successfully for model 'K-Means'.\n",
      "2025-01-09 18:08:13,105 [INFO] ---\n",
      "Processing Model: Linear Regression (Linear Regression)\n",
      "---\n",
      "2025-01-09 18:08:13,106 [INFO] Model Category: Regression\n",
      "2025-01-09 18:08:13,107 [INFO] Skipping non-clustering type Linear Regression in 'clustering' mode.\n",
      "2025-01-09 18:08:13,107 [INFO] ---\n",
      "Processing Model: Random Forest Regressor (Tree Based Regressor)\n",
      "---\n",
      "2025-01-09 18:08:13,108 [INFO] Model Category: Regression\n",
      "2025-01-09 18:08:13,109 [INFO] Skipping non-clustering type Tree Based Regressor in 'clustering' mode.\n",
      "2025-01-09 18:08:13,109 [INFO] ---\n",
      "Processing Model: XGBoost Regressor (Tree Based Regressor)\n",
      "---\n",
      "2025-01-09 18:08:13,110 [INFO] Model Category: Regression\n",
      "2025-01-09 18:08:13,111 [INFO] Skipping non-clustering type Tree Based Regressor in 'clustering' mode.\n",
      "2025-01-09 18:08:13,111 [INFO] ---\n",
      "Processing Model: Decision Tree Regressor (Tree Based Regressor)\n",
      "---\n",
      "2025-01-09 18:08:13,112 [INFO] Model Category: Regression\n",
      "2025-01-09 18:08:13,113 [INFO] Skipping non-clustering type Tree Based Regressor in 'clustering' mode.\n",
      "2025-01-09 18:08:13,113 [INFO] ---\n",
      "Processing Model: Support Vector Machine (Support Vector Machine)\n",
      "---\n",
      "2025-01-09 18:08:13,114 [INFO] Model Category: Classification\n",
      "2025-01-09 18:08:13,115 [INFO] Skipping non-clustering type Support Vector Machine in 'clustering' mode.\n",
      "2025-01-09 18:08:13,163 [INFO] Mode: Train\n",
      "2025-01-09 18:08:13,164 [INFO] ---\n",
      "Processing Model: Random Forest (Tree Based Classifier)\n",
      "---\n",
      "2025-01-09 18:08:13,165 [INFO] Model Category: Classification\n",
      "2025-01-09 18:08:13,165 [INFO] ---\n",
      "Processing Model: Random Forest (Tree Based Classifier) in 'train' mode\n",
      "---\n",
      "2025-01-09 18:08:13,176 [INFO] ✅ Training input data loaded from '..\\..\\dataset\\test\\data\\final_ml_dataset.csv'.\n",
      "2025-01-09 18:08:13,177 [INFO] Starting: Final Preprocessing Pipeline in 'train' mode.\n",
      "2025-01-09 18:08:13,178 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:13,179 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 16)\n",
      "2025-01-09 18:08:13,180 [INFO] ✅ Column filtering completed successfully.\n",
      "2025-01-09 18:08:13,182 [INFO] Step: Split Dataset into Train and Test\n",
      "2025-01-09 18:08:13,188 [INFO] Step: Handle Missing Values\n",
      "2025-01-09 18:08:13,203 [INFO] Step: Test for Normality\n",
      "2025-01-09 18:08:13,213 [INFO] Step: Handle Outliers\n",
      "2025-01-09 18:08:13,213 [INFO] Applying univariate outlier detection for classification.\n",
      "2025-01-09 18:08:13,230 [INFO] Step: Generate Preprocessor Recommendations\n",
      "2025-01-09 18:08:13,240 [INFO] ✅ Preprocessor fitted on training data.\n",
      "2025-01-09 18:08:13,253 [INFO] Step: Implement SMOTE (Train Only)\n",
      "2025-01-09 18:08:13,254 [INFO] Class Distribution before SMOTE: {1: 52, 0: 27}\n",
      "2025-01-09 18:08:13,255 [INFO] Imbalance Ratio (Minority/Majority): 0.5192\n",
      "2025-01-09 18:08:13,255 [INFO] Dataset contains both numerical and categorical features. Using SMOTENC.\n",
      "2025-01-09 18:08:13,266 [INFO] Applied SMOTENC. Resampled dataset shape: (104, 15)\n",
      "2025-01-09 18:08:13,267 [INFO] Step: Save Transformers\n",
      "2025-01-09 18:08:13,271 [INFO] Transformers saved at '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:13,278 [INFO] ✅ Inverse transformations applied successfully.\n",
      "2025-01-09 18:08:13,279 [INFO] ✅ Preprocessing completed successfully in train mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training mode...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 18:08:13,388 [INFO] ✅ Random Forest trained successfully.\n",
      "2025-01-09 18:08:13,413 [INFO] ✅ Trained Random Forest saved to '..\\models\\Random_Forest\\trained_model.pkl'.\n",
      "2025-01-09 18:08:13,437 [INFO] ✅ Trained model loaded from '..\\models\\Random_Forest\\trained_model.pkl'.\n",
      "2025-01-09 18:08:13,466 [INFO] ✅ Predictions made successfully.\n",
      "2025-01-09 18:08:13,467 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 18:08:13,468 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 18:08:13,468 [INFO] Step: Save Transformers\n",
      "2025-01-09 18:08:13,472 [INFO] Transformers saved at '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:13,472 [INFO] ✅ Transformers saved to '..\\transformers'.\n",
      "2025-01-09 18:08:13,472 [INFO] ✅ All tasks completed successfully for model 'Random Forest'.\n",
      "2025-01-09 18:08:13,473 [INFO] ---\n",
      "Processing Model: XGBoost (Tree Based Classifier)\n",
      "---\n",
      "2025-01-09 18:08:13,474 [INFO] Model Category: Classification\n",
      "2025-01-09 18:08:13,474 [INFO] ---\n",
      "Processing Model: XGBoost (Tree Based Classifier) in 'train' mode\n",
      "---\n",
      "2025-01-09 18:08:13,480 [INFO] ✅ Training input data loaded from '..\\..\\dataset\\test\\data\\final_ml_dataset.csv'.\n",
      "2025-01-09 18:08:13,480 [INFO] Starting: Final Preprocessing Pipeline in 'train' mode.\n",
      "2025-01-09 18:08:13,481 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:13,482 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 16)\n",
      "2025-01-09 18:08:13,482 [INFO] ✅ Column filtering completed successfully.\n",
      "2025-01-09 18:08:13,483 [INFO] Step: Split Dataset into Train and Test\n",
      "2025-01-09 18:08:13,485 [INFO] Step: Handle Missing Values\n",
      "2025-01-09 18:08:13,494 [INFO] Step: Test for Normality\n",
      "2025-01-09 18:08:13,498 [INFO] Step: Handle Outliers\n",
      "2025-01-09 18:08:13,499 [INFO] Applying univariate outlier detection for classification.\n",
      "2025-01-09 18:08:13,513 [INFO] Step: Generate Preprocessor Recommendations\n",
      "2025-01-09 18:08:13,518 [INFO] ✅ Preprocessor fitted on training data.\n",
      "2025-01-09 18:08:13,526 [INFO] Step: Implement SMOTE (Train Only)\n",
      "2025-01-09 18:08:13,526 [INFO] Class Distribution before SMOTE: {1: 52, 0: 27}\n",
      "2025-01-09 18:08:13,527 [INFO] Imbalance Ratio (Minority/Majority): 0.5192\n",
      "2025-01-09 18:08:13,527 [INFO] Dataset contains both numerical and categorical features. Using SMOTENC.\n",
      "2025-01-09 18:08:13,537 [INFO] Applied SMOTENC. Resampled dataset shape: (104, 15)\n",
      "2025-01-09 18:08:13,538 [INFO] Step: Save Transformers\n",
      "2025-01-09 18:08:13,541 [INFO] Transformers saved at '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:13,544 [INFO] ✅ Inverse transformations applied successfully.\n",
      "2025-01-09 18:08:13,545 [INFO] ✅ Preprocessing completed successfully in train mode.\n",
      "2025-01-09 18:08:13,587 [INFO] ✅ XGBoost trained successfully.\n",
      "2025-01-09 18:08:13,591 [INFO] ✅ Trained XGBoost saved to '..\\models\\XGBoost\\trained_model.pkl'.\n",
      "2025-01-09 18:08:13,601 [INFO] ✅ Trained model loaded from '..\\models\\XGBoost\\trained_model.pkl'.\n",
      "2025-01-09 18:08:13,607 [INFO] ✅ Predictions made successfully.\n",
      "2025-01-09 18:08:13,609 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 18:08:13,610 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 18:08:13,611 [INFO] Step: Save Transformers\n",
      "2025-01-09 18:08:13,617 [INFO] Transformers saved at '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:13,618 [INFO] ✅ Transformers saved to '..\\transformers'.\n",
      "2025-01-09 18:08:13,618 [INFO] ✅ All tasks completed successfully for model 'XGBoost'.\n",
      "2025-01-09 18:08:13,619 [INFO] ---\n",
      "Processing Model: Decision Tree (Tree Based Classifier)\n",
      "---\n",
      "2025-01-09 18:08:13,620 [INFO] Model Category: Classification\n",
      "2025-01-09 18:08:13,621 [INFO] ---\n",
      "Processing Model: Decision Tree (Tree Based Classifier) in 'train' mode\n",
      "---\n",
      "2025-01-09 18:08:13,633 [INFO] ✅ Training input data loaded from '..\\..\\dataset\\test\\data\\final_ml_dataset.csv'.\n",
      "2025-01-09 18:08:13,634 [INFO] Starting: Final Preprocessing Pipeline in 'train' mode.\n",
      "2025-01-09 18:08:13,635 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:13,636 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 16)\n",
      "2025-01-09 18:08:13,637 [INFO] ✅ Column filtering completed successfully.\n",
      "2025-01-09 18:08:13,638 [INFO] Step: Split Dataset into Train and Test\n",
      "2025-01-09 18:08:13,644 [INFO] Step: Handle Missing Values\n",
      "2025-01-09 18:08:13,658 [INFO] Step: Test for Normality\n",
      "2025-01-09 18:08:13,668 [INFO] Step: Handle Outliers\n",
      "2025-01-09 18:08:13,669 [INFO] Applying univariate outlier detection for classification.\n",
      "2025-01-09 18:08:13,694 [INFO] Step: Generate Preprocessor Recommendations\n",
      "2025-01-09 18:08:13,705 [INFO] ✅ Preprocessor fitted on training data.\n",
      "2025-01-09 18:08:13,714 [INFO] Step: Implement SMOTE (Train Only)\n",
      "2025-01-09 18:08:13,715 [INFO] Class Distribution before SMOTE: {1: 52, 0: 27}\n",
      "2025-01-09 18:08:13,715 [INFO] Imbalance Ratio (Minority/Majority): 0.5192\n",
      "2025-01-09 18:08:13,716 [INFO] Dataset contains both numerical and categorical features. Using SMOTENC.\n",
      "2025-01-09 18:08:13,725 [INFO] Applied SMOTENC. Resampled dataset shape: (104, 15)\n",
      "2025-01-09 18:08:13,726 [INFO] Step: Save Transformers\n",
      "2025-01-09 18:08:13,729 [INFO] Transformers saved at '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:13,733 [INFO] ✅ Inverse transformations applied successfully.\n",
      "2025-01-09 18:08:13,733 [INFO] ✅ Preprocessing completed successfully in train mode.\n",
      "2025-01-09 18:08:13,735 [INFO] ✅ Decision Tree trained successfully.\n",
      "2025-01-09 18:08:13,737 [INFO] ✅ Trained Decision Tree saved to '..\\models\\Decision_Tree\\trained_model.pkl'.\n",
      "2025-01-09 18:08:13,745 [INFO] ✅ Trained model loaded from '..\\models\\Decision_Tree\\trained_model.pkl'.\n",
      "2025-01-09 18:08:13,746 [INFO] ✅ Predictions made successfully.\n",
      "2025-01-09 18:08:13,747 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 18:08:13,748 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 18:08:13,749 [INFO] Step: Save Transformers\n",
      "2025-01-09 18:08:13,752 [INFO] Transformers saved at '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:13,752 [INFO] ✅ Transformers saved to '..\\transformers'.\n",
      "2025-01-09 18:08:13,752 [INFO] ✅ All tasks completed successfully for model 'Decision Tree'.\n",
      "2025-01-09 18:08:13,753 [INFO] ---\n",
      "Processing Model: Logistic Regression (Logistic Regression)\n",
      "---\n",
      "2025-01-09 18:08:13,753 [INFO] Model Category: Classification\n",
      "2025-01-09 18:08:13,754 [INFO] ---\n",
      "Processing Model: Logistic Regression (Logistic Regression) in 'train' mode\n",
      "---\n",
      "2025-01-09 18:08:13,760 [INFO] ✅ Training input data loaded from '..\\..\\dataset\\test\\data\\final_ml_dataset.csv'.\n",
      "2025-01-09 18:08:13,760 [INFO] Starting: Final Preprocessing Pipeline in 'train' mode.\n",
      "2025-01-09 18:08:13,761 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:13,761 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 16)\n",
      "2025-01-09 18:08:13,762 [INFO] ✅ Column filtering completed successfully.\n",
      "2025-01-09 18:08:13,763 [INFO] Step: Split Dataset into Train and Test\n",
      "2025-01-09 18:08:13,766 [INFO] Step: Handle Missing Values\n",
      "2025-01-09 18:08:13,774 [INFO] Step: Test for Normality\n",
      "2025-01-09 18:08:13,779 [INFO] Step: Handle Outliers\n",
      "2025-01-09 18:08:13,779 [INFO] Applying univariate outlier detection for classification.\n",
      "2025-01-09 18:08:13,795 [INFO] Step: Generate Preprocessor Recommendations\n",
      "2025-01-09 18:08:13,803 [INFO] ✅ Preprocessor fitted on training data.\n",
      "2025-01-09 18:08:13,810 [INFO] Step: Implement SMOTE (Train Only)\n",
      "2025-01-09 18:08:13,811 [INFO] Class Distribution before SMOTE: {1: 52, 0: 27}\n",
      "2025-01-09 18:08:13,812 [INFO] Imbalance Ratio (Minority/Majority): 0.5192\n",
      "2025-01-09 18:08:13,812 [INFO] Dataset contains both numerical and categorical features. Using SMOTENC.\n",
      "2025-01-09 18:08:13,823 [INFO] Applied SMOTENC. Resampled dataset shape: (104, 15)\n",
      "2025-01-09 18:08:13,824 [INFO] Step: Save Transformers\n",
      "2025-01-09 18:08:13,827 [INFO] Transformers saved at '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:13,831 [INFO] ✅ Inverse transformations applied successfully.\n",
      "2025-01-09 18:08:13,831 [INFO] ✅ Preprocessing completed successfully in train mode.\n",
      "2025-01-09 18:08:13,836 [INFO] ✅ Logistic Regression trained successfully.\n",
      "2025-01-09 18:08:13,837 [INFO] ✅ Trained Logistic Regression saved to '..\\models\\Logistic_Regression\\trained_model.pkl'.\n",
      "2025-01-09 18:08:13,839 [INFO] ✅ Trained model loaded from '..\\models\\Logistic_Regression\\trained_model.pkl'.\n",
      "2025-01-09 18:08:13,840 [INFO] ✅ Predictions made successfully.\n",
      "2025-01-09 18:08:13,841 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 18:08:13,841 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 18:08:13,842 [INFO] Step: Save Transformers\n",
      "2025-01-09 18:08:13,845 [INFO] Transformers saved at '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:13,845 [INFO] ✅ Transformers saved to '..\\transformers'.\n",
      "2025-01-09 18:08:13,846 [INFO] ✅ All tasks completed successfully for model 'Logistic Regression'.\n",
      "2025-01-09 18:08:13,846 [INFO] ---\n",
      "Processing Model: K-Means (K-Means)\n",
      "---\n",
      "2025-01-09 18:08:13,847 [INFO] Model Category: Clustering\n",
      "2025-01-09 18:08:13,848 [INFO] Skipping clustering type K-Means in 'train' mode.\n",
      "2025-01-09 18:08:13,848 [INFO] ---\n",
      "Processing Model: Linear Regression (Linear Regression)\n",
      "---\n",
      "2025-01-09 18:08:13,848 [INFO] Model Category: Regression\n",
      "2025-01-09 18:08:13,849 [INFO] ---\n",
      "Processing Model: Linear Regression (Linear Regression) in 'train' mode\n",
      "---\n",
      "2025-01-09 18:08:13,854 [INFO] ✅ Training input data loaded from '..\\..\\dataset\\test\\data\\final_ml_dataset.csv'.\n",
      "2025-01-09 18:08:13,855 [INFO] Starting: Final Preprocessing Pipeline in 'train' mode.\n",
      "2025-01-09 18:08:13,855 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:13,856 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 16)\n",
      "2025-01-09 18:08:13,857 [INFO] ✅ Column filtering completed successfully.\n",
      "2025-01-09 18:08:13,858 [INFO] Step: Split Dataset into Train and Test\n",
      "2025-01-09 18:08:13,861 [INFO] Step: Handle Missing Values\n",
      "2025-01-09 18:08:13,868 [INFO] Step: Test for Normality\n",
      "2025-01-09 18:08:13,873 [INFO] Step: Handle Outliers\n",
      "2025-01-09 18:08:13,873 [INFO] Applying univariate outlier detection for regression.\n",
      "2025-01-09 18:08:13,893 [INFO] Step: Generate Preprocessor Recommendations\n",
      "2025-01-09 18:08:13,898 [INFO] ✅ Preprocessor fitted on training data.\n",
      "2025-01-09 18:08:13,906 [INFO] ⚠️ SMOTE not applied: Not a classification model.\n",
      "2025-01-09 18:08:13,906 [INFO] Step: Save Transformers\n",
      "2025-01-09 18:08:13,909 [INFO] Transformers saved at '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:13,912 [INFO] ✅ Inverse transformations applied successfully.\n",
      "2025-01-09 18:08:13,913 [INFO] ✅ Preprocessing completed successfully in train mode.\n",
      "2025-01-09 18:08:13,917 [INFO] ✅ Linear Regression trained successfully.\n",
      "2025-01-09 18:08:13,918 [INFO] ✅ Trained Linear Regression saved to '..\\models\\Linear_Regression\\trained_model.pkl'.\n",
      "2025-01-09 18:08:13,926 [INFO] ✅ Trained model loaded from '..\\models\\Linear_Regression\\trained_model.pkl'.\n",
      "2025-01-09 18:08:13,927 [INFO] ✅ Predictions made successfully.\n",
      "2025-01-09 18:08:13,928 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 18:08:13,928 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 18:08:13,929 [INFO] Step: Save Transformers\n",
      "2025-01-09 18:08:13,931 [INFO] Transformers saved at '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:13,932 [INFO] ✅ Transformers saved to '..\\transformers'.\n",
      "2025-01-09 18:08:13,932 [INFO] ✅ All tasks completed successfully for model 'Linear Regression'.\n",
      "2025-01-09 18:08:13,933 [INFO] ---\n",
      "Processing Model: Random Forest Regressor (Tree Based Regressor)\n",
      "---\n",
      "2025-01-09 18:08:13,933 [INFO] Model Category: Regression\n",
      "2025-01-09 18:08:13,934 [INFO] ---\n",
      "Processing Model: Random Forest Regressor (Tree Based Regressor) in 'train' mode\n",
      "---\n",
      "2025-01-09 18:08:13,940 [INFO] ✅ Training input data loaded from '..\\..\\dataset\\test\\data\\final_ml_dataset.csv'.\n",
      "2025-01-09 18:08:13,940 [INFO] Starting: Final Preprocessing Pipeline in 'train' mode.\n",
      "2025-01-09 18:08:13,941 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:13,941 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 16)\n",
      "2025-01-09 18:08:13,942 [INFO] ✅ Column filtering completed successfully.\n",
      "2025-01-09 18:08:13,943 [INFO] Step: Split Dataset into Train and Test\n",
      "2025-01-09 18:08:13,947 [INFO] Step: Handle Missing Values\n",
      "2025-01-09 18:08:13,954 [INFO] Step: Test for Normality\n",
      "2025-01-09 18:08:13,959 [INFO] Step: Handle Outliers\n",
      "2025-01-09 18:08:13,960 [INFO] Applying univariate outlier detection for regression.\n",
      "2025-01-09 18:08:13,973 [INFO] Step: Generate Preprocessor Recommendations\n",
      "2025-01-09 18:08:13,979 [INFO] ✅ Preprocessor fitted on training data.\n",
      "2025-01-09 18:08:13,986 [INFO] ⚠️ SMOTE not applied: Not a classification model.\n",
      "2025-01-09 18:08:13,986 [INFO] Step: Save Transformers\n",
      "2025-01-09 18:08:13,989 [INFO] Transformers saved at '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:13,991 [INFO] ✅ Inverse transformations applied successfully.\n",
      "2025-01-09 18:08:13,992 [INFO] ✅ Preprocessing completed successfully in train mode.\n",
      "2025-01-09 18:08:14,086 [INFO] ✅ Random Forest Regressor trained successfully.\n",
      "2025-01-09 18:08:14,106 [INFO] ✅ Trained Random Forest Regressor saved to '..\\models\\Random_Forest_Regressor\\trained_model.pkl'.\n",
      "2025-01-09 18:08:14,124 [INFO] ✅ Trained model loaded from '..\\models\\Random_Forest_Regressor\\trained_model.pkl'.\n",
      "2025-01-09 18:08:14,148 [INFO] ✅ Predictions made successfully.\n",
      "2025-01-09 18:08:14,149 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 18:08:14,150 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 18:08:14,150 [INFO] Step: Save Transformers\n",
      "2025-01-09 18:08:14,153 [INFO] Transformers saved at '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:14,153 [INFO] ✅ Transformers saved to '..\\transformers'.\n",
      "2025-01-09 18:08:14,154 [INFO] ✅ All tasks completed successfully for model 'Random Forest Regressor'.\n",
      "2025-01-09 18:08:14,154 [INFO] ---\n",
      "Processing Model: XGBoost Regressor (Tree Based Regressor)\n",
      "---\n",
      "2025-01-09 18:08:14,155 [INFO] Model Category: Regression\n",
      "2025-01-09 18:08:14,155 [INFO] ---\n",
      "Processing Model: XGBoost Regressor (Tree Based Regressor) in 'train' mode\n",
      "---\n",
      "2025-01-09 18:08:14,161 [INFO] ✅ Training input data loaded from '..\\..\\dataset\\test\\data\\final_ml_dataset.csv'.\n",
      "2025-01-09 18:08:14,161 [INFO] Starting: Final Preprocessing Pipeline in 'train' mode.\n",
      "2025-01-09 18:08:14,161 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:14,163 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 16)\n",
      "2025-01-09 18:08:14,163 [INFO] ✅ Column filtering completed successfully.\n",
      "2025-01-09 18:08:14,164 [INFO] Step: Split Dataset into Train and Test\n",
      "2025-01-09 18:08:14,168 [INFO] Step: Handle Missing Values\n",
      "2025-01-09 18:08:14,175 [INFO] Step: Test for Normality\n",
      "2025-01-09 18:08:14,181 [INFO] Step: Handle Outliers\n",
      "2025-01-09 18:08:14,181 [INFO] Applying univariate outlier detection for regression.\n",
      "2025-01-09 18:08:14,194 [INFO] Step: Generate Preprocessor Recommendations\n",
      "2025-01-09 18:08:14,201 [INFO] ✅ Preprocessor fitted on training data.\n",
      "2025-01-09 18:08:14,207 [INFO] ⚠️ SMOTE not applied: Not a classification model.\n",
      "2025-01-09 18:08:14,208 [INFO] Step: Save Transformers\n",
      "2025-01-09 18:08:14,210 [INFO] Transformers saved at '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:14,213 [INFO] ✅ Inverse transformations applied successfully.\n",
      "2025-01-09 18:08:14,214 [INFO] ✅ Preprocessing completed successfully in train mode.\n",
      "2025-01-09 18:08:14,255 [INFO] ✅ XGBoost Regressor trained successfully.\n",
      "2025-01-09 18:08:14,259 [INFO] ✅ Trained XGBoost Regressor saved to '..\\models\\XGBoost_Regressor\\trained_model.pkl'.\n",
      "2025-01-09 18:08:14,268 [INFO] ✅ Trained model loaded from '..\\models\\XGBoost_Regressor\\trained_model.pkl'.\n",
      "2025-01-09 18:08:14,275 [INFO] ✅ Predictions made successfully.\n",
      "2025-01-09 18:08:14,277 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 18:08:14,277 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 18:08:14,278 [INFO] Step: Save Transformers\n",
      "2025-01-09 18:08:14,282 [INFO] Transformers saved at '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:14,283 [INFO] ✅ Transformers saved to '..\\transformers'.\n",
      "2025-01-09 18:08:14,283 [INFO] ✅ All tasks completed successfully for model 'XGBoost Regressor'.\n",
      "2025-01-09 18:08:14,284 [INFO] ---\n",
      "Processing Model: Decision Tree Regressor (Tree Based Regressor)\n",
      "---\n",
      "2025-01-09 18:08:14,284 [INFO] Model Category: Regression\n",
      "2025-01-09 18:08:14,285 [INFO] ---\n",
      "Processing Model: Decision Tree Regressor (Tree Based Regressor) in 'train' mode\n",
      "---\n",
      "2025-01-09 18:08:14,296 [INFO] ✅ Training input data loaded from '..\\..\\dataset\\test\\data\\final_ml_dataset.csv'.\n",
      "2025-01-09 18:08:14,297 [INFO] Starting: Final Preprocessing Pipeline in 'train' mode.\n",
      "2025-01-09 18:08:14,297 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:14,299 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 16)\n",
      "2025-01-09 18:08:14,300 [INFO] ✅ Column filtering completed successfully.\n",
      "2025-01-09 18:08:14,301 [INFO] Step: Split Dataset into Train and Test\n",
      "2025-01-09 18:08:14,309 [INFO] Step: Handle Missing Values\n",
      "2025-01-09 18:08:14,324 [INFO] Step: Test for Normality\n",
      "2025-01-09 18:08:14,334 [INFO] Step: Handle Outliers\n",
      "2025-01-09 18:08:14,335 [INFO] Applying univariate outlier detection for regression.\n",
      "2025-01-09 18:08:14,364 [INFO] Step: Generate Preprocessor Recommendations\n",
      "2025-01-09 18:08:14,373 [INFO] ✅ Preprocessor fitted on training data.\n",
      "2025-01-09 18:08:14,383 [INFO] ⚠️ SMOTE not applied: Not a classification model.\n",
      "2025-01-09 18:08:14,384 [INFO] Step: Save Transformers\n",
      "2025-01-09 18:08:14,386 [INFO] Transformers saved at '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:14,388 [INFO] ✅ Inverse transformations applied successfully.\n",
      "2025-01-09 18:08:14,389 [INFO] ✅ Preprocessing completed successfully in train mode.\n",
      "2025-01-09 18:08:14,391 [INFO] ✅ Decision Tree Regressor trained successfully.\n",
      "2025-01-09 18:08:14,392 [INFO] ✅ Trained Decision Tree Regressor saved to '..\\models\\Decision_Tree_Regressor\\trained_model.pkl'.\n",
      "2025-01-09 18:08:14,395 [INFO] ✅ Trained model loaded from '..\\models\\Decision_Tree_Regressor\\trained_model.pkl'.\n",
      "2025-01-09 18:08:14,397 [INFO] ✅ Predictions made successfully.\n",
      "2025-01-09 18:08:14,398 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 18:08:14,399 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 18:08:14,400 [INFO] Step: Save Transformers\n",
      "2025-01-09 18:08:14,402 [INFO] Transformers saved at '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:14,403 [INFO] ✅ Transformers saved to '..\\transformers'.\n",
      "2025-01-09 18:08:14,403 [INFO] ✅ All tasks completed successfully for model 'Decision Tree Regressor'.\n",
      "2025-01-09 18:08:14,404 [INFO] ---\n",
      "Processing Model: Support Vector Machine (Support Vector Machine)\n",
      "---\n",
      "2025-01-09 18:08:14,404 [INFO] Model Category: Classification\n",
      "2025-01-09 18:08:14,405 [INFO] ---\n",
      "Processing Model: Support Vector Machine (Support Vector Machine) in 'train' mode\n",
      "---\n",
      "2025-01-09 18:08:14,410 [INFO] ✅ Training input data loaded from '..\\..\\dataset\\test\\data\\final_ml_dataset.csv'.\n",
      "2025-01-09 18:08:14,411 [INFO] Starting: Final Preprocessing Pipeline in 'train' mode.\n",
      "2025-01-09 18:08:14,411 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:14,412 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 16)\n",
      "2025-01-09 18:08:14,413 [INFO] ✅ Column filtering completed successfully.\n",
      "2025-01-09 18:08:14,414 [INFO] Step: Split Dataset into Train and Test\n",
      "2025-01-09 18:08:14,416 [INFO] Step: Handle Missing Values\n",
      "2025-01-09 18:08:14,424 [INFO] Step: Test for Normality\n",
      "2025-01-09 18:08:14,429 [INFO] Step: Handle Outliers\n",
      "2025-01-09 18:08:14,429 [INFO] Applying univariate outlier detection for classification.\n",
      "2025-01-09 18:08:14,442 [INFO] Step: Generate Preprocessor Recommendations\n",
      "2025-01-09 18:08:14,447 [INFO] ✅ Preprocessor fitted on training data.\n",
      "2025-01-09 18:08:14,453 [INFO] Step: Implement SMOTE (Train Only)\n",
      "2025-01-09 18:08:14,454 [INFO] Class Distribution before SMOTE: {1: 52, 0: 27}\n",
      "2025-01-09 18:08:14,455 [INFO] Imbalance Ratio (Minority/Majority): 0.5192\n",
      "2025-01-09 18:08:14,455 [INFO] Dataset contains both numerical and categorical features. Using SMOTENC.\n",
      "2025-01-09 18:08:14,464 [INFO] Applied SMOTENC. Resampled dataset shape: (104, 15)\n",
      "2025-01-09 18:08:14,465 [INFO] Step: Save Transformers\n",
      "2025-01-09 18:08:14,469 [INFO] Transformers saved at '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:14,472 [INFO] ✅ Inverse transformations applied successfully.\n",
      "2025-01-09 18:08:14,473 [INFO] ✅ Preprocessing completed successfully in train mode.\n",
      "2025-01-09 18:08:14,476 [INFO] ✅ Support Vector Machine trained successfully.\n",
      "2025-01-09 18:08:14,478 [INFO] ✅ Trained Support Vector Machine saved to '..\\models\\Support_Vector_Machine\\trained_model.pkl'.\n",
      "2025-01-09 18:08:14,486 [INFO] ✅ Trained model loaded from '..\\models\\Support_Vector_Machine\\trained_model.pkl'.\n",
      "2025-01-09 18:08:14,487 [INFO] ✅ Predictions made successfully.\n",
      "2025-01-09 18:08:14,488 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 18:08:14,489 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 18:08:14,489 [INFO] Step: Save Transformers\n",
      "2025-01-09 18:08:14,492 [INFO] Transformers saved at '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:14,492 [INFO] ✅ Transformers saved to '..\\transformers'.\n",
      "2025-01-09 18:08:14,493 [INFO] ✅ All tasks completed successfully for model 'Support Vector Machine'.\n",
      "2025-01-09 18:08:14,518 [INFO] Mode: Predict\n",
      "2025-01-09 18:08:14,519 [INFO] ---\n",
      "Processing Model: Random Forest (Tree Based Classifier)\n",
      "---\n",
      "2025-01-09 18:08:14,519 [INFO] Model Category: Classification\n",
      "2025-01-09 18:08:14,520 [INFO] ---\n",
      "Processing Model: Random Forest (Tree Based Classifier) in 'predict' mode\n",
      "---\n",
      "2025-01-09 18:08:14,526 [INFO] ✅ Prediction input data loaded from '..\\..\\dataset\\test\\data\\final_ml_dataset.csv'.\n",
      "2025-01-09 18:08:14,526 [INFO] Starting: Final Preprocessing Pipeline in 'predict' mode.\n",
      "2025-01-09 18:08:14,527 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:14,528 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 15)\n",
      "2025-01-09 18:08:14,528 [DEBUG] Selected Features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,529 [INFO] ✅ Column filtering completed successfully.\n",
      "2025-01-09 18:08:14,530 [INFO] Step: Preprocess Predict\n",
      "2025-01-09 18:08:14,530 [DEBUG] Initial columns in prediction data: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,531 [DEBUG] Initial number of features: 15\n",
      "2025-01-09 18:08:14,531 [INFO] Step: Load Transformers\n",
      "2025-01-09 18:08:14,532 [DEBUG] Loading transformers from: ..\\transformers\\transformers.pkl\n",
      "2025-01-09 18:08:14,541 [DEBUG] Pipeline loaded. Ready to transform new data.\n",
      "2025-01-09 18:08:14,541 [INFO] Transformers loaded successfully from '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:14,541 [DEBUG] Transformers loaded successfully.\n",
      "2025-01-09 18:08:14,542 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:14,543 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 15)\n",
      "2025-01-09 18:08:14,544 [DEBUG] Selected Features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,544 [DEBUG] Columns after filtering: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,544 [DEBUG] Number of features after filtering: 15\n",
      "2025-01-09 18:08:14,545 [INFO] Step: Handle Missing Values\n",
      "2025-01-09 18:08:14,545 [DEBUG] Numerical Imputation Strategy: Median, Imputer Type: SimpleImputer\n",
      "2025-01-09 18:08:14,548 [DEBUG] Categorical Imputation Strategy: Most_frequent, Imputer Type: SimpleImputer\n",
      "2025-01-09 18:08:14,550 [DEBUG] Completed: Handle Missing Values. Dataset shape after imputation: (125, 15)\n",
      "2025-01-09 18:08:14,551 [DEBUG] Missing values after imputation in X_train:\n",
      "release_ball_direction_x                    0\n",
      "release_ball_direction_z                    0\n",
      "release_ball_direction_y                    0\n",
      "elbow_release_angle                         0\n",
      "elbow_max_angle                             0\n",
      "wrist_release_angle                         0\n",
      "wrist_max_angle                             0\n",
      "knee_release_angle                          0\n",
      "knee_max_angle                              0\n",
      "release_ball_speed                          0\n",
      "calculated_release_angle                    0\n",
      "release_ball_velocity_x                     0\n",
      "release_ball_velocity_y                     0\n",
      "release_ball_velocity_z                     0\n",
      "player_estimated_hand_length_cm_category    0\n",
      "dtype: int64\n",
      "2025-01-09 18:08:14,552 [DEBUG] New columns handled: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,552 [DEBUG] Columns after handling missing values: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,552 [DEBUG] Number of features after handling missing values: 15\n",
      "2025-01-09 18:08:14,553 [DEBUG] Expected raw features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,553 [DEBUG] Provided features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,554 [DEBUG] Reordered columns to match the pipeline's raw feature expectations.\n",
      "2025-01-09 18:08:14,557 [DEBUG] Transformed data shape: (125, 15)\n",
      "2025-01-09 18:08:14,558 [DEBUG] Derived feature names from pipeline: ['num__release_ball_direction_x', 'num__release_ball_direction_z', 'num__release_ball_direction_y', 'num__elbow_release_angle', 'num__elbow_max_angle', 'num__wrist_release_angle', 'num__wrist_max_angle', 'num__knee_release_angle', 'num__knee_max_angle', 'num__release_ball_speed', 'num__calculated_release_angle', 'num__release_ball_velocity_x', 'num__release_ball_velocity_y', 'num__release_ball_velocity_z', 'nominal__player_estimated_hand_length_cm_category_Medium']\n",
      "2025-01-09 18:08:14,558 [DEBUG] X_preprocessed_df columns: ['num__release_ball_direction_x', 'num__release_ball_direction_z', 'num__release_ball_direction_y', 'num__elbow_release_angle', 'num__elbow_max_angle', 'num__wrist_release_angle', 'num__wrist_max_angle', 'num__knee_release_angle', 'num__knee_max_angle', 'num__release_ball_speed', 'num__calculated_release_angle', 'num__release_ball_velocity_x', 'num__release_ball_velocity_y', 'num__release_ball_velocity_z', 'nominal__player_estimated_hand_length_cm_category_Medium']\n",
      "2025-01-09 18:08:14,561 [DEBUG] Sample of X_preprocessed_df:\n",
      "   num__release_ball_direction_x  num__release_ball_direction_z  \\\n",
      "0                       0.200442                       0.029218   \n",
      "1                       0.628897                      -0.731202   \n",
      "2                       0.264488                      -0.091281   \n",
      "3                      -0.695430                       0.974150   \n",
      "4                       0.336515                      -0.199535   \n",
      "\n",
      "   num__release_ball_direction_y  num__elbow_release_angle  \\\n",
      "0                       1.175516                  1.020327   \n",
      "1                      -1.071842                 -1.423048   \n",
      "2                       0.121513                  1.294261   \n",
      "3                       1.180299                  0.861899   \n",
      "4                      -0.074955                  1.247774   \n",
      "\n",
      "   num__elbow_max_angle  num__wrist_release_angle  num__wrist_max_angle  \\\n",
      "0              1.138980                  0.441979             -0.782146   \n",
      "1             -1.457654                  1.794251              0.107597   \n",
      "2              1.555476                 -0.103650              0.205150   \n",
      "3             -0.086542                 -1.139068             -0.642810   \n",
      "4             -0.277425                 -1.398682             -1.226460   \n",
      "\n",
      "   num__knee_release_angle  num__knee_max_angle  num__release_ball_speed  \\\n",
      "0                 0.644151             0.702538                -0.238583   \n",
      "1                 1.092342             1.789279                 0.873691   \n",
      "2                 0.985277             1.623802                -0.020846   \n",
      "3                -0.517249             1.299184                -0.669375   \n",
      "4                 0.723405             1.037778                 0.460286   \n",
      "\n",
      "   num__calculated_release_angle  num__release_ball_velocity_x  \\\n",
      "0                       0.346229                     -0.071285   \n",
      "1                       1.067820                      0.738698   \n",
      "2                      -0.605145                      0.066010   \n",
      "3                       0.511606                     -0.783542   \n",
      "4                      -0.394284                      0.331009   \n",
      "\n",
      "   num__release_ball_velocity_y  num__release_ball_velocity_z  \\\n",
      "0                      1.192943                     -0.245370   \n",
      "1                     -1.443174                      0.893517   \n",
      "2                      0.115574                     -0.009691   \n",
      "3                      1.192943                     -0.560063   \n",
      "4                     -0.184186                      0.546129   \n",
      "\n",
      "   nominal__player_estimated_hand_length_cm_category_Medium  \n",
      "0                                                1.0         \n",
      "1                                                1.0         \n",
      "2                                                1.0         \n",
      "3                                                1.0         \n",
      "4                                                1.0         \n",
      "2025-01-09 18:08:14,561 [DEBUG] [DEBUG] Original data shape before inverse transform: (125, 15)\n",
      "2025-01-09 18:08:14,565 [DEBUG] [DEBUG] Inversed data shape: (125, 15)\n",
      "2025-01-09 18:08:14,566 [INFO] Step: Generate Preprocessor Recommendations\n",
      "2025-01-09 18:08:14,567 [DEBUG] Preprocessing Recommendations:\n",
      "                                                           Preprocessing Reason\n",
      "player_estimated_hand_length_cm_category  Categorical: Most_frequent Imputation\n",
      "release_ball_direction_x                           Numerical: Median Imputation\n",
      "release_ball_direction_z                           Numerical: Median Imputation\n",
      "release_ball_direction_y                           Numerical: Median Imputation\n",
      "elbow_release_angle                                Numerical: Median Imputation\n",
      "elbow_max_angle                                    Numerical: Median Imputation\n",
      "wrist_release_angle                                Numerical: Median Imputation\n",
      "wrist_max_angle                                    Numerical: Median Imputation\n",
      "knee_release_angle                                 Numerical: Median Imputation\n",
      "knee_max_angle                                     Numerical: Median Imputation\n",
      "release_ball_speed                                 Numerical: Median Imputation\n",
      "calculated_release_angle                           Numerical: Median Imputation\n",
      "release_ball_velocity_x                            Numerical: Median Imputation\n",
      "release_ball_velocity_y                            Numerical: Median Imputation\n",
      "release_ball_velocity_z                            Numerical: Median Imputation\n",
      "2025-01-09 18:08:14,567 [DEBUG] Generated preprocessing recommendations.\n",
      "2025-01-09 18:08:14,568 [INFO] ✅ Preprocessing completed successfully in predict mode.\n",
      "2025-01-09 18:08:14,568 [INFO] ✅ Preprocessing completed successfully in predict mode.\n",
      "2025-01-09 18:08:14,584 [INFO] ✅ Trained model loaded from '..\\models\\Random_Forest\\trained_model.pkl'.\n",
      "2025-01-09 18:08:14,614 [INFO] ✅ Predictions made successfully.\n",
      "2025-01-09 18:08:14,615 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 18:08:14,618 [INFO] ✅ Predictions saved to '..\\..\\dataset\\test\\data\\preprocessor\\predictions\\predictions_Random_Forest.csv'.\n",
      "2025-01-09 18:08:14,618 [INFO] ✅ All tasks completed successfully for model 'Random Forest'.\n",
      "2025-01-09 18:08:14,618 [INFO] ---\n",
      "Processing Model: XGBoost (Tree Based Classifier)\n",
      "---\n",
      "2025-01-09 18:08:14,619 [INFO] Model Category: Classification\n",
      "2025-01-09 18:08:14,620 [INFO] ---\n",
      "Processing Model: XGBoost (Tree Based Classifier) in 'predict' mode\n",
      "---\n",
      "2025-01-09 18:08:14,625 [INFO] ✅ Prediction input data loaded from '..\\..\\dataset\\test\\data\\final_ml_dataset.csv'.\n",
      "2025-01-09 18:08:14,626 [INFO] Starting: Final Preprocessing Pipeline in 'predict' mode.\n",
      "2025-01-09 18:08:14,626 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:14,627 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 15)\n",
      "2025-01-09 18:08:14,627 [DEBUG] Selected Features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,628 [INFO] ✅ Column filtering completed successfully.\n",
      "2025-01-09 18:08:14,628 [INFO] Step: Preprocess Predict\n",
      "2025-01-09 18:08:14,629 [DEBUG] Initial columns in prediction data: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,629 [DEBUG] Initial number of features: 15\n",
      "2025-01-09 18:08:14,630 [INFO] Step: Load Transformers\n",
      "2025-01-09 18:08:14,630 [DEBUG] Loading transformers from: ..\\transformers\\transformers.pkl\n",
      "2025-01-09 18:08:14,632 [DEBUG] Pipeline loaded. Ready to transform new data.\n",
      "2025-01-09 18:08:14,633 [INFO] Transformers loaded successfully from '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:14,633 [DEBUG] Transformers loaded successfully.\n",
      "2025-01-09 18:08:14,633 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:14,634 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 15)\n",
      "2025-01-09 18:08:14,635 [DEBUG] Selected Features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,636 [DEBUG] Columns after filtering: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,637 [DEBUG] Number of features after filtering: 15\n",
      "2025-01-09 18:08:14,638 [INFO] Step: Handle Missing Values\n",
      "2025-01-09 18:08:14,638 [DEBUG] Numerical Imputation Strategy: Median, Imputer Type: SimpleImputer\n",
      "2025-01-09 18:08:14,644 [DEBUG] Categorical Imputation Strategy: Most_frequent, Imputer Type: SimpleImputer\n",
      "2025-01-09 18:08:14,647 [DEBUG] Completed: Handle Missing Values. Dataset shape after imputation: (125, 15)\n",
      "2025-01-09 18:08:14,649 [DEBUG] Missing values after imputation in X_train:\n",
      "release_ball_direction_x                    0\n",
      "release_ball_direction_z                    0\n",
      "release_ball_direction_y                    0\n",
      "elbow_release_angle                         0\n",
      "elbow_max_angle                             0\n",
      "wrist_release_angle                         0\n",
      "wrist_max_angle                             0\n",
      "knee_release_angle                          0\n",
      "knee_max_angle                              0\n",
      "release_ball_speed                          0\n",
      "calculated_release_angle                    0\n",
      "release_ball_velocity_x                     0\n",
      "release_ball_velocity_y                     0\n",
      "release_ball_velocity_z                     0\n",
      "player_estimated_hand_length_cm_category    0\n",
      "dtype: int64\n",
      "2025-01-09 18:08:14,650 [DEBUG] New columns handled: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,651 [DEBUG] Columns after handling missing values: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,651 [DEBUG] Number of features after handling missing values: 15\n",
      "2025-01-09 18:08:14,652 [DEBUG] Expected raw features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,652 [DEBUG] Provided features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,654 [DEBUG] Reordered columns to match the pipeline's raw feature expectations.\n",
      "2025-01-09 18:08:14,658 [DEBUG] Transformed data shape: (125, 15)\n",
      "2025-01-09 18:08:14,659 [DEBUG] Derived feature names from pipeline: ['num__release_ball_direction_x', 'num__release_ball_direction_z', 'num__release_ball_direction_y', 'num__elbow_release_angle', 'num__elbow_max_angle', 'num__wrist_release_angle', 'num__wrist_max_angle', 'num__knee_release_angle', 'num__knee_max_angle', 'num__release_ball_speed', 'num__calculated_release_angle', 'num__release_ball_velocity_x', 'num__release_ball_velocity_y', 'num__release_ball_velocity_z', 'nominal__player_estimated_hand_length_cm_category_Medium']\n",
      "2025-01-09 18:08:14,660 [DEBUG] X_preprocessed_df columns: ['num__release_ball_direction_x', 'num__release_ball_direction_z', 'num__release_ball_direction_y', 'num__elbow_release_angle', 'num__elbow_max_angle', 'num__wrist_release_angle', 'num__wrist_max_angle', 'num__knee_release_angle', 'num__knee_max_angle', 'num__release_ball_speed', 'num__calculated_release_angle', 'num__release_ball_velocity_x', 'num__release_ball_velocity_y', 'num__release_ball_velocity_z', 'nominal__player_estimated_hand_length_cm_category_Medium']\n",
      "2025-01-09 18:08:14,663 [DEBUG] Sample of X_preprocessed_df:\n",
      "   num__release_ball_direction_x  num__release_ball_direction_z  \\\n",
      "0                       0.200442                       0.029218   \n",
      "1                       0.628897                      -0.731202   \n",
      "2                       0.264488                      -0.091281   \n",
      "3                      -0.695430                       0.974150   \n",
      "4                       0.336515                      -0.199535   \n",
      "\n",
      "   num__release_ball_direction_y  num__elbow_release_angle  \\\n",
      "0                       1.175516                  1.020327   \n",
      "1                      -1.071842                 -1.423048   \n",
      "2                       0.121513                  1.294261   \n",
      "3                       1.180299                  0.861899   \n",
      "4                      -0.074955                  1.247774   \n",
      "\n",
      "   num__elbow_max_angle  num__wrist_release_angle  num__wrist_max_angle  \\\n",
      "0              1.138980                  0.441979             -0.782146   \n",
      "1             -1.457654                  1.794251              0.107597   \n",
      "2              1.555476                 -0.103650              0.205150   \n",
      "3             -0.086542                 -1.139068             -0.642810   \n",
      "4             -0.277425                 -1.398682             -1.226460   \n",
      "\n",
      "   num__knee_release_angle  num__knee_max_angle  num__release_ball_speed  \\\n",
      "0                 0.644151             0.702538                -0.238583   \n",
      "1                 1.092342             1.789279                 0.873691   \n",
      "2                 0.985277             1.623802                -0.020846   \n",
      "3                -0.517249             1.299184                -0.669375   \n",
      "4                 0.723405             1.037778                 0.460286   \n",
      "\n",
      "   num__calculated_release_angle  num__release_ball_velocity_x  \\\n",
      "0                       0.346229                     -0.071285   \n",
      "1                       1.067820                      0.738698   \n",
      "2                      -0.605145                      0.066010   \n",
      "3                       0.511606                     -0.783542   \n",
      "4                      -0.394284                      0.331009   \n",
      "\n",
      "   num__release_ball_velocity_y  num__release_ball_velocity_z  \\\n",
      "0                      1.192943                     -0.245370   \n",
      "1                     -1.443174                      0.893517   \n",
      "2                      0.115574                     -0.009691   \n",
      "3                      1.192943                     -0.560063   \n",
      "4                     -0.184186                      0.546129   \n",
      "\n",
      "   nominal__player_estimated_hand_length_cm_category_Medium  \n",
      "0                                                1.0         \n",
      "1                                                1.0         \n",
      "2                                                1.0         \n",
      "3                                                1.0         \n",
      "4                                                1.0         \n",
      "2025-01-09 18:08:14,664 [DEBUG] [DEBUG] Original data shape before inverse transform: (125, 15)\n",
      "2025-01-09 18:08:14,668 [DEBUG] [DEBUG] Inversed data shape: (125, 15)\n",
      "2025-01-09 18:08:14,669 [INFO] Step: Generate Preprocessor Recommendations\n",
      "2025-01-09 18:08:14,671 [DEBUG] Preprocessing Recommendations:\n",
      "                                                           Preprocessing Reason\n",
      "player_estimated_hand_length_cm_category  Categorical: Most_frequent Imputation\n",
      "release_ball_direction_x                           Numerical: Median Imputation\n",
      "release_ball_direction_z                           Numerical: Median Imputation\n",
      "release_ball_direction_y                           Numerical: Median Imputation\n",
      "elbow_release_angle                                Numerical: Median Imputation\n",
      "elbow_max_angle                                    Numerical: Median Imputation\n",
      "wrist_release_angle                                Numerical: Median Imputation\n",
      "wrist_max_angle                                    Numerical: Median Imputation\n",
      "knee_release_angle                                 Numerical: Median Imputation\n",
      "knee_max_angle                                     Numerical: Median Imputation\n",
      "release_ball_speed                                 Numerical: Median Imputation\n",
      "calculated_release_angle                           Numerical: Median Imputation\n",
      "release_ball_velocity_x                            Numerical: Median Imputation\n",
      "release_ball_velocity_y                            Numerical: Median Imputation\n",
      "release_ball_velocity_z                            Numerical: Median Imputation\n",
      "2025-01-09 18:08:14,671 [DEBUG] Generated preprocessing recommendations.\n",
      "2025-01-09 18:08:14,672 [INFO] ✅ Preprocessing completed successfully in predict mode.\n",
      "2025-01-09 18:08:14,672 [INFO] ✅ Preprocessing completed successfully in predict mode.\n",
      "2025-01-09 18:08:14,677 [INFO] ✅ Trained model loaded from '..\\models\\XGBoost\\trained_model.pkl'.\n",
      "2025-01-09 18:08:14,683 [INFO] ✅ Predictions made successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting predict mode...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 18:08:14,685 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 18:08:14,689 [INFO] ✅ Predictions saved to '..\\..\\dataset\\test\\data\\preprocessor\\predictions\\predictions_XGBoost.csv'.\n",
      "2025-01-09 18:08:14,690 [INFO] ✅ All tasks completed successfully for model 'XGBoost'.\n",
      "2025-01-09 18:08:14,690 [INFO] ---\n",
      "Processing Model: Decision Tree (Tree Based Classifier)\n",
      "---\n",
      "2025-01-09 18:08:14,691 [INFO] Model Category: Classification\n",
      "2025-01-09 18:08:14,691 [INFO] ---\n",
      "Processing Model: Decision Tree (Tree Based Classifier) in 'predict' mode\n",
      "---\n",
      "2025-01-09 18:08:14,702 [INFO] ✅ Prediction input data loaded from '..\\..\\dataset\\test\\data\\final_ml_dataset.csv'.\n",
      "2025-01-09 18:08:14,703 [INFO] Starting: Final Preprocessing Pipeline in 'predict' mode.\n",
      "2025-01-09 18:08:14,704 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:14,705 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 15)\n",
      "2025-01-09 18:08:14,706 [DEBUG] Selected Features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,706 [INFO] ✅ Column filtering completed successfully.\n",
      "2025-01-09 18:08:14,707 [INFO] Step: Preprocess Predict\n",
      "2025-01-09 18:08:14,708 [DEBUG] Initial columns in prediction data: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,708 [DEBUG] Initial number of features: 15\n",
      "2025-01-09 18:08:14,709 [INFO] Step: Load Transformers\n",
      "2025-01-09 18:08:14,709 [DEBUG] Loading transformers from: ..\\transformers\\transformers.pkl\n",
      "2025-01-09 18:08:14,714 [DEBUG] Pipeline loaded. Ready to transform new data.\n",
      "2025-01-09 18:08:14,715 [INFO] Transformers loaded successfully from '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:14,715 [DEBUG] Transformers loaded successfully.\n",
      "2025-01-09 18:08:14,716 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:14,717 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 15)\n",
      "2025-01-09 18:08:14,718 [DEBUG] Selected Features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,718 [DEBUG] Columns after filtering: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,719 [DEBUG] Number of features after filtering: 15\n",
      "2025-01-09 18:08:14,719 [INFO] Step: Handle Missing Values\n",
      "2025-01-09 18:08:14,720 [DEBUG] Numerical Imputation Strategy: Median, Imputer Type: SimpleImputer\n",
      "2025-01-09 18:08:14,728 [DEBUG] Categorical Imputation Strategy: Most_frequent, Imputer Type: SimpleImputer\n",
      "2025-01-09 18:08:14,732 [DEBUG] Completed: Handle Missing Values. Dataset shape after imputation: (125, 15)\n",
      "2025-01-09 18:08:14,734 [DEBUG] Missing values after imputation in X_train:\n",
      "release_ball_direction_x                    0\n",
      "release_ball_direction_z                    0\n",
      "release_ball_direction_y                    0\n",
      "elbow_release_angle                         0\n",
      "elbow_max_angle                             0\n",
      "wrist_release_angle                         0\n",
      "wrist_max_angle                             0\n",
      "knee_release_angle                          0\n",
      "knee_max_angle                              0\n",
      "release_ball_speed                          0\n",
      "calculated_release_angle                    0\n",
      "release_ball_velocity_x                     0\n",
      "release_ball_velocity_y                     0\n",
      "release_ball_velocity_z                     0\n",
      "player_estimated_hand_length_cm_category    0\n",
      "dtype: int64\n",
      "2025-01-09 18:08:14,735 [DEBUG] New columns handled: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,735 [DEBUG] Columns after handling missing values: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,736 [DEBUG] Number of features after handling missing values: 15\n",
      "2025-01-09 18:08:14,736 [DEBUG] Expected raw features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,737 [DEBUG] Provided features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,739 [DEBUG] Reordered columns to match the pipeline's raw feature expectations.\n",
      "2025-01-09 18:08:14,745 [DEBUG] Transformed data shape: (125, 15)\n",
      "2025-01-09 18:08:14,746 [DEBUG] Derived feature names from pipeline: ['num__release_ball_direction_x', 'num__release_ball_direction_z', 'num__release_ball_direction_y', 'num__elbow_release_angle', 'num__elbow_max_angle', 'num__wrist_release_angle', 'num__wrist_max_angle', 'num__knee_release_angle', 'num__knee_max_angle', 'num__release_ball_speed', 'num__calculated_release_angle', 'num__release_ball_velocity_x', 'num__release_ball_velocity_y', 'num__release_ball_velocity_z', 'nominal__player_estimated_hand_length_cm_category_Medium']\n",
      "2025-01-09 18:08:14,747 [DEBUG] X_preprocessed_df columns: ['num__release_ball_direction_x', 'num__release_ball_direction_z', 'num__release_ball_direction_y', 'num__elbow_release_angle', 'num__elbow_max_angle', 'num__wrist_release_angle', 'num__wrist_max_angle', 'num__knee_release_angle', 'num__knee_max_angle', 'num__release_ball_speed', 'num__calculated_release_angle', 'num__release_ball_velocity_x', 'num__release_ball_velocity_y', 'num__release_ball_velocity_z', 'nominal__player_estimated_hand_length_cm_category_Medium']\n",
      "2025-01-09 18:08:14,752 [DEBUG] Sample of X_preprocessed_df:\n",
      "   num__release_ball_direction_x  num__release_ball_direction_z  \\\n",
      "0                       0.200442                       0.029218   \n",
      "1                       0.628897                      -0.731202   \n",
      "2                       0.264488                      -0.091281   \n",
      "3                      -0.695430                       0.974150   \n",
      "4                       0.336515                      -0.199535   \n",
      "\n",
      "   num__release_ball_direction_y  num__elbow_release_angle  \\\n",
      "0                       1.175516                  1.020327   \n",
      "1                      -1.071842                 -1.423048   \n",
      "2                       0.121513                  1.294261   \n",
      "3                       1.180299                  0.861899   \n",
      "4                      -0.074955                  1.247774   \n",
      "\n",
      "   num__elbow_max_angle  num__wrist_release_angle  num__wrist_max_angle  \\\n",
      "0              1.138980                  0.441979             -0.782146   \n",
      "1             -1.457654                  1.794251              0.107597   \n",
      "2              1.555476                 -0.103650              0.205150   \n",
      "3             -0.086542                 -1.139068             -0.642810   \n",
      "4             -0.277425                 -1.398682             -1.226460   \n",
      "\n",
      "   num__knee_release_angle  num__knee_max_angle  num__release_ball_speed  \\\n",
      "0                 0.644151             0.702538                -0.238583   \n",
      "1                 1.092342             1.789279                 0.873691   \n",
      "2                 0.985277             1.623802                -0.020846   \n",
      "3                -0.517249             1.299184                -0.669375   \n",
      "4                 0.723405             1.037778                 0.460286   \n",
      "\n",
      "   num__calculated_release_angle  num__release_ball_velocity_x  \\\n",
      "0                       0.346229                     -0.071285   \n",
      "1                       1.067820                      0.738698   \n",
      "2                      -0.605145                      0.066010   \n",
      "3                       0.511606                     -0.783542   \n",
      "4                      -0.394284                      0.331009   \n",
      "\n",
      "   num__release_ball_velocity_y  num__release_ball_velocity_z  \\\n",
      "0                      1.192943                     -0.245370   \n",
      "1                     -1.443174                      0.893517   \n",
      "2                      0.115574                     -0.009691   \n",
      "3                      1.192943                     -0.560063   \n",
      "4                     -0.184186                      0.546129   \n",
      "\n",
      "   nominal__player_estimated_hand_length_cm_category_Medium  \n",
      "0                                                1.0         \n",
      "1                                                1.0         \n",
      "2                                                1.0         \n",
      "3                                                1.0         \n",
      "4                                                1.0         \n",
      "2025-01-09 18:08:14,753 [DEBUG] [DEBUG] Original data shape before inverse transform: (125, 15)\n",
      "2025-01-09 18:08:14,760 [DEBUG] [DEBUG] Inversed data shape: (125, 15)\n",
      "2025-01-09 18:08:14,761 [INFO] Step: Generate Preprocessor Recommendations\n",
      "2025-01-09 18:08:14,763 [DEBUG] Preprocessing Recommendations:\n",
      "                                                           Preprocessing Reason\n",
      "player_estimated_hand_length_cm_category  Categorical: Most_frequent Imputation\n",
      "release_ball_direction_x                           Numerical: Median Imputation\n",
      "release_ball_direction_z                           Numerical: Median Imputation\n",
      "release_ball_direction_y                           Numerical: Median Imputation\n",
      "elbow_release_angle                                Numerical: Median Imputation\n",
      "elbow_max_angle                                    Numerical: Median Imputation\n",
      "wrist_release_angle                                Numerical: Median Imputation\n",
      "wrist_max_angle                                    Numerical: Median Imputation\n",
      "knee_release_angle                                 Numerical: Median Imputation\n",
      "knee_max_angle                                     Numerical: Median Imputation\n",
      "release_ball_speed                                 Numerical: Median Imputation\n",
      "calculated_release_angle                           Numerical: Median Imputation\n",
      "release_ball_velocity_x                            Numerical: Median Imputation\n",
      "release_ball_velocity_y                            Numerical: Median Imputation\n",
      "release_ball_velocity_z                            Numerical: Median Imputation\n",
      "2025-01-09 18:08:14,763 [DEBUG] Generated preprocessing recommendations.\n",
      "2025-01-09 18:08:14,764 [INFO] ✅ Preprocessing completed successfully in predict mode.\n",
      "2025-01-09 18:08:14,764 [INFO] ✅ Preprocessing completed successfully in predict mode.\n",
      "2025-01-09 18:08:14,767 [INFO] ✅ Trained model loaded from '..\\models\\Decision_Tree\\trained_model.pkl'.\n",
      "2025-01-09 18:08:14,769 [INFO] ✅ Predictions made successfully.\n",
      "2025-01-09 18:08:14,770 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 18:08:14,775 [INFO] ✅ Predictions saved to '..\\..\\dataset\\test\\data\\preprocessor\\predictions\\predictions_Decision_Tree.csv'.\n",
      "2025-01-09 18:08:14,776 [INFO] ✅ All tasks completed successfully for model 'Decision Tree'.\n",
      "2025-01-09 18:08:14,776 [INFO] ---\n",
      "Processing Model: Logistic Regression (Logistic Regression)\n",
      "---\n",
      "2025-01-09 18:08:14,777 [INFO] Model Category: Classification\n",
      "2025-01-09 18:08:14,778 [INFO] ---\n",
      "Processing Model: Logistic Regression (Logistic Regression) in 'predict' mode\n",
      "---\n",
      "2025-01-09 18:08:14,788 [INFO] ✅ Prediction input data loaded from '..\\..\\dataset\\test\\data\\final_ml_dataset.csv'.\n",
      "2025-01-09 18:08:14,789 [INFO] Starting: Final Preprocessing Pipeline in 'predict' mode.\n",
      "2025-01-09 18:08:14,789 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:14,790 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 15)\n",
      "2025-01-09 18:08:14,791 [DEBUG] Selected Features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,791 [INFO] ✅ Column filtering completed successfully.\n",
      "2025-01-09 18:08:14,792 [INFO] Step: Preprocess Predict\n",
      "2025-01-09 18:08:14,792 [DEBUG] Initial columns in prediction data: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,793 [DEBUG] Initial number of features: 15\n",
      "2025-01-09 18:08:14,793 [INFO] Step: Load Transformers\n",
      "2025-01-09 18:08:14,793 [DEBUG] Loading transformers from: ..\\transformers\\transformers.pkl\n",
      "2025-01-09 18:08:14,795 [DEBUG] Pipeline loaded. Ready to transform new data.\n",
      "2025-01-09 18:08:14,796 [INFO] Transformers loaded successfully from '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:14,796 [DEBUG] Transformers loaded successfully.\n",
      "2025-01-09 18:08:14,797 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:14,797 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 15)\n",
      "2025-01-09 18:08:14,797 [DEBUG] Selected Features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,798 [DEBUG] Columns after filtering: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,799 [DEBUG] Number of features after filtering: 15\n",
      "2025-01-09 18:08:14,799 [INFO] Step: Handle Missing Values\n",
      "2025-01-09 18:08:14,799 [DEBUG] Numerical Imputation Strategy: Mean, Imputer Type: SimpleImputer\n",
      "2025-01-09 18:08:14,803 [DEBUG] Categorical Imputation Strategy: Most_frequent, Imputer Type: SimpleImputer\n",
      "2025-01-09 18:08:14,804 [DEBUG] Completed: Handle Missing Values. Dataset shape after imputation: (125, 15)\n",
      "2025-01-09 18:08:14,805 [DEBUG] Missing values after imputation in X_train:\n",
      "release_ball_direction_x                    0\n",
      "release_ball_direction_z                    0\n",
      "release_ball_direction_y                    0\n",
      "elbow_release_angle                         0\n",
      "elbow_max_angle                             0\n",
      "wrist_release_angle                         0\n",
      "wrist_max_angle                             0\n",
      "knee_release_angle                          0\n",
      "knee_max_angle                              0\n",
      "release_ball_speed                          0\n",
      "calculated_release_angle                    0\n",
      "release_ball_velocity_x                     0\n",
      "release_ball_velocity_y                     0\n",
      "release_ball_velocity_z                     0\n",
      "player_estimated_hand_length_cm_category    0\n",
      "dtype: int64\n",
      "2025-01-09 18:08:14,806 [DEBUG] New columns handled: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,806 [DEBUG] Columns after handling missing values: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,807 [DEBUG] Number of features after handling missing values: 15\n",
      "2025-01-09 18:08:14,807 [DEBUG] Expected raw features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,808 [DEBUG] Provided features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,808 [DEBUG] Reordered columns to match the pipeline's raw feature expectations.\n",
      "2025-01-09 18:08:14,812 [DEBUG] Transformed data shape: (125, 15)\n",
      "2025-01-09 18:08:14,812 [DEBUG] Derived feature names from pipeline: ['num__release_ball_direction_x', 'num__release_ball_direction_z', 'num__release_ball_direction_y', 'num__elbow_release_angle', 'num__elbow_max_angle', 'num__wrist_release_angle', 'num__wrist_max_angle', 'num__knee_release_angle', 'num__knee_max_angle', 'num__release_ball_speed', 'num__calculated_release_angle', 'num__release_ball_velocity_x', 'num__release_ball_velocity_y', 'num__release_ball_velocity_z', 'nominal__player_estimated_hand_length_cm_category_Medium']\n",
      "2025-01-09 18:08:14,813 [DEBUG] X_preprocessed_df columns: ['num__release_ball_direction_x', 'num__release_ball_direction_z', 'num__release_ball_direction_y', 'num__elbow_release_angle', 'num__elbow_max_angle', 'num__wrist_release_angle', 'num__wrist_max_angle', 'num__knee_release_angle', 'num__knee_max_angle', 'num__release_ball_speed', 'num__calculated_release_angle', 'num__release_ball_velocity_x', 'num__release_ball_velocity_y', 'num__release_ball_velocity_z', 'nominal__player_estimated_hand_length_cm_category_Medium']\n",
      "2025-01-09 18:08:14,817 [DEBUG] Sample of X_preprocessed_df:\n",
      "   num__release_ball_direction_x  num__release_ball_direction_z  \\\n",
      "0                       0.200442                       0.029218   \n",
      "1                       0.628897                      -0.731202   \n",
      "2                       0.264488                      -0.091281   \n",
      "3                      -0.695430                       0.974150   \n",
      "4                       0.336515                      -0.199535   \n",
      "\n",
      "   num__release_ball_direction_y  num__elbow_release_angle  \\\n",
      "0                       1.175516                  1.020327   \n",
      "1                      -1.071842                 -1.423048   \n",
      "2                       0.121513                  1.294261   \n",
      "3                       1.180299                  0.861899   \n",
      "4                      -0.074955                  1.247774   \n",
      "\n",
      "   num__elbow_max_angle  num__wrist_release_angle  num__wrist_max_angle  \\\n",
      "0              1.138980                  0.441979             -0.782146   \n",
      "1             -1.457654                  1.794251              0.107597   \n",
      "2              1.555476                 -0.103650              0.205150   \n",
      "3             -0.086542                 -1.139068             -0.642810   \n",
      "4             -0.277425                 -1.398682             -1.226460   \n",
      "\n",
      "   num__knee_release_angle  num__knee_max_angle  num__release_ball_speed  \\\n",
      "0                 0.644151             0.702538                -0.238583   \n",
      "1                 1.092342             1.789279                 0.873691   \n",
      "2                 0.985277             1.623802                -0.020846   \n",
      "3                -0.517249             1.299184                -0.669375   \n",
      "4                 0.723405             1.037778                 0.460286   \n",
      "\n",
      "   num__calculated_release_angle  num__release_ball_velocity_x  \\\n",
      "0                       0.346229                     -0.071285   \n",
      "1                       1.067820                      0.738698   \n",
      "2                      -0.605145                      0.066010   \n",
      "3                       0.511606                     -0.783542   \n",
      "4                      -0.394284                      0.331009   \n",
      "\n",
      "   num__release_ball_velocity_y  num__release_ball_velocity_z  \\\n",
      "0                      1.192943                     -0.245370   \n",
      "1                     -1.443174                      0.893517   \n",
      "2                      0.115574                     -0.009691   \n",
      "3                      1.192943                     -0.560063   \n",
      "4                     -0.184186                      0.546129   \n",
      "\n",
      "   nominal__player_estimated_hand_length_cm_category_Medium  \n",
      "0                                                1.0         \n",
      "1                                                1.0         \n",
      "2                                                1.0         \n",
      "3                                                1.0         \n",
      "4                                                1.0         \n",
      "2025-01-09 18:08:14,817 [DEBUG] [DEBUG] Original data shape before inverse transform: (125, 15)\n",
      "2025-01-09 18:08:14,821 [DEBUG] [DEBUG] Inversed data shape: (125, 15)\n",
      "2025-01-09 18:08:14,822 [INFO] Step: Generate Preprocessor Recommendations\n",
      "2025-01-09 18:08:14,824 [DEBUG] Preprocessing Recommendations:\n",
      "                                                           Preprocessing Reason\n",
      "player_estimated_hand_length_cm_category  Categorical: Most_frequent Imputation\n",
      "release_ball_direction_x                             Numerical: Mean Imputation\n",
      "release_ball_direction_z                             Numerical: Mean Imputation\n",
      "release_ball_direction_y                             Numerical: Mean Imputation\n",
      "elbow_release_angle                                  Numerical: Mean Imputation\n",
      "elbow_max_angle                                      Numerical: Mean Imputation\n",
      "wrist_release_angle                                  Numerical: Mean Imputation\n",
      "wrist_max_angle                                      Numerical: Mean Imputation\n",
      "knee_release_angle                                   Numerical: Mean Imputation\n",
      "knee_max_angle                                       Numerical: Mean Imputation\n",
      "release_ball_speed                                   Numerical: Mean Imputation\n",
      "calculated_release_angle                             Numerical: Mean Imputation\n",
      "release_ball_velocity_x                              Numerical: Mean Imputation\n",
      "release_ball_velocity_y                              Numerical: Mean Imputation\n",
      "release_ball_velocity_z                              Numerical: Mean Imputation\n",
      "2025-01-09 18:08:14,825 [DEBUG] Generated preprocessing recommendations.\n",
      "2025-01-09 18:08:14,825 [INFO] ✅ Preprocessing completed successfully in predict mode.\n",
      "2025-01-09 18:08:14,826 [INFO] ✅ Preprocessing completed successfully in predict mode.\n",
      "2025-01-09 18:08:14,828 [INFO] ✅ Trained model loaded from '..\\models\\Logistic_Regression\\trained_model.pkl'.\n",
      "2025-01-09 18:08:14,829 [INFO] ✅ Predictions made successfully.\n",
      "2025-01-09 18:08:14,830 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 18:08:14,835 [INFO] ✅ Predictions saved to '..\\..\\dataset\\test\\data\\preprocessor\\predictions\\predictions_Logistic_Regression.csv'.\n",
      "2025-01-09 18:08:14,836 [INFO] ✅ All tasks completed successfully for model 'Logistic Regression'.\n",
      "2025-01-09 18:08:14,837 [INFO] ---\n",
      "Processing Model: K-Means (K-Means)\n",
      "---\n",
      "2025-01-09 18:08:14,837 [INFO] Model Category: Clustering\n",
      "2025-01-09 18:08:14,838 [INFO] Skipping clustering type K-Means in 'predict' mode.\n",
      "2025-01-09 18:08:14,839 [INFO] ---\n",
      "Processing Model: Linear Regression (Linear Regression)\n",
      "---\n",
      "2025-01-09 18:08:14,839 [INFO] Model Category: Regression\n",
      "2025-01-09 18:08:14,840 [INFO] ---\n",
      "Processing Model: Linear Regression (Linear Regression) in 'predict' mode\n",
      "---\n",
      "2025-01-09 18:08:14,846 [INFO] ✅ Prediction input data loaded from '..\\..\\dataset\\test\\data\\final_ml_dataset.csv'.\n",
      "2025-01-09 18:08:14,846 [INFO] Starting: Final Preprocessing Pipeline in 'predict' mode.\n",
      "2025-01-09 18:08:14,847 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:14,848 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 15)\n",
      "2025-01-09 18:08:14,848 [DEBUG] Selected Features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,849 [INFO] ✅ Column filtering completed successfully.\n",
      "2025-01-09 18:08:14,849 [INFO] Step: Preprocess Predict\n",
      "2025-01-09 18:08:14,850 [DEBUG] Initial columns in prediction data: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,850 [DEBUG] Initial number of features: 15\n",
      "2025-01-09 18:08:14,850 [INFO] Step: Load Transformers\n",
      "2025-01-09 18:08:14,851 [DEBUG] Loading transformers from: ..\\transformers\\transformers.pkl\n",
      "2025-01-09 18:08:14,854 [DEBUG] Pipeline loaded. Ready to transform new data.\n",
      "2025-01-09 18:08:14,855 [INFO] Transformers loaded successfully from '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:14,855 [DEBUG] Transformers loaded successfully.\n",
      "2025-01-09 18:08:14,855 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:14,856 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 15)\n",
      "2025-01-09 18:08:14,856 [DEBUG] Selected Features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,857 [DEBUG] Columns after filtering: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,857 [DEBUG] Number of features after filtering: 15\n",
      "2025-01-09 18:08:14,858 [INFO] Step: Handle Missing Values\n",
      "2025-01-09 18:08:14,858 [DEBUG] Numerical Imputation Strategy: Mean, Imputer Type: SimpleImputer\n",
      "2025-01-09 18:08:14,861 [DEBUG] Categorical Imputation Strategy: Most_frequent, Imputer Type: SimpleImputer\n",
      "2025-01-09 18:08:14,863 [DEBUG] Completed: Handle Missing Values. Dataset shape after imputation: (125, 15)\n",
      "2025-01-09 18:08:14,864 [DEBUG] Missing values after imputation in X_train:\n",
      "release_ball_direction_x                    0\n",
      "release_ball_direction_z                    0\n",
      "release_ball_direction_y                    0\n",
      "elbow_release_angle                         0\n",
      "elbow_max_angle                             0\n",
      "wrist_release_angle                         0\n",
      "wrist_max_angle                             0\n",
      "knee_release_angle                          0\n",
      "knee_max_angle                              0\n",
      "release_ball_speed                          0\n",
      "calculated_release_angle                    0\n",
      "release_ball_velocity_x                     0\n",
      "release_ball_velocity_y                     0\n",
      "release_ball_velocity_z                     0\n",
      "player_estimated_hand_length_cm_category    0\n",
      "dtype: int64\n",
      "2025-01-09 18:08:14,865 [DEBUG] New columns handled: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,865 [DEBUG] Columns after handling missing values: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,865 [DEBUG] Number of features after handling missing values: 15\n",
      "2025-01-09 18:08:14,866 [DEBUG] Expected raw features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,866 [DEBUG] Provided features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,868 [DEBUG] Reordered columns to match the pipeline's raw feature expectations.\n",
      "2025-01-09 18:08:14,871 [DEBUG] Transformed data shape: (125, 15)\n",
      "2025-01-09 18:08:14,871 [DEBUG] Derived feature names from pipeline: ['num__release_ball_direction_x', 'num__release_ball_direction_z', 'num__release_ball_direction_y', 'num__elbow_release_angle', 'num__elbow_max_angle', 'num__wrist_release_angle', 'num__wrist_max_angle', 'num__knee_release_angle', 'num__knee_max_angle', 'num__release_ball_speed', 'num__calculated_release_angle', 'num__release_ball_velocity_x', 'num__release_ball_velocity_y', 'num__release_ball_velocity_z', 'nominal__player_estimated_hand_length_cm_category_Medium']\n",
      "2025-01-09 18:08:14,872 [DEBUG] X_preprocessed_df columns: ['num__release_ball_direction_x', 'num__release_ball_direction_z', 'num__release_ball_direction_y', 'num__elbow_release_angle', 'num__elbow_max_angle', 'num__wrist_release_angle', 'num__wrist_max_angle', 'num__knee_release_angle', 'num__knee_max_angle', 'num__release_ball_speed', 'num__calculated_release_angle', 'num__release_ball_velocity_x', 'num__release_ball_velocity_y', 'num__release_ball_velocity_z', 'nominal__player_estimated_hand_length_cm_category_Medium']\n",
      "2025-01-09 18:08:14,874 [DEBUG] Sample of X_preprocessed_df:\n",
      "   num__release_ball_direction_x  num__release_ball_direction_z  \\\n",
      "0                       0.200442                       0.029218   \n",
      "1                       0.628897                      -0.731202   \n",
      "2                       0.264488                      -0.091281   \n",
      "3                      -0.695430                       0.974150   \n",
      "4                       0.336515                      -0.199535   \n",
      "\n",
      "   num__release_ball_direction_y  num__elbow_release_angle  \\\n",
      "0                       1.175516                  1.020327   \n",
      "1                      -1.071842                 -1.423048   \n",
      "2                       0.121513                  1.294261   \n",
      "3                       1.180299                  0.861899   \n",
      "4                      -0.074955                  1.247774   \n",
      "\n",
      "   num__elbow_max_angle  num__wrist_release_angle  num__wrist_max_angle  \\\n",
      "0              1.138980                  0.441979             -0.782146   \n",
      "1             -1.457654                  1.794251              0.107597   \n",
      "2              1.555476                 -0.103650              0.205150   \n",
      "3             -0.086542                 -1.139068             -0.642810   \n",
      "4             -0.277425                 -1.398682             -1.226460   \n",
      "\n",
      "   num__knee_release_angle  num__knee_max_angle  num__release_ball_speed  \\\n",
      "0                 0.644151             0.702538                -0.238583   \n",
      "1                 1.092342             1.789279                 0.873691   \n",
      "2                 0.985277             1.623802                -0.020846   \n",
      "3                -0.517249             1.299184                -0.669375   \n",
      "4                 0.723405             1.037778                 0.460286   \n",
      "\n",
      "   num__calculated_release_angle  num__release_ball_velocity_x  \\\n",
      "0                       0.346229                     -0.071285   \n",
      "1                       1.067820                      0.738698   \n",
      "2                      -0.605145                      0.066010   \n",
      "3                       0.511606                     -0.783542   \n",
      "4                      -0.394284                      0.331009   \n",
      "\n",
      "   num__release_ball_velocity_y  num__release_ball_velocity_z  \\\n",
      "0                      1.192943                     -0.245370   \n",
      "1                     -1.443174                      0.893517   \n",
      "2                      0.115574                     -0.009691   \n",
      "3                      1.192943                     -0.560063   \n",
      "4                     -0.184186                      0.546129   \n",
      "\n",
      "   nominal__player_estimated_hand_length_cm_category_Medium  \n",
      "0                                                1.0         \n",
      "1                                                1.0         \n",
      "2                                                1.0         \n",
      "3                                                1.0         \n",
      "4                                                1.0         \n",
      "2025-01-09 18:08:14,875 [DEBUG] [DEBUG] Original data shape before inverse transform: (125, 15)\n",
      "2025-01-09 18:08:14,878 [DEBUG] [DEBUG] Inversed data shape: (125, 15)\n",
      "2025-01-09 18:08:14,879 [INFO] Step: Generate Preprocessor Recommendations\n",
      "2025-01-09 18:08:14,880 [DEBUG] Preprocessing Recommendations:\n",
      "                                                           Preprocessing Reason\n",
      "player_estimated_hand_length_cm_category  Categorical: Most_frequent Imputation\n",
      "release_ball_direction_x                             Numerical: Mean Imputation\n",
      "release_ball_direction_z                             Numerical: Mean Imputation\n",
      "release_ball_direction_y                             Numerical: Mean Imputation\n",
      "elbow_release_angle                                  Numerical: Mean Imputation\n",
      "elbow_max_angle                                      Numerical: Mean Imputation\n",
      "wrist_release_angle                                  Numerical: Mean Imputation\n",
      "wrist_max_angle                                      Numerical: Mean Imputation\n",
      "knee_release_angle                                   Numerical: Mean Imputation\n",
      "knee_max_angle                                       Numerical: Mean Imputation\n",
      "release_ball_speed                                   Numerical: Mean Imputation\n",
      "calculated_release_angle                             Numerical: Mean Imputation\n",
      "release_ball_velocity_x                              Numerical: Mean Imputation\n",
      "release_ball_velocity_y                              Numerical: Mean Imputation\n",
      "release_ball_velocity_z                              Numerical: Mean Imputation\n",
      "2025-01-09 18:08:14,880 [DEBUG] Generated preprocessing recommendations.\n",
      "2025-01-09 18:08:14,881 [INFO] ✅ Preprocessing completed successfully in predict mode.\n",
      "2025-01-09 18:08:14,881 [INFO] ✅ Preprocessing completed successfully in predict mode.\n",
      "2025-01-09 18:08:14,882 [INFO] ✅ Trained model loaded from '..\\models\\Linear_Regression\\trained_model.pkl'.\n",
      "2025-01-09 18:08:14,883 [INFO] ✅ Predictions made successfully.\n",
      "2025-01-09 18:08:14,884 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 18:08:14,887 [INFO] ✅ Predictions saved to '..\\..\\dataset\\test\\data\\preprocessor\\predictions\\predictions_Linear_Regression.csv'.\n",
      "2025-01-09 18:08:14,887 [INFO] ✅ All tasks completed successfully for model 'Linear Regression'.\n",
      "2025-01-09 18:08:14,887 [INFO] ---\n",
      "Processing Model: Random Forest Regressor (Tree Based Regressor)\n",
      "---\n",
      "2025-01-09 18:08:14,888 [INFO] Model Category: Regression\n",
      "2025-01-09 18:08:14,889 [INFO] ---\n",
      "Processing Model: Random Forest Regressor (Tree Based Regressor) in 'predict' mode\n",
      "---\n",
      "2025-01-09 18:08:14,894 [INFO] ✅ Prediction input data loaded from '..\\..\\dataset\\test\\data\\final_ml_dataset.csv'.\n",
      "2025-01-09 18:08:14,894 [INFO] Starting: Final Preprocessing Pipeline in 'predict' mode.\n",
      "2025-01-09 18:08:14,895 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:14,895 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 15)\n",
      "2025-01-09 18:08:14,896 [DEBUG] Selected Features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,896 [INFO] ✅ Column filtering completed successfully.\n",
      "2025-01-09 18:08:14,897 [INFO] Step: Preprocess Predict\n",
      "2025-01-09 18:08:14,897 [DEBUG] Initial columns in prediction data: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,897 [DEBUG] Initial number of features: 15\n",
      "2025-01-09 18:08:14,898 [INFO] Step: Load Transformers\n",
      "2025-01-09 18:08:14,899 [DEBUG] Loading transformers from: ..\\transformers\\transformers.pkl\n",
      "2025-01-09 18:08:14,901 [DEBUG] Pipeline loaded. Ready to transform new data.\n",
      "2025-01-09 18:08:14,902 [INFO] Transformers loaded successfully from '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:14,902 [DEBUG] Transformers loaded successfully.\n",
      "2025-01-09 18:08:14,902 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:14,903 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 15)\n",
      "2025-01-09 18:08:14,903 [DEBUG] Selected Features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,904 [DEBUG] Columns after filtering: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,904 [DEBUG] Number of features after filtering: 15\n",
      "2025-01-09 18:08:14,905 [INFO] Step: Handle Missing Values\n",
      "2025-01-09 18:08:14,905 [DEBUG] Numerical Imputation Strategy: Median, Imputer Type: SimpleImputer\n",
      "2025-01-09 18:08:14,909 [DEBUG] Categorical Imputation Strategy: Most_frequent, Imputer Type: SimpleImputer\n",
      "2025-01-09 18:08:14,911 [DEBUG] Completed: Handle Missing Values. Dataset shape after imputation: (125, 15)\n",
      "2025-01-09 18:08:14,912 [DEBUG] Missing values after imputation in X_train:\n",
      "release_ball_direction_x                    0\n",
      "release_ball_direction_z                    0\n",
      "release_ball_direction_y                    0\n",
      "elbow_release_angle                         0\n",
      "elbow_max_angle                             0\n",
      "wrist_release_angle                         0\n",
      "wrist_max_angle                             0\n",
      "knee_release_angle                          0\n",
      "knee_max_angle                              0\n",
      "release_ball_speed                          0\n",
      "calculated_release_angle                    0\n",
      "release_ball_velocity_x                     0\n",
      "release_ball_velocity_y                     0\n",
      "release_ball_velocity_z                     0\n",
      "player_estimated_hand_length_cm_category    0\n",
      "dtype: int64\n",
      "2025-01-09 18:08:14,913 [DEBUG] New columns handled: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,913 [DEBUG] Columns after handling missing values: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,913 [DEBUG] Number of features after handling missing values: 15\n",
      "2025-01-09 18:08:14,914 [DEBUG] Expected raw features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,914 [DEBUG] Provided features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,915 [DEBUG] Reordered columns to match the pipeline's raw feature expectations.\n",
      "2025-01-09 18:08:14,919 [DEBUG] Transformed data shape: (125, 15)\n",
      "2025-01-09 18:08:14,920 [DEBUG] Derived feature names from pipeline: ['num__release_ball_direction_x', 'num__release_ball_direction_z', 'num__release_ball_direction_y', 'num__elbow_release_angle', 'num__elbow_max_angle', 'num__wrist_release_angle', 'num__wrist_max_angle', 'num__knee_release_angle', 'num__knee_max_angle', 'num__release_ball_speed', 'num__calculated_release_angle', 'num__release_ball_velocity_x', 'num__release_ball_velocity_y', 'num__release_ball_velocity_z', 'nominal__player_estimated_hand_length_cm_category_Medium']\n",
      "2025-01-09 18:08:14,920 [DEBUG] X_preprocessed_df columns: ['num__release_ball_direction_x', 'num__release_ball_direction_z', 'num__release_ball_direction_y', 'num__elbow_release_angle', 'num__elbow_max_angle', 'num__wrist_release_angle', 'num__wrist_max_angle', 'num__knee_release_angle', 'num__knee_max_angle', 'num__release_ball_speed', 'num__calculated_release_angle', 'num__release_ball_velocity_x', 'num__release_ball_velocity_y', 'num__release_ball_velocity_z', 'nominal__player_estimated_hand_length_cm_category_Medium']\n",
      "2025-01-09 18:08:14,924 [DEBUG] Sample of X_preprocessed_df:\n",
      "   num__release_ball_direction_x  num__release_ball_direction_z  \\\n",
      "0                       0.200442                       0.029218   \n",
      "1                       0.628897                      -0.731202   \n",
      "2                       0.264488                      -0.091281   \n",
      "3                      -0.695430                       0.974150   \n",
      "4                       0.336515                      -0.199535   \n",
      "\n",
      "   num__release_ball_direction_y  num__elbow_release_angle  \\\n",
      "0                       1.175516                  1.020327   \n",
      "1                      -1.071842                 -1.423048   \n",
      "2                       0.121513                  1.294261   \n",
      "3                       1.180299                  0.861899   \n",
      "4                      -0.074955                  1.247774   \n",
      "\n",
      "   num__elbow_max_angle  num__wrist_release_angle  num__wrist_max_angle  \\\n",
      "0              1.138980                  0.441979             -0.782146   \n",
      "1             -1.457654                  1.794251              0.107597   \n",
      "2              1.555476                 -0.103650              0.205150   \n",
      "3             -0.086542                 -1.139068             -0.642810   \n",
      "4             -0.277425                 -1.398682             -1.226460   \n",
      "\n",
      "   num__knee_release_angle  num__knee_max_angle  num__release_ball_speed  \\\n",
      "0                 0.644151             0.702538                -0.238583   \n",
      "1                 1.092342             1.789279                 0.873691   \n",
      "2                 0.985277             1.623802                -0.020846   \n",
      "3                -0.517249             1.299184                -0.669375   \n",
      "4                 0.723405             1.037778                 0.460286   \n",
      "\n",
      "   num__calculated_release_angle  num__release_ball_velocity_x  \\\n",
      "0                       0.346229                     -0.071285   \n",
      "1                       1.067820                      0.738698   \n",
      "2                      -0.605145                      0.066010   \n",
      "3                       0.511606                     -0.783542   \n",
      "4                      -0.394284                      0.331009   \n",
      "\n",
      "   num__release_ball_velocity_y  num__release_ball_velocity_z  \\\n",
      "0                      1.192943                     -0.245370   \n",
      "1                     -1.443174                      0.893517   \n",
      "2                      0.115574                     -0.009691   \n",
      "3                      1.192943                     -0.560063   \n",
      "4                     -0.184186                      0.546129   \n",
      "\n",
      "   nominal__player_estimated_hand_length_cm_category_Medium  \n",
      "0                                                1.0         \n",
      "1                                                1.0         \n",
      "2                                                1.0         \n",
      "3                                                1.0         \n",
      "4                                                1.0         \n",
      "2025-01-09 18:08:14,925 [DEBUG] [DEBUG] Original data shape before inverse transform: (125, 15)\n",
      "2025-01-09 18:08:14,930 [DEBUG] [DEBUG] Inversed data shape: (125, 15)\n",
      "2025-01-09 18:08:14,931 [INFO] Step: Generate Preprocessor Recommendations\n",
      "2025-01-09 18:08:14,932 [DEBUG] Preprocessing Recommendations:\n",
      "                                                           Preprocessing Reason\n",
      "player_estimated_hand_length_cm_category  Categorical: Most_frequent Imputation\n",
      "release_ball_direction_x                           Numerical: Median Imputation\n",
      "release_ball_direction_z                           Numerical: Median Imputation\n",
      "release_ball_direction_y                           Numerical: Median Imputation\n",
      "elbow_release_angle                                Numerical: Median Imputation\n",
      "elbow_max_angle                                    Numerical: Median Imputation\n",
      "wrist_release_angle                                Numerical: Median Imputation\n",
      "wrist_max_angle                                    Numerical: Median Imputation\n",
      "knee_release_angle                                 Numerical: Median Imputation\n",
      "knee_max_angle                                     Numerical: Median Imputation\n",
      "release_ball_speed                                 Numerical: Median Imputation\n",
      "calculated_release_angle                           Numerical: Median Imputation\n",
      "release_ball_velocity_x                            Numerical: Median Imputation\n",
      "release_ball_velocity_y                            Numerical: Median Imputation\n",
      "release_ball_velocity_z                            Numerical: Median Imputation\n",
      "2025-01-09 18:08:14,933 [DEBUG] Generated preprocessing recommendations.\n",
      "2025-01-09 18:08:14,933 [INFO] ✅ Preprocessing completed successfully in predict mode.\n",
      "2025-01-09 18:08:14,933 [INFO] ✅ Preprocessing completed successfully in predict mode.\n",
      "2025-01-09 18:08:14,947 [INFO] ✅ Trained model loaded from '..\\models\\Random_Forest_Regressor\\trained_model.pkl'.\n",
      "2025-01-09 18:08:14,970 [INFO] ✅ Predictions made successfully.\n",
      "2025-01-09 18:08:14,971 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 18:08:14,974 [INFO] ✅ Predictions saved to '..\\..\\dataset\\test\\data\\preprocessor\\predictions\\predictions_Random_Forest_Regressor.csv'.\n",
      "2025-01-09 18:08:14,975 [INFO] ✅ All tasks completed successfully for model 'Random Forest Regressor'.\n",
      "2025-01-09 18:08:14,975 [INFO] ---\n",
      "Processing Model: XGBoost Regressor (Tree Based Regressor)\n",
      "---\n",
      "2025-01-09 18:08:14,976 [INFO] Model Category: Regression\n",
      "2025-01-09 18:08:14,976 [INFO] ---\n",
      "Processing Model: XGBoost Regressor (Tree Based Regressor) in 'predict' mode\n",
      "---\n",
      "2025-01-09 18:08:14,982 [INFO] ✅ Prediction input data loaded from '..\\..\\dataset\\test\\data\\final_ml_dataset.csv'.\n",
      "2025-01-09 18:08:14,982 [INFO] Starting: Final Preprocessing Pipeline in 'predict' mode.\n",
      "2025-01-09 18:08:14,983 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:14,983 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 15)\n",
      "2025-01-09 18:08:14,984 [DEBUG] Selected Features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,984 [INFO] ✅ Column filtering completed successfully.\n",
      "2025-01-09 18:08:14,985 [INFO] Step: Preprocess Predict\n",
      "2025-01-09 18:08:14,985 [DEBUG] Initial columns in prediction data: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,986 [DEBUG] Initial number of features: 15\n",
      "2025-01-09 18:08:14,986 [INFO] Step: Load Transformers\n",
      "2025-01-09 18:08:14,987 [DEBUG] Loading transformers from: ..\\transformers\\transformers.pkl\n",
      "2025-01-09 18:08:14,989 [DEBUG] Pipeline loaded. Ready to transform new data.\n",
      "2025-01-09 18:08:14,989 [INFO] Transformers loaded successfully from '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:14,990 [DEBUG] Transformers loaded successfully.\n",
      "2025-01-09 18:08:14,990 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:14,991 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 15)\n",
      "2025-01-09 18:08:14,991 [DEBUG] Selected Features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,992 [DEBUG] Columns after filtering: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:14,992 [DEBUG] Number of features after filtering: 15\n",
      "2025-01-09 18:08:14,993 [INFO] Step: Handle Missing Values\n",
      "2025-01-09 18:08:14,993 [DEBUG] Numerical Imputation Strategy: Median, Imputer Type: SimpleImputer\n",
      "2025-01-09 18:08:14,996 [DEBUG] Categorical Imputation Strategy: Most_frequent, Imputer Type: SimpleImputer\n",
      "2025-01-09 18:08:14,998 [DEBUG] Completed: Handle Missing Values. Dataset shape after imputation: (125, 15)\n",
      "2025-01-09 18:08:14,999 [DEBUG] Missing values after imputation in X_train:\n",
      "release_ball_direction_x                    0\n",
      "release_ball_direction_z                    0\n",
      "release_ball_direction_y                    0\n",
      "elbow_release_angle                         0\n",
      "elbow_max_angle                             0\n",
      "wrist_release_angle                         0\n",
      "wrist_max_angle                             0\n",
      "knee_release_angle                          0\n",
      "knee_max_angle                              0\n",
      "release_ball_speed                          0\n",
      "calculated_release_angle                    0\n",
      "release_ball_velocity_x                     0\n",
      "release_ball_velocity_y                     0\n",
      "release_ball_velocity_z                     0\n",
      "player_estimated_hand_length_cm_category    0\n",
      "dtype: int64\n",
      "2025-01-09 18:08:15,000 [DEBUG] New columns handled: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:15,000 [DEBUG] Columns after handling missing values: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:15,001 [DEBUG] Number of features after handling missing values: 15\n",
      "2025-01-09 18:08:15,001 [DEBUG] Expected raw features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:15,002 [DEBUG] Provided features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:15,002 [DEBUG] Reordered columns to match the pipeline's raw feature expectations.\n",
      "2025-01-09 18:08:15,006 [DEBUG] Transformed data shape: (125, 15)\n",
      "2025-01-09 18:08:15,006 [DEBUG] Derived feature names from pipeline: ['num__release_ball_direction_x', 'num__release_ball_direction_z', 'num__release_ball_direction_y', 'num__elbow_release_angle', 'num__elbow_max_angle', 'num__wrist_release_angle', 'num__wrist_max_angle', 'num__knee_release_angle', 'num__knee_max_angle', 'num__release_ball_speed', 'num__calculated_release_angle', 'num__release_ball_velocity_x', 'num__release_ball_velocity_y', 'num__release_ball_velocity_z', 'nominal__player_estimated_hand_length_cm_category_Medium']\n",
      "2025-01-09 18:08:15,007 [DEBUG] X_preprocessed_df columns: ['num__release_ball_direction_x', 'num__release_ball_direction_z', 'num__release_ball_direction_y', 'num__elbow_release_angle', 'num__elbow_max_angle', 'num__wrist_release_angle', 'num__wrist_max_angle', 'num__knee_release_angle', 'num__knee_max_angle', 'num__release_ball_speed', 'num__calculated_release_angle', 'num__release_ball_velocity_x', 'num__release_ball_velocity_y', 'num__release_ball_velocity_z', 'nominal__player_estimated_hand_length_cm_category_Medium']\n",
      "2025-01-09 18:08:15,010 [DEBUG] Sample of X_preprocessed_df:\n",
      "   num__release_ball_direction_x  num__release_ball_direction_z  \\\n",
      "0                       0.200442                       0.029218   \n",
      "1                       0.628897                      -0.731202   \n",
      "2                       0.264488                      -0.091281   \n",
      "3                      -0.695430                       0.974150   \n",
      "4                       0.336515                      -0.199535   \n",
      "\n",
      "   num__release_ball_direction_y  num__elbow_release_angle  \\\n",
      "0                       1.175516                  1.020327   \n",
      "1                      -1.071842                 -1.423048   \n",
      "2                       0.121513                  1.294261   \n",
      "3                       1.180299                  0.861899   \n",
      "4                      -0.074955                  1.247774   \n",
      "\n",
      "   num__elbow_max_angle  num__wrist_release_angle  num__wrist_max_angle  \\\n",
      "0              1.138980                  0.441979             -0.782146   \n",
      "1             -1.457654                  1.794251              0.107597   \n",
      "2              1.555476                 -0.103650              0.205150   \n",
      "3             -0.086542                 -1.139068             -0.642810   \n",
      "4             -0.277425                 -1.398682             -1.226460   \n",
      "\n",
      "   num__knee_release_angle  num__knee_max_angle  num__release_ball_speed  \\\n",
      "0                 0.644151             0.702538                -0.238583   \n",
      "1                 1.092342             1.789279                 0.873691   \n",
      "2                 0.985277             1.623802                -0.020846   \n",
      "3                -0.517249             1.299184                -0.669375   \n",
      "4                 0.723405             1.037778                 0.460286   \n",
      "\n",
      "   num__calculated_release_angle  num__release_ball_velocity_x  \\\n",
      "0                       0.346229                     -0.071285   \n",
      "1                       1.067820                      0.738698   \n",
      "2                      -0.605145                      0.066010   \n",
      "3                       0.511606                     -0.783542   \n",
      "4                      -0.394284                      0.331009   \n",
      "\n",
      "   num__release_ball_velocity_y  num__release_ball_velocity_z  \\\n",
      "0                      1.192943                     -0.245370   \n",
      "1                     -1.443174                      0.893517   \n",
      "2                      0.115574                     -0.009691   \n",
      "3                      1.192943                     -0.560063   \n",
      "4                     -0.184186                      0.546129   \n",
      "\n",
      "   nominal__player_estimated_hand_length_cm_category_Medium  \n",
      "0                                                1.0         \n",
      "1                                                1.0         \n",
      "2                                                1.0         \n",
      "3                                                1.0         \n",
      "4                                                1.0         \n",
      "2025-01-09 18:08:15,010 [DEBUG] [DEBUG] Original data shape before inverse transform: (125, 15)\n",
      "2025-01-09 18:08:15,013 [DEBUG] [DEBUG] Inversed data shape: (125, 15)\n",
      "2025-01-09 18:08:15,014 [INFO] Step: Generate Preprocessor Recommendations\n",
      "2025-01-09 18:08:15,015 [DEBUG] Preprocessing Recommendations:\n",
      "                                                           Preprocessing Reason\n",
      "player_estimated_hand_length_cm_category  Categorical: Most_frequent Imputation\n",
      "release_ball_direction_x                           Numerical: Median Imputation\n",
      "release_ball_direction_z                           Numerical: Median Imputation\n",
      "release_ball_direction_y                           Numerical: Median Imputation\n",
      "elbow_release_angle                                Numerical: Median Imputation\n",
      "elbow_max_angle                                    Numerical: Median Imputation\n",
      "wrist_release_angle                                Numerical: Median Imputation\n",
      "wrist_max_angle                                    Numerical: Median Imputation\n",
      "knee_release_angle                                 Numerical: Median Imputation\n",
      "knee_max_angle                                     Numerical: Median Imputation\n",
      "release_ball_speed                                 Numerical: Median Imputation\n",
      "calculated_release_angle                           Numerical: Median Imputation\n",
      "release_ball_velocity_x                            Numerical: Median Imputation\n",
      "release_ball_velocity_y                            Numerical: Median Imputation\n",
      "release_ball_velocity_z                            Numerical: Median Imputation\n",
      "2025-01-09 18:08:15,016 [DEBUG] Generated preprocessing recommendations.\n",
      "2025-01-09 18:08:15,017 [INFO] ✅ Preprocessing completed successfully in predict mode.\n",
      "2025-01-09 18:08:15,017 [INFO] ✅ Preprocessing completed successfully in predict mode.\n",
      "2025-01-09 18:08:15,021 [INFO] ✅ Trained model loaded from '..\\models\\XGBoost_Regressor\\trained_model.pkl'.\n",
      "2025-01-09 18:08:15,028 [INFO] ✅ Predictions made successfully.\n",
      "2025-01-09 18:08:15,029 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 18:08:15,034 [INFO] ✅ Predictions saved to '..\\..\\dataset\\test\\data\\preprocessor\\predictions\\predictions_XGBoost_Regressor.csv'.\n",
      "2025-01-09 18:08:15,034 [INFO] ✅ All tasks completed successfully for model 'XGBoost Regressor'.\n",
      "2025-01-09 18:08:15,035 [INFO] ---\n",
      "Processing Model: Decision Tree Regressor (Tree Based Regressor)\n",
      "---\n",
      "2025-01-09 18:08:15,036 [INFO] Model Category: Regression\n",
      "2025-01-09 18:08:15,037 [INFO] ---\n",
      "Processing Model: Decision Tree Regressor (Tree Based Regressor) in 'predict' mode\n",
      "---\n",
      "2025-01-09 18:08:15,048 [INFO] ✅ Prediction input data loaded from '..\\..\\dataset\\test\\data\\final_ml_dataset.csv'.\n",
      "2025-01-09 18:08:15,048 [INFO] Starting: Final Preprocessing Pipeline in 'predict' mode.\n",
      "2025-01-09 18:08:15,049 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:15,051 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 15)\n",
      "2025-01-09 18:08:15,051 [DEBUG] Selected Features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:15,051 [INFO] ✅ Column filtering completed successfully.\n",
      "2025-01-09 18:08:15,052 [INFO] Step: Preprocess Predict\n",
      "2025-01-09 18:08:15,053 [DEBUG] Initial columns in prediction data: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:15,053 [DEBUG] Initial number of features: 15\n",
      "2025-01-09 18:08:15,054 [INFO] Step: Load Transformers\n",
      "2025-01-09 18:08:15,054 [DEBUG] Loading transformers from: ..\\transformers\\transformers.pkl\n",
      "2025-01-09 18:08:15,059 [DEBUG] Pipeline loaded. Ready to transform new data.\n",
      "2025-01-09 18:08:15,060 [INFO] Transformers loaded successfully from '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:15,060 [DEBUG] Transformers loaded successfully.\n",
      "2025-01-09 18:08:15,061 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:15,062 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 15)\n",
      "2025-01-09 18:08:15,063 [DEBUG] Selected Features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:15,063 [DEBUG] Columns after filtering: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:15,064 [DEBUG] Number of features after filtering: 15\n",
      "2025-01-09 18:08:15,064 [INFO] Step: Handle Missing Values\n",
      "2025-01-09 18:08:15,065 [DEBUG] Numerical Imputation Strategy: Median, Imputer Type: SimpleImputer\n",
      "2025-01-09 18:08:15,075 [DEBUG] Categorical Imputation Strategy: Most_frequent, Imputer Type: SimpleImputer\n",
      "2025-01-09 18:08:15,078 [DEBUG] Completed: Handle Missing Values. Dataset shape after imputation: (125, 15)\n",
      "2025-01-09 18:08:15,080 [DEBUG] Missing values after imputation in X_train:\n",
      "release_ball_direction_x                    0\n",
      "release_ball_direction_z                    0\n",
      "release_ball_direction_y                    0\n",
      "elbow_release_angle                         0\n",
      "elbow_max_angle                             0\n",
      "wrist_release_angle                         0\n",
      "wrist_max_angle                             0\n",
      "knee_release_angle                          0\n",
      "knee_max_angle                              0\n",
      "release_ball_speed                          0\n",
      "calculated_release_angle                    0\n",
      "release_ball_velocity_x                     0\n",
      "release_ball_velocity_y                     0\n",
      "release_ball_velocity_z                     0\n",
      "player_estimated_hand_length_cm_category    0\n",
      "dtype: int64\n",
      "2025-01-09 18:08:15,081 [DEBUG] New columns handled: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:15,082 [DEBUG] Columns after handling missing values: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:15,082 [DEBUG] Number of features after handling missing values: 15\n",
      "2025-01-09 18:08:15,083 [DEBUG] Expected raw features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:15,084 [DEBUG] Provided features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:15,085 [DEBUG] Reordered columns to match the pipeline's raw feature expectations.\n",
      "2025-01-09 18:08:15,093 [DEBUG] Transformed data shape: (125, 15)\n",
      "2025-01-09 18:08:15,094 [DEBUG] Derived feature names from pipeline: ['num__release_ball_direction_x', 'num__release_ball_direction_z', 'num__release_ball_direction_y', 'num__elbow_release_angle', 'num__elbow_max_angle', 'num__wrist_release_angle', 'num__wrist_max_angle', 'num__knee_release_angle', 'num__knee_max_angle', 'num__release_ball_speed', 'num__calculated_release_angle', 'num__release_ball_velocity_x', 'num__release_ball_velocity_y', 'num__release_ball_velocity_z', 'nominal__player_estimated_hand_length_cm_category_Medium']\n",
      "2025-01-09 18:08:15,094 [DEBUG] X_preprocessed_df columns: ['num__release_ball_direction_x', 'num__release_ball_direction_z', 'num__release_ball_direction_y', 'num__elbow_release_angle', 'num__elbow_max_angle', 'num__wrist_release_angle', 'num__wrist_max_angle', 'num__knee_release_angle', 'num__knee_max_angle', 'num__release_ball_speed', 'num__calculated_release_angle', 'num__release_ball_velocity_x', 'num__release_ball_velocity_y', 'num__release_ball_velocity_z', 'nominal__player_estimated_hand_length_cm_category_Medium']\n",
      "2025-01-09 18:08:15,097 [DEBUG] Sample of X_preprocessed_df:\n",
      "   num__release_ball_direction_x  num__release_ball_direction_z  \\\n",
      "0                       0.200442                       0.029218   \n",
      "1                       0.628897                      -0.731202   \n",
      "2                       0.264488                      -0.091281   \n",
      "3                      -0.695430                       0.974150   \n",
      "4                       0.336515                      -0.199535   \n",
      "\n",
      "   num__release_ball_direction_y  num__elbow_release_angle  \\\n",
      "0                       1.175516                  1.020327   \n",
      "1                      -1.071842                 -1.423048   \n",
      "2                       0.121513                  1.294261   \n",
      "3                       1.180299                  0.861899   \n",
      "4                      -0.074955                  1.247774   \n",
      "\n",
      "   num__elbow_max_angle  num__wrist_release_angle  num__wrist_max_angle  \\\n",
      "0              1.138980                  0.441979             -0.782146   \n",
      "1             -1.457654                  1.794251              0.107597   \n",
      "2              1.555476                 -0.103650              0.205150   \n",
      "3             -0.086542                 -1.139068             -0.642810   \n",
      "4             -0.277425                 -1.398682             -1.226460   \n",
      "\n",
      "   num__knee_release_angle  num__knee_max_angle  num__release_ball_speed  \\\n",
      "0                 0.644151             0.702538                -0.238583   \n",
      "1                 1.092342             1.789279                 0.873691   \n",
      "2                 0.985277             1.623802                -0.020846   \n",
      "3                -0.517249             1.299184                -0.669375   \n",
      "4                 0.723405             1.037778                 0.460286   \n",
      "\n",
      "   num__calculated_release_angle  num__release_ball_velocity_x  \\\n",
      "0                       0.346229                     -0.071285   \n",
      "1                       1.067820                      0.738698   \n",
      "2                      -0.605145                      0.066010   \n",
      "3                       0.511606                     -0.783542   \n",
      "4                      -0.394284                      0.331009   \n",
      "\n",
      "   num__release_ball_velocity_y  num__release_ball_velocity_z  \\\n",
      "0                      1.192943                     -0.245370   \n",
      "1                     -1.443174                      0.893517   \n",
      "2                      0.115574                     -0.009691   \n",
      "3                      1.192943                     -0.560063   \n",
      "4                     -0.184186                      0.546129   \n",
      "\n",
      "   nominal__player_estimated_hand_length_cm_category_Medium  \n",
      "0                                                1.0         \n",
      "1                                                1.0         \n",
      "2                                                1.0         \n",
      "3                                                1.0         \n",
      "4                                                1.0         \n",
      "2025-01-09 18:08:15,099 [DEBUG] [DEBUG] Original data shape before inverse transform: (125, 15)\n",
      "2025-01-09 18:08:15,105 [DEBUG] [DEBUG] Inversed data shape: (125, 15)\n",
      "2025-01-09 18:08:15,106 [INFO] Step: Generate Preprocessor Recommendations\n",
      "2025-01-09 18:08:15,108 [DEBUG] Preprocessing Recommendations:\n",
      "                                                           Preprocessing Reason\n",
      "player_estimated_hand_length_cm_category  Categorical: Most_frequent Imputation\n",
      "release_ball_direction_x                           Numerical: Median Imputation\n",
      "release_ball_direction_z                           Numerical: Median Imputation\n",
      "release_ball_direction_y                           Numerical: Median Imputation\n",
      "elbow_release_angle                                Numerical: Median Imputation\n",
      "elbow_max_angle                                    Numerical: Median Imputation\n",
      "wrist_release_angle                                Numerical: Median Imputation\n",
      "wrist_max_angle                                    Numerical: Median Imputation\n",
      "knee_release_angle                                 Numerical: Median Imputation\n",
      "knee_max_angle                                     Numerical: Median Imputation\n",
      "release_ball_speed                                 Numerical: Median Imputation\n",
      "calculated_release_angle                           Numerical: Median Imputation\n",
      "release_ball_velocity_x                            Numerical: Median Imputation\n",
      "release_ball_velocity_y                            Numerical: Median Imputation\n",
      "release_ball_velocity_z                            Numerical: Median Imputation\n",
      "2025-01-09 18:08:15,108 [DEBUG] Generated preprocessing recommendations.\n",
      "2025-01-09 18:08:15,109 [INFO] ✅ Preprocessing completed successfully in predict mode.\n",
      "2025-01-09 18:08:15,109 [INFO] ✅ Preprocessing completed successfully in predict mode.\n",
      "2025-01-09 18:08:15,112 [INFO] ✅ Trained model loaded from '..\\models\\Decision_Tree_Regressor\\trained_model.pkl'.\n",
      "2025-01-09 18:08:15,115 [INFO] ✅ Predictions made successfully.\n",
      "2025-01-09 18:08:15,116 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 18:08:15,122 [INFO] ✅ Predictions saved to '..\\..\\dataset\\test\\data\\preprocessor\\predictions\\predictions_Decision_Tree_Regressor.csv'.\n",
      "2025-01-09 18:08:15,123 [INFO] ✅ All tasks completed successfully for model 'Decision Tree Regressor'.\n",
      "2025-01-09 18:08:15,124 [INFO] ---\n",
      "Processing Model: Support Vector Machine (Support Vector Machine)\n",
      "---\n",
      "2025-01-09 18:08:15,124 [INFO] Model Category: Classification\n",
      "2025-01-09 18:08:15,125 [INFO] ---\n",
      "Processing Model: Support Vector Machine (Support Vector Machine) in 'predict' mode\n",
      "---\n",
      "2025-01-09 18:08:15,136 [INFO] ✅ Prediction input data loaded from '..\\..\\dataset\\test\\data\\final_ml_dataset.csv'.\n",
      "2025-01-09 18:08:15,137 [INFO] Starting: Final Preprocessing Pipeline in 'predict' mode.\n",
      "2025-01-09 18:08:15,137 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:15,138 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 15)\n",
      "2025-01-09 18:08:15,139 [DEBUG] Selected Features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:15,139 [INFO] ✅ Column filtering completed successfully.\n",
      "2025-01-09 18:08:15,140 [INFO] Step: Preprocess Predict\n",
      "2025-01-09 18:08:15,140 [DEBUG] Initial columns in prediction data: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:15,140 [DEBUG] Initial number of features: 15\n",
      "2025-01-09 18:08:15,140 [INFO] Step: Load Transformers\n",
      "2025-01-09 18:08:15,141 [DEBUG] Loading transformers from: ..\\transformers\\transformers.pkl\n",
      "2025-01-09 18:08:15,144 [DEBUG] Pipeline loaded. Ready to transform new data.\n",
      "2025-01-09 18:08:15,144 [INFO] Transformers loaded successfully from '..\\transformers\\transformers.pkl'.\n",
      "2025-01-09 18:08:15,145 [DEBUG] Transformers loaded successfully.\n",
      "2025-01-09 18:08:15,145 [INFO] Step: filter_columns\n",
      "2025-01-09 18:08:15,146 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 15)\n",
      "2025-01-09 18:08:15,146 [DEBUG] Selected Features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:15,147 [DEBUG] Columns after filtering: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:15,147 [DEBUG] Number of features after filtering: 15\n",
      "2025-01-09 18:08:15,148 [INFO] Step: Handle Missing Values\n",
      "2025-01-09 18:08:15,148 [DEBUG] Numerical Imputation Strategy: Mean, Imputer Type: KNNImputer\n",
      "2025-01-09 18:08:15,152 [DEBUG] Categorical Imputation Strategy: Constant, Imputer Type: SimpleImputer\n",
      "2025-01-09 18:08:15,154 [DEBUG] Completed: Handle Missing Values. Dataset shape after imputation: (125, 15)\n",
      "2025-01-09 18:08:15,155 [DEBUG] Missing values after imputation in X_train:\n",
      "release_ball_direction_x                    0\n",
      "release_ball_direction_z                    0\n",
      "release_ball_direction_y                    0\n",
      "elbow_release_angle                         0\n",
      "elbow_max_angle                             0\n",
      "wrist_release_angle                         0\n",
      "wrist_max_angle                             0\n",
      "knee_release_angle                          0\n",
      "knee_max_angle                              0\n",
      "release_ball_speed                          0\n",
      "calculated_release_angle                    0\n",
      "release_ball_velocity_x                     0\n",
      "release_ball_velocity_y                     0\n",
      "release_ball_velocity_z                     0\n",
      "player_estimated_hand_length_cm_category    0\n",
      "dtype: int64\n",
      "2025-01-09 18:08:15,155 [DEBUG] New columns handled: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:15,156 [DEBUG] Columns after handling missing values: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:15,156 [DEBUG] Number of features after handling missing values: 15\n",
      "2025-01-09 18:08:15,156 [DEBUG] Expected raw features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:15,157 [DEBUG] Provided features: ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z', 'player_estimated_hand_length_cm_category']\n",
      "2025-01-09 18:08:15,158 [DEBUG] Reordered columns to match the pipeline's raw feature expectations.\n",
      "2025-01-09 18:08:15,161 [DEBUG] Transformed data shape: (125, 15)\n",
      "2025-01-09 18:08:15,162 [DEBUG] Derived feature names from pipeline: ['num__release_ball_direction_x', 'num__release_ball_direction_z', 'num__release_ball_direction_y', 'num__elbow_release_angle', 'num__elbow_max_angle', 'num__wrist_release_angle', 'num__wrist_max_angle', 'num__knee_release_angle', 'num__knee_max_angle', 'num__release_ball_speed', 'num__calculated_release_angle', 'num__release_ball_velocity_x', 'num__release_ball_velocity_y', 'num__release_ball_velocity_z', 'nominal__player_estimated_hand_length_cm_category_Medium']\n",
      "2025-01-09 18:08:15,162 [DEBUG] X_preprocessed_df columns: ['num__release_ball_direction_x', 'num__release_ball_direction_z', 'num__release_ball_direction_y', 'num__elbow_release_angle', 'num__elbow_max_angle', 'num__wrist_release_angle', 'num__wrist_max_angle', 'num__knee_release_angle', 'num__knee_max_angle', 'num__release_ball_speed', 'num__calculated_release_angle', 'num__release_ball_velocity_x', 'num__release_ball_velocity_y', 'num__release_ball_velocity_z', 'nominal__player_estimated_hand_length_cm_category_Medium']\n",
      "2025-01-09 18:08:15,165 [DEBUG] Sample of X_preprocessed_df:\n",
      "   num__release_ball_direction_x  num__release_ball_direction_z  \\\n",
      "0                       0.200442                       0.029218   \n",
      "1                       0.628897                      -0.731202   \n",
      "2                       0.264488                      -0.091281   \n",
      "3                      -0.695430                       0.974150   \n",
      "4                       0.336515                      -0.199535   \n",
      "\n",
      "   num__release_ball_direction_y  num__elbow_release_angle  \\\n",
      "0                       1.175516                  1.020327   \n",
      "1                      -1.071842                 -1.423048   \n",
      "2                       0.121513                  1.294261   \n",
      "3                       1.180299                  0.861899   \n",
      "4                      -0.074955                  1.247774   \n",
      "\n",
      "   num__elbow_max_angle  num__wrist_release_angle  num__wrist_max_angle  \\\n",
      "0              1.138980                  0.441979             -0.782146   \n",
      "1             -1.457654                  1.794251              0.107597   \n",
      "2              1.555476                 -0.103650              0.205150   \n",
      "3             -0.086542                 -1.139068             -0.642810   \n",
      "4             -0.277425                 -1.398682             -1.226460   \n",
      "\n",
      "   num__knee_release_angle  num__knee_max_angle  num__release_ball_speed  \\\n",
      "0                 0.644151             0.702538                -0.238583   \n",
      "1                 1.092342             1.789279                 0.873691   \n",
      "2                 0.985277             1.623802                -0.020846   \n",
      "3                -0.517249             1.299184                -0.669375   \n",
      "4                 0.723405             1.037778                 0.460286   \n",
      "\n",
      "   num__calculated_release_angle  num__release_ball_velocity_x  \\\n",
      "0                       0.346229                     -0.071285   \n",
      "1                       1.067820                      0.738698   \n",
      "2                      -0.605145                      0.066010   \n",
      "3                       0.511606                     -0.783542   \n",
      "4                      -0.394284                      0.331009   \n",
      "\n",
      "   num__release_ball_velocity_y  num__release_ball_velocity_z  \\\n",
      "0                      1.192943                     -0.245370   \n",
      "1                     -1.443174                      0.893517   \n",
      "2                      0.115574                     -0.009691   \n",
      "3                      1.192943                     -0.560063   \n",
      "4                     -0.184186                      0.546129   \n",
      "\n",
      "   nominal__player_estimated_hand_length_cm_category_Medium  \n",
      "0                                                1.0         \n",
      "1                                                1.0         \n",
      "2                                                1.0         \n",
      "3                                                1.0         \n",
      "4                                                1.0         \n",
      "2025-01-09 18:08:15,166 [DEBUG] [DEBUG] Original data shape before inverse transform: (125, 15)\n",
      "2025-01-09 18:08:15,169 [DEBUG] [DEBUG] Inversed data shape: (125, 15)\n",
      "2025-01-09 18:08:15,169 [INFO] Step: Generate Preprocessor Recommendations\n",
      "2025-01-09 18:08:15,170 [DEBUG] Preprocessing Recommendations:\n",
      "                                                      Preprocessing Reason\n",
      "player_estimated_hand_length_cm_category  Categorical: Constant Imputation\n",
      "release_ball_direction_x                        Numerical: Mean Imputation\n",
      "release_ball_direction_z                        Numerical: Mean Imputation\n",
      "release_ball_direction_y                        Numerical: Mean Imputation\n",
      "elbow_release_angle                             Numerical: Mean Imputation\n",
      "elbow_max_angle                                 Numerical: Mean Imputation\n",
      "wrist_release_angle                             Numerical: Mean Imputation\n",
      "wrist_max_angle                                 Numerical: Mean Imputation\n",
      "knee_release_angle                              Numerical: Mean Imputation\n",
      "knee_max_angle                                  Numerical: Mean Imputation\n",
      "release_ball_speed                              Numerical: Mean Imputation\n",
      "calculated_release_angle                        Numerical: Mean Imputation\n",
      "release_ball_velocity_x                         Numerical: Mean Imputation\n",
      "release_ball_velocity_y                         Numerical: Mean Imputation\n",
      "release_ball_velocity_z                         Numerical: Mean Imputation\n",
      "2025-01-09 18:08:15,171 [DEBUG] Generated preprocessing recommendations.\n",
      "2025-01-09 18:08:15,171 [INFO] ✅ Preprocessing completed successfully in predict mode.\n",
      "2025-01-09 18:08:15,172 [INFO] ✅ Preprocessing completed successfully in predict mode.\n",
      "2025-01-09 18:08:15,174 [INFO] ✅ Trained model loaded from '..\\models\\Support_Vector_Machine\\trained_model.pkl'.\n",
      "2025-01-09 18:08:15,175 [INFO] ✅ Predictions made successfully.\n",
      "2025-01-09 18:08:15,176 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 18:08:15,178 [INFO] ✅ Predictions saved to '..\\..\\dataset\\test\\data\\preprocessor\\predictions\\predictions_Support_Vector_Machine.csv'.\n",
      "2025-01-09 18:08:15,179 [INFO] ✅ All tasks completed successfully for model 'Support Vector Machine'.\n"
     ]
    }
   ],
   "source": [
    "# scripts/model_factory.py\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.svm import SVC, SVR\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import logging\n",
    "# from datapreprocessor import DataPreprocessor # Importing the DataPreprocessor class from datapreprocessor.py\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def get_model(model_type: str, model_sub_type: str):\n",
    "    \"\"\"Factory function to get model instances based on the model type and subtype.\"\"\"\n",
    "    if model_type == \"Tree Based Classifier\":\n",
    "        if model_sub_type == \"Random Forest\":\n",
    "            return RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "        elif model_sub_type == \"XGBoost\":\n",
    "            return XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "        elif model_sub_type == \"Decision Tree\":\n",
    "            return DecisionTreeClassifier(random_state=42)\n",
    "        else:\n",
    "            raise ValueError(f\"Classifier subtype '{model_sub_type}' is not supported under '{model_type}'.\")\n",
    "    \n",
    "    elif model_type == \"Logistic Regression\":\n",
    "        if model_sub_type == \"Logistic Regression\":\n",
    "            return LogisticRegression(random_state=42, max_iter=1000)\n",
    "        else:\n",
    "            raise ValueError(f\"Subtype '{model_sub_type}' is not supported under '{model_type}'.\")\n",
    "    \n",
    "    elif model_type == \"K-Means\":\n",
    "        if model_sub_type == \"K-Means\":\n",
    "            return KMeans(n_clusters=3, init='k-means++', n_init=10, max_iter=300, random_state=42)\n",
    "        else:\n",
    "            raise ValueError(f\"Clustering subtype '{model_sub_type}' is not supported under '{model_type}'.\")\n",
    "    \n",
    "    elif model_type == \"Linear Regression\":\n",
    "        if model_sub_type == \"Linear Regression\":\n",
    "            return LinearRegression()\n",
    "        else:\n",
    "            raise ValueError(f\"Subtype '{model_sub_type}' is not supported under '{model_type}'.\")\n",
    "    \n",
    "    elif model_type == \"Tree Based Regressor\":\n",
    "        if model_sub_type == \"Random Forest Regressor\":\n",
    "            return RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "        elif model_sub_type == \"XGBoost Regressor\":\n",
    "            return XGBRegressor(eval_metric='rmse', random_state=42)\n",
    "        elif model_sub_type == \"Decision Tree Regressor\":\n",
    "            return DecisionTreeRegressor(random_state=42)\n",
    "        else:\n",
    "            raise ValueError(f\"Regressor subtype '{model_sub_type}' is not supported under '{model_type}'.\")\n",
    "    \n",
    "    elif model_type == \"Support Vector Machine\":\n",
    "        if model_sub_type == \"Support Vector Machine\":\n",
    "            return SVC(probability=True, random_state=42)\n",
    "        else:\n",
    "            raise ValueError(f\"SVM subtype '{model_sub_type}' is not supported under '{model_type}'.\")\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Model type '{model_type}' is not supported.\")\n",
    "\n",
    "\n",
    "\n",
    "# scripts/train_predict.py\n",
    "\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "import yaml\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# Local imports - Adjust based on your project structure\n",
    "# from model_factory import get_model\n",
    "from datapreprocessor import DataPreprocessor\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_dataset(path: Path) -> pd.DataFrame:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Dataset not found at {path}\")\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def load_config(config_path: Path) -> dict:\n",
    "    if not config_path.exists():\n",
    "        raise FileNotFoundError(f\"Configuration file not found at {config_path}\")\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "def setup_logging(log_dir: Path, log_filename: str = 'training.log') -> logging.Logger:\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    log_path = log_dir / log_filename\n",
    "    \n",
    "    logger = logging.getLogger('model_training')\n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "    # Clear existing handlers to prevent duplicate logs\n",
    "    if logger.hasHandlers():\n",
    "        logger.handlers.clear()\n",
    "    \n",
    "    # Create handlers\n",
    "    f_handler = logging.FileHandler(log_path)\n",
    "    f_handler.setLevel(logging.INFO)\n",
    "    c_handler = logging.StreamHandler()\n",
    "    c_handler.setLevel(logging.INFO)\n",
    "    \n",
    "    # Create formatters and add them to handlers\n",
    "    formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s')\n",
    "    f_handler.setFormatter(formatter)\n",
    "    c_handler.setFormatter(formatter)\n",
    "    \n",
    "    # Add handlers to the logger\n",
    "    logger.addHandler(f_handler)\n",
    "    logger.addHandler(c_handler)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "def construct_model_path(model_save_dir: Path, model_sub_type: str) -> Path:\n",
    "    \"\"\"Constructs a standardized path for saving/loading models.\"\"\"\n",
    "    model_dir = model_save_dir / model_sub_type.replace(\" \", \"_\")\n",
    "    model_dir.mkdir(parents=True, exist_ok=True)\n",
    "    model_path = model_dir / 'trained_model.pkl'\n",
    "    return model_path\n",
    "\n",
    "def get_model_category(model_type: str) -> str:\n",
    "    \"\"\"Determines the category of the model based on its type.\"\"\"\n",
    "    classification_models = [\"Tree Based Classifier\", \"Logistic Regression\", \"Support Vector Machine\"]\n",
    "    regression_models = [\"Linear Regression\", \"Tree Based Regressor\"]\n",
    "    clustering_models = [\"K-Means\"]\n",
    "    \n",
    "    if model_type in classification_models:\n",
    "        return \"classification\"\n",
    "    elif model_type in regression_models:\n",
    "        return \"regression\"\n",
    "    elif model_type in clustering_models:\n",
    "        return \"clustering\"\n",
    "    else:\n",
    "        raise ValueError(f\"Model type '{model_type}' does not belong to a recognized category.\")\n",
    "\n",
    "def main(mode: str):\n",
    "    # Now we allow 3 modes: train, predict, clustering\n",
    "    valid_modes = [\"train\", \"predict\", \"clustering\"]\n",
    "    if mode.lower() not in valid_modes:\n",
    "        logger.error(f\"❌ Unsupported mode '{mode}'. Use one of {valid_modes}.\")\n",
    "        return\n",
    "    # ----------------------------\n",
    "    # Step 1: Load Configuration\n",
    "    # ----------------------------\n",
    "    config = load_config(Path('../../dataset/test/preprocessor_config/preprocessor_config.yaml'))\n",
    "    \n",
    "    # Extract paths\n",
    "    paths = config.get('paths', {})\n",
    "    data_dir = Path(paths.get('data_dir', '../../dataset/test/data'))\n",
    "    raw_data_path = data_dir / paths.get('raw_data', 'final_ml_dataset.csv')\n",
    "    processed_data_dir = data_dir / paths.get('processed_data_dir', 'processed')\n",
    "    features_metadata_path = data_dir / paths.get('features_metadata', 'features_info/features_metadata.pkl')\n",
    "    predictions_output_dir = data_dir / paths.get('predictions_output_dir', 'predictions')\n",
    "    \n",
    "    config_path = Path(paths.get('config_path', 'preprocessor_config/preprocessor_config.yaml'))\n",
    "    log_dir = Path(paths.get('log_dir', '../logs'))\n",
    "    log_file = paths.get('log_file', 'training.log')\n",
    "    \n",
    "    model_save_dir = Path(paths.get('model_save_dir', '../models'))\n",
    "    transformers_dir = Path(paths.get('transformers_dir', '../transformers'))\n",
    "    plots_output_dir = Path(paths.get('plots_output_dir', '../plots'))\n",
    "    \n",
    "    training_output_dir = Path(paths.get('training_output_dir', '../training_output'))\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Step 2: Setup Logging\n",
    "    # ----------------------------\n",
    "    logger = setup_logging(log_dir, log_file)\n",
    "    logger.info(f\"Mode: {mode.capitalize()}\")\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Step 3: Extract Feature Assets\n",
    "    # ----------------------------\n",
    "    features_config = config.get('features', {})\n",
    "    column_assets = {\n",
    "        'y_variable': features_config.get('y_variable', []),\n",
    "        'ordinal_categoricals': features_config.get('ordinal_categoricals', []),\n",
    "        'nominal_categoricals': features_config.get('nominal_categoricals', []),\n",
    "        'numericals': features_config.get('numericals', [])\n",
    "    }\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Step 4: Get List of Model Types and Subtypes\n",
    "    # ----------------------------\n",
    "    model_types = config.get('model_types', [])  # Should be defined in config\n",
    "    model_sub_types_config = config.get('model_sub_types', {})\n",
    "    \n",
    "    if not model_types:\n",
    "        logger.error(\"❌ No model types specified in the configuration.\")\n",
    "        return\n",
    "    \n",
    "    for model_type in model_types:\n",
    "        sub_types = model_sub_types_config.get(model_type, [])\n",
    "        if not sub_types:\n",
    "            logger.warning(f\"⚠️ No subtypes found for model type '{model_type}'. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        for model_sub_type in sub_types:\n",
    "            logger.info(f\"---\\nProcessing Model: {model_sub_type} ({model_type})\\n---\")\n",
    "            \n",
    "            # Step 5: Extract Model Configuration\n",
    "            model_config = config.get('models', {}).get(model_type, {})\n",
    "            if not model_config:\n",
    "                logger.error(f\"No configuration found for model type '{model_type}'. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # Step 6: Determine Model Category\n",
    "            try:\n",
    "                model_category = get_model_category(model_type)\n",
    "                logger.info(f\"Model Category: {model_category.capitalize()}\")\n",
    "            except ValueError as ve:\n",
    "                logger.error(str(ve))\n",
    "                continue\n",
    "            \n",
    "            if mode.lower() == 'clustering':\n",
    "                # only run if model_type == \"K-Means\"\n",
    "                if model_type != \"K-Means\":\n",
    "                    logger.info(f\"Skipping non-clustering type {model_type} in 'clustering' mode.\")\n",
    "                    continue\n",
    "                logger.info(f\"---\\nProcessing Model: {model_sub_type} ({model_type}) in 'clustering' mode\\n---\")\n",
    "\n",
    "                # 1) Load dataset\n",
    "                if not raw_data_path.exists():\n",
    "                    logger.error(f\"❌ Clustering dataset not found at '{raw_data_path}'.\")\n",
    "                    continue\n",
    "                try:\n",
    "                    df_cluster = load_dataset(raw_data_path)\n",
    "                    logger.info(f\"✅ Clustering input data loaded from '{raw_data_path}'.\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"❌ Failed to load clustering dataset: {e}\")\n",
    "                    continue\n",
    "\n",
    "                # 2) Initialize DataPreprocessor with mode='clustering'\n",
    "                preprocessor = DataPreprocessor(\n",
    "                    model_type=model_type,\n",
    "                    y_variable=[],  # K-Means is unsupervised, no target\n",
    "                    ordinal_categoricals=column_assets.get('ordinal_categoricals', []),\n",
    "                    nominal_categoricals=column_assets.get('nominal_categoricals', []),\n",
    "                    numericals=column_assets.get('numericals', []),\n",
    "                    mode='clustering',\n",
    "                    options=model_config,\n",
    "                    debug=False,\n",
    "                    normalize_debug=False,\n",
    "                    normalize_graphs_output=False,\n",
    "                    graphs_output_dir=plots_output_dir,\n",
    "                    transformers_dir=transformers_dir\n",
    "                )\n",
    "\n",
    "                # 3) Preprocess for Clustering\n",
    "                try:\n",
    "                    X_preprocessed, recommendations = preprocessor.final_preprocessing(df_cluster)\n",
    "                    logger.info(\"✅ Preprocessing completed successfully in clustering mode.\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"❌ Preprocessing failed in clustering mode: {e}\")\n",
    "                    continue\n",
    "\n",
    "                # 4) Instantiate the K-Means model\n",
    "                try:\n",
    "                    # from model_factory import get_model\n",
    "                    model = get_model(model_type, model_sub_type)  # This should create a KMeans instance\n",
    "                    model.fit(X_preprocessed)  # Fit K-Means\n",
    "                    logger.info(f\"✅ {model_sub_type} clustering completed. Inertia: {model.inertia_}\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"❌ Clustering failed for {model_sub_type}: {e}\")\n",
    "                    continue\n",
    "\n",
    "                # 5) (Optional) Save cluster model\n",
    "                try:\n",
    "                    model_path = construct_model_path(model_save_dir, model_sub_type)\n",
    "                    joblib.dump(model, model_path)\n",
    "                    logger.info(f\"✅ Clustering model {model_sub_type} saved to '{model_path}'.\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"❌ Failed to save the clustering model: {e}\")\n",
    "                    continue\n",
    "\n",
    "                logger.info(f\"✅ All tasks completed successfully for clustering model '{model_sub_type}'.\")\n",
    "\n",
    "            # ----------------------------\n",
    "            # Training Phase\n",
    "            # ----------------------------\n",
    "            elif mode.lower() == 'train':\n",
    "                # Validate paths\n",
    "                if not raw_data_path.exists():\n",
    "                    logger.error(f\"❌ Training input dataset not found at '{raw_data_path}'.\")\n",
    "                    continue\n",
    "                # only run if model_type == \"K-Means\"\n",
    "                if model_sub_type == \"K-Means\":\n",
    "                    logger.info(f\"Skipping clustering type {model_sub_type} in 'train' mode.\")\n",
    "                    continue\n",
    "                logger.info(f\"---\\nProcessing Model: {model_sub_type} ({model_type}) in 'train' mode\\n---\")\n",
    "\n",
    "                # Load Training Dataset\n",
    "                try:\n",
    "                    df_train = load_dataset(raw_data_path)\n",
    "                    logger.info(f\"✅ Training input data loaded from '{raw_data_path}'.\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"❌ Failed to load training input data: {e}\")\n",
    "                    continue\n",
    "                \n",
    "                # Initialize DataPreprocessor\n",
    "                preprocessor = DataPreprocessor(\n",
    "                    model_type=model_type,\n",
    "                    y_variable=column_assets.get('y_variable', []),\n",
    "                    ordinal_categoricals=column_assets.get('ordinal_categoricals', []),\n",
    "                    nominal_categoricals=column_assets.get('nominal_categoricals', []),\n",
    "                    numericals=column_assets.get('numericals', []),\n",
    "                    mode='train',\n",
    "                    options=model_config,\n",
    "                    debug=False,  # Can be parameterized\n",
    "                    normalize_debug=False,  # As per hardcoded paths\n",
    "                    normalize_graphs_output=False,  # As per hardcoded paths\n",
    "                    graphs_output_dir=plots_output_dir,\n",
    "                    transformers_dir=transformers_dir\n",
    "                )\n",
    "                \n",
    "                # Execute Preprocessing\n",
    "                try:\n",
    "                    X_train, X_test, y_train, y_test, recommendations, X_test_inverse = preprocessor.final_preprocessing(df_train)\n",
    "                    logger.info(\"✅ Preprocessing completed successfully in train mode.\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"❌ Preprocessing failed in train mode: {e}\")\n",
    "                    continue\n",
    "                \n",
    "                # Initialize and Train Model\n",
    "                try:\n",
    "                    model = get_model(model_type, model_sub_type)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    logger.info(f\"✅ {model_sub_type} trained successfully.\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"❌ Training failed for {model_sub_type}: {e}\")\n",
    "                    continue\n",
    "                \n",
    "                # Save the Trained Model\n",
    "                try:\n",
    "                    model_path = construct_model_path(model_save_dir, model_sub_type)\n",
    "                    joblib.dump(model, model_path)\n",
    "                    logger.info(f\"✅ Trained {model_sub_type} saved to '{model_path}'.\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"❌ Failed to save the trained model: {e}\")\n",
    "                    continue\n",
    "                \n",
    "                # Load Trained Model\n",
    "                try:\n",
    "                    model_path = construct_model_path(model_save_dir, model_sub_type)\n",
    "                    if not model_path.exists():\n",
    "                        logger.error(f\"❌ Trained model not found at '{model_path}'.\")\n",
    "                        continue\n",
    "                    trained_model = joblib.load(model_path)\n",
    "                    logger.info(f\"✅ Trained model loaded from '{model_path}'.\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"❌ Failed to load trained model: {e}\")\n",
    "                    continue\n",
    "                \n",
    "                # Just after we build X_test_final and get X_test_inverse:\n",
    "                logger.debug(f\"[DEBUG] X_test_final.shape: {X_test.shape}\")\n",
    "                logger.debug(f\"[DEBUG] X_test_final indices: {X_test.index.tolist()}\")\n",
    "                logger.debug(f\"[DEBUG] X_test_inverse.shape: {X_test_inverse.shape}\")\n",
    "                logger.debug(f\"[DEBUG] X_test_inverse indices: {X_test_inverse.index.tolist()}\")\n",
    "                \n",
    "                # Make Predictions\n",
    "                try:\n",
    "                    test_predictions = trained_model.predict(X_test)\n",
    "                    logger.info(\"✅ Predictions made successfully.\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"❌ Prediction failed: {e}\")\n",
    "                    continue\n",
    "                \n",
    "                logger.debug(f\"[DEBUG] test_predictions.shape: {test_predictions.shape}\")\n",
    "                logger.debug(f\"[DEBUG] First 5 predictions: {test_predictions[:5]}\")\n",
    "\n",
    "                if X_test_inverse is not None:\n",
    "                    logger.debug(f\"[DEBUG] X_test_inverse.shape: {X_test_inverse.shape}\")\n",
    "                    logger.debug(f\"[DEBUG] X_test_inverse indices:\\n{X_test_inverse.index.tolist()}\")\n",
    "                    if len(test_predictions) == len(X_test_inverse):\n",
    "                        X_test_inverse['predictions'] = test_predictions\n",
    "                        logger.info(\"✅ Predictions attached to inversed data successfully.\")\n",
    "                    else:\n",
    "                        logger.error(\"❌ Predictions length does not match inversed data length.\")\n",
    "                        logger.error(f\"[DEBUG] len(test_predictions) = {len(test_predictions)}, \"\n",
    "                                    f\"len(X_test_inverse) = {len(X_test_inverse)}\")\n",
    "                        logger.error(f\"[DEBUG] X_test_inverse sample:\\n{X_test_inverse.head()}\")\n",
    "                else:\n",
    "                    logger.error(\"❌ Inversed data is None. Cannot attach predictions.\")\n",
    "                \n",
    "                # Attach Predictions to Inversed Data\n",
    "                if X_test_inverse is not None:\n",
    "                    if len(test_predictions) == len(X_test_inverse):\n",
    "                        X_test_inverse['predictions'] = test_predictions\n",
    "                        logger.info(\"✅ Predictions attached to inversed data successfully.\")\n",
    "                    else:\n",
    "                        logger.error(\"❌ Predictions length does not match inversed data length.\")\n",
    "                        continue\n",
    "                else:\n",
    "                    logger.error(\"❌ Inversed data is None. Cannot attach predictions.\")\n",
    "                    continue\n",
    "                \n",
    "                # Optionally, save transformers if needed\n",
    "                try:\n",
    "                    preprocessor.save_transformers()\n",
    "                    logger.info(f\"✅ Transformers saved to '{transformers_dir}'.\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"❌ Failed to save transformers: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            # ----------------------------\n",
    "            # Prediction Phase\n",
    "            # ----------------------------\n",
    "            elif mode.lower() == 'predict':\n",
    "                # Validate paths\n",
    "                if not raw_data_path.exists():\n",
    "                    logger.error(f\"❌ Prediction input dataset not found at '{raw_data_path}'.\")\n",
    "                    continue\n",
    "                # only run if model_type == \"K-Means\"\n",
    "                if model_sub_type == \"K-Means\":\n",
    "                    logger.info(f\"Skipping clustering type {model_sub_type} in 'predict' mode.\")\n",
    "                    continue\n",
    "                logger.info(f\"---\\nProcessing Model: {model_sub_type} ({model_type}) in 'predict' mode\\n---\")\n",
    "\n",
    "                # Load Prediction Dataset\n",
    "                try:\n",
    "                    df_predict = load_dataset(raw_data_path)\n",
    "                    logger.info(f\"✅ Prediction input data loaded from '{raw_data_path}'.\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"❌ Failed to load prediction input data: {e}\")\n",
    "                    continue\n",
    "                \n",
    "                # Initialize DataPreprocessor\n",
    "                preprocessor = DataPreprocessor(\n",
    "                    model_type=model_type,\n",
    "                    y_variable=column_assets.get('y_variable', []),\n",
    "                    ordinal_categoricals=column_assets.get('ordinal_categoricals', []),\n",
    "                    nominal_categoricals=column_assets.get('nominal_categoricals', []),\n",
    "                    numericals=column_assets.get('numericals', []),\n",
    "                    mode='predict',\n",
    "                    options=model_config,\n",
    "                    debug=True,  # Can be parameterized\n",
    "                    normalize_debug=False,  # As per hardcoded paths\n",
    "                    normalize_graphs_output=False,  # As per hardcoded paths\n",
    "                    graphs_output_dir=plots_output_dir,\n",
    "                    transformers_dir=transformers_dir\n",
    "                )\n",
    "                \n",
    "                # Execute Preprocessing for Prediction\n",
    "                try:\n",
    "                    X_preprocessed, recommendations, X_inversed = preprocessor.final_preprocessing(df_predict)\n",
    "                    logger.info(\"✅ Preprocessing completed successfully in predict mode.\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"❌ Preprocessing failed in predict mode: {e}\")\n",
    "                    continue\n",
    "                \n",
    "                # Load Trained Model\n",
    "                try:\n",
    "                    model_path = construct_model_path(model_save_dir, model_sub_type)\n",
    "                    if not model_path.exists():\n",
    "                        logger.error(f\"❌ Trained model not found at '{model_path}'.\")\n",
    "                        continue\n",
    "                    trained_model = joblib.load(model_path)\n",
    "                    logger.info(f\"✅ Trained model loaded from '{model_path}'.\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"❌ Failed to load trained model: {e}\")\n",
    "                    continue\n",
    "                \n",
    "                # Make Predictions\n",
    "                try:\n",
    "                    predictions = trained_model.predict(X_preprocessed)\n",
    "                    logger.info(\"✅ Predictions made successfully.\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"❌ Prediction failed: {e}\")\n",
    "                    continue\n",
    "                \n",
    "                # Attach Predictions to Inversed Data\n",
    "                if X_inversed is not None:\n",
    "                    if len(predictions) == len(X_inversed):\n",
    "                        X_inversed['predictions'] = predictions\n",
    "                        logger.info(\"✅ Predictions attached to inversed data successfully.\")\n",
    "                    else:\n",
    "                        logger.error(\"❌ Predictions length does not match inversed data length.\")\n",
    "                        continue\n",
    "                else:\n",
    "                    logger.error(\"❌ Inversed data is None. Cannot attach predictions.\")\n",
    "                    continue\n",
    "                \n",
    "                # Save Predictions\n",
    "                try:\n",
    "                    predictions_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "                    predictions_filename = predictions_output_dir / f'predictions_{model_sub_type.replace(\" \", \"_\")}.csv'\n",
    "                    X_inversed.to_csv(predictions_filename, index=False)\n",
    "                    logger.info(f\"✅ Predictions saved to '{predictions_filename}'.\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"❌ Failed to save predictions: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            else:\n",
    "                logger.error(f\"❌ Unsupported mode '{mode}'. Use 'train' or 'predict'.\")\n",
    "                continue\n",
    "            \n",
    "            logger.info(f\"✅ All tasks completed successfully for model '{model_sub_type}'.\")\n",
    "    \n",
    "# ----------------------------\n",
    "# Testing Entry Point\n",
    "# ----------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test with 'train' or 'predict' mode\n",
    "    # For example, to test 'train' mode:\n",
    "    print(\"Starting training mode...\")\n",
    "    mode = \"clustering\"  # Change to \"predict\" for testing predictions\n",
    "    main(mode)\n",
    "    # For example, to test 'train' mode:\n",
    "    print(\"Starting training mode...\")\n",
    "    mode = \"train\"  # Change to \"predict\" for testing predictions\n",
    "    main(mode)\n",
    "    \n",
    "    # To test 'predict' mode, uncomment the following lines:\n",
    "    print(\"Starting predict mode...\")\n",
    "    mode = \"predict\"\n",
    "    main(mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile ../../src/freethrow_predictions/ml/train_utils/train_utils.py\n",
    "import os  \n",
    "import joblib  \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    log_loss,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import logging\n",
    "import json\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Main function with MLflow integration\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from inspect import signature\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, save_path=\"classification_report.txt\"):\n",
    "    \"\"\"\n",
    "    Evaluate the model and log performance metrics.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained model to evaluate.\n",
    "    - X_test: Test features.\n",
    "    - y_test: True labels for the test data.\n",
    "    - save_path: Path to save the classification report.\n",
    "\n",
    "    Returns:\n",
    "    - metrics: Dictionary containing evaluation metrics.\n",
    "    \"\"\"\n",
    "    logger.info(\"Evaluating model...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Check if the model supports probability predictions\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "        logger.info(f\"Predicted probabilities: {y_proba}\")\n",
    "    else:\n",
    "        y_proba = None\n",
    "        logger.info(\"Model does not support probability predictions.\")\n",
    "\n",
    "    # Calculate metrics with consistent key naming\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"recall\": recall_score(y_test, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"f1_score\": f1_score(y_test, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"roc_auc\": roc_auc_score(y_test, y_proba) if y_proba is not None else None,\n",
    "        \"log_loss\": log_loss(y_test, y_proba) if y_proba is not None else None,\n",
    "    }\n",
    "\n",
    "    # Log metrics\n",
    "    logger.info(f\"Evaluation Metrics: {metrics}\")\n",
    "\n",
    "    # Generate and save classification report\n",
    "    report = classification_report(y_test, y_pred, output_dict=False)\n",
    "    logger.info(\"\\n\" + report)\n",
    "    report_path = Path(save_path)\n",
    "    report_path.parent.mkdir(parents=True, exist_ok=True)  # Ensure directory exists\n",
    "    with open(report_path, \"w\") as f:\n",
    "        f.write(report)\n",
    "    logger.info(f\"Classification report saved to {save_path}\")\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    confusion_matrix_path = report_path.parent / 'confusion_matrix.png'\n",
    "    disp.plot()\n",
    "    plt.savefig(confusion_matrix_path)\n",
    "    logger.info(f\"Confusion matrix saved to '{confusion_matrix_path}'\")\n",
    "    plt.close()\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "def save_model(model, model_name, save_dir=\"../../data/model\"):\n",
    "    \"\"\"\n",
    "    Save the trained model to disk within a subdirectory named after the model type.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained model to save.\n",
    "    - model_name: Name of the model for saving.\n",
    "    - save_dir: Directory to save the model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        save_dir_path = Path(save_dir) / model_name.replace(\" \", \"_\")\n",
    "        save_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "        model_path = save_dir_path / 'trained_model.pkl'\n",
    "        joblib.dump(model, model_path)\n",
    "        logger.info(f\"Model saved to {model_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save model '{model_name}' to '{save_dir}': {e}\")\n",
    "        raise\n",
    "\n",
    "def load_model(model_name, save_dir=\"../../data/model\"):\n",
    "    \"\"\"\n",
    "    Load the trained model from disk.\n",
    "\n",
    "    Parameters:\n",
    "    - model_name: Name of the model to load.\n",
    "    - save_dir: Directory where the model is saved.\n",
    "\n",
    "    Returns:\n",
    "    - model: Loaded trained model.\n",
    "    \"\"\"\n",
    "    model_path = Path(save_dir) / model_name.replace(\" \", \"_\") / 'trained_model.pkl'\n",
    "    if not model_path.exists():\n",
    "        logger.error(f\"❌ Model file does not exist at '{model_path}'.\")\n",
    "        raise FileNotFoundError(f\"Model file does not exist at '{model_path}'.\")\n",
    "    model = joblib.load(model_path)\n",
    "    logger.info(f\"Model loaded from {model_path}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Plot decision boundary\n",
    "def plot_decision_boundary(model, X, y, title, use_pca=True):\n",
    "    \"\"\"\n",
    "    Plot decision boundaries for the model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained model to visualize.\n",
    "    - X: Feature data (test set).\n",
    "    - y: Target labels.\n",
    "    - title: Title for the plot.\n",
    "    - use_pca: If True, applies PCA for dimensionality reduction if X has >2 features.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Original X shape: {X.shape}\")\n",
    "    if X.shape[1] > 2 and use_pca:\n",
    "        logger.info(\"X has more than 2 features, applying PCA for visualization.\")\n",
    "        try:\n",
    "            pca = PCA(n_components=2)\n",
    "            X_2d = pca.fit_transform(X)\n",
    "            explained_variance = pca.explained_variance_ratio_\n",
    "            logger.info(f\"PCA explained variance ratios: {explained_variance}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"PCA transformation failed: {e}\")\n",
    "            raise e\n",
    "    elif X.shape[1] > 2:\n",
    "        logger.error(\"Cannot plot decision boundary for more than 2D without PCA.\")\n",
    "        raise ValueError(\"Cannot plot decision boundary for more than 2D without PCA.\")\n",
    "    else:\n",
    "        logger.info(\"X has 2 or fewer features, using original features for plotting.\")\n",
    "        X_2d = X\n",
    "\n",
    "    logger.info(f\"Transformed X shape for plotting: {X_2d.shape}\")\n",
    "\n",
    "    # Create mesh grid\n",
    "    try:\n",
    "        x_min, x_max = X_2d[:, 0].min() - 1, X_2d[:, 0].max() + 1\n",
    "        y_min, y_max = X_2d[:, 1].min() - 1, X_2d[:, 1].max() + 1\n",
    "        xx, yy = np.meshgrid(\n",
    "            np.arange(x_min, x_max, 0.01),\n",
    "            np.arange(y_min, y_max, 0.01)\n",
    "        )\n",
    "        logger.info(f\"Mesh grid created with shape xx: {xx.shape}, yy: {yy.shape}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Mesh grid creation failed: {e}\")\n",
    "        raise e\n",
    "\n",
    "    # Flatten the grid arrays and combine into a single array\n",
    "    try:\n",
    "        grid_points_2d = np.c_[xx.ravel(), yy.ravel()]\n",
    "        logger.info(f\"Grid points in 2D PCA space shape: {grid_points_2d.shape}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Grid points preparation failed: {e}\")\n",
    "        raise e\n",
    "\n",
    "    if X.shape[1] > 2 and use_pca:\n",
    "        # Inverse transform the grid points back to the original feature space\n",
    "        try:\n",
    "            logger.info(\"Inverse transforming grid points back to original feature space for prediction.\")\n",
    "            grid_points_original = pca.inverse_transform(grid_points_2d)\n",
    "            logger.info(f\"Grid points in original feature space shape: {grid_points_original.shape}\")\n",
    "            # Predict on the grid points in original feature space\n",
    "            Z = model.predict(grid_points_original)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error predicting decision boundary: {e}\")\n",
    "            return\n",
    "    else:\n",
    "        # For 2D data, use grid points directly for prediction\n",
    "        grid_points_original = grid_points_2d\n",
    "        try:\n",
    "            Z = model.predict(grid_points_original)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error predicting decision boundary: {e}\")\n",
    "            return\n",
    "\n",
    "    try:\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        logger.info(f\"Decision boundary predictions reshaped to: {Z.shape}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Reshaping predictions failed: {e}\")\n",
    "        raise e\n",
    "\n",
    "    # Plot the decision boundary\n",
    "    try:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.RdYlBu)\n",
    "        plt.scatter(X_2d[:, 0], X_2d[:, 1], c=y, edgecolor=\"k\", cmap=plt.cm.RdYlBu)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Principal Component 1\" if use_pca and X.shape[1] > 2 else \"Feature 1\")\n",
    "        plt.ylabel(\"Principal Component 2\" if use_pca and X.shape[1] > 2 else \"Feature 2\")\n",
    "        plt.show()\n",
    "        logger.info(\"Decision boundary plot displayed successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Plotting failed: {e}\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "\n",
    "# Hyperparameter tuning for Random Forest\n",
    "def tune_random_forest(X_train, y_train, scoring_metric=\"neg_log_loss\"):\n",
    "    logger.info(\"Starting hyperparameter tuning for Random Forest...\")\n",
    "    param_space = {\n",
    "        \"n_estimators\": Integer(10, 500),\n",
    "        \"max_depth\": Integer(2, 50),\n",
    "        \"min_samples_split\": Integer(2, 20),\n",
    "        \"min_samples_leaf\": Integer(1, 10),\n",
    "        \"max_features\": Categorical([\"sqrt\", \"log2\", None]),\n",
    "        \"bootstrap\": Categorical([True, False]),\n",
    "        \"criterion\": Categorical([\"gini\", \"entropy\"]),\n",
    "    }\n",
    "    logger.info(f\"Parameter space: {param_space}\")\n",
    "\n",
    "    search = BayesSearchCV(\n",
    "        RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "        param_space,\n",
    "        n_iter=60,\n",
    "        scoring=scoring_metric, #accuracy, neg_log_loss\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    search.fit(X_train, y_train)\n",
    "    logger.info(f\"Best parameters found: {search.best_params_}\")\n",
    "    logger.info(f\"Best cross-validation score: {search.best_score_}\")\n",
    "    return search.best_params_, search.best_score_, search.best_estimator_\n",
    "\n",
    "# Hyperparameter tuning for XGBoost\n",
    "def tune_xgboost(X_train, y_train, scoring_metric=\"neg_log_loss\"):\n",
    "    logger.info(\"Starting hyperparameter tuning for XGBoost...\")\n",
    "    param_space = {\n",
    "        'learning_rate': Real(0.01, 0.3, prior='log-uniform'),\n",
    "        'n_estimators': Integer(100, 500),\n",
    "        'max_depth': Integer(3, 15),\n",
    "        'min_child_weight': Integer(1, 10),\n",
    "        'gamma': Real(0, 5),\n",
    "        'subsample': Real(0.5, 1.0),\n",
    "        'colsample_bytree': Real(0.5, 1.0),\n",
    "        'reg_alpha': Real(1e-8, 1.0, prior='log-uniform'),\n",
    "        'reg_lambda': Real(1e-8, 1.0, prior='log-uniform'),\n",
    "    }\n",
    "    logger.info(f\"Parameter space: {param_space}\")\n",
    "\n",
    "    search = BayesSearchCV(\n",
    "        XGBClassifier(eval_metric=\"logloss\", random_state=42, n_jobs=-1),\n",
    "        param_space,\n",
    "        n_iter=60,\n",
    "        scoring=scoring_metric,\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    search.fit(X_train, y_train)\n",
    "    logger.info(f\"Best parameters found: {search.best_params_}\")\n",
    "    logger.info(f\"Best cross-validation score: {search.best_score_}\")\n",
    "    return search.best_params_, search.best_score_, search.best_estimator_\n",
    "\n",
    "# Hyperparameter tuning for Decision Tree\n",
    "def tune_decision_tree(X_train, y_train, scoring_metric=\"neg_log_loss\"):\n",
    "    logger.info(\"Starting hyperparameter tuning for Decision Tree...\")\n",
    "    param_space = {\n",
    "        \"max_depth\": Integer(2, 50),\n",
    "        \"min_samples_split\": Integer(2, 20),\n",
    "        \"min_samples_leaf\": Integer(1, 10),\n",
    "        \"criterion\": Categorical([\"gini\", \"entropy\"]),\n",
    "        \"splitter\": Categorical([\"best\", \"random\"]),\n",
    "    }\n",
    "    logger.info(f\"Parameter space: {param_space}\")\n",
    "\n",
    "    search = BayesSearchCV(\n",
    "        DecisionTreeClassifier(random_state=42),\n",
    "        param_space,\n",
    "        n_iter=60,\n",
    "        scoring=scoring_metric,\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    search.fit(X_train, y_train)\n",
    "    logger.info(f\"Best parameters found: {search.best_params_}\")\n",
    "    logger.info(f\"Best cross-validation score: {search.best_score_}\")\n",
    "    return search.best_params_, search.best_score_, search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 16:02:30,472 - INFO - ✅ Configuration loaded from ..\\..\\dataset\\test\\preprocessor_config\\preprocessor_config.yaml.\n",
      "2025-01-09 16:02:30,475 [INFO] ✅ Starting the training module.\n",
      "2025-01-09 16:02:30,475 - INFO - ✅ Starting the training module.\n",
      "2025-01-09 16:02:30,481 [INFO] ✅ Loaded dataset from C:\\Users\\ghadf\\vscode_projects\\docker_projects\\ml_preprocessor\\dataset\\test\\data\\final_ml_dataset.csv. Shape: (125, 140)\n",
      "2025-01-09 16:02:30,481 - INFO - ✅ Loaded dataset from C:\\Users\\ghadf\\vscode_projects\\docker_projects\\ml_preprocessor\\dataset\\test\\data\\final_ml_dataset.csv. Shape: (125, 140)\n",
      "2025-01-09 16:02:30,482 [INFO] Starting: Final Preprocessing Pipeline in 'train' mode.\n",
      "2025-01-09 16:02:30,482 - INFO - Starting: Final Preprocessing Pipeline in 'train' mode.\n",
      "2025-01-09 16:02:30,483 [INFO] Step: filter_columns\n",
      "2025-01-09 16:02:30,483 - INFO - Step: filter_columns\n",
      "2025-01-09 16:02:30,484 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 15)\n",
      "2025-01-09 16:02:30,484 - INFO - ✅ Filtered DataFrame to include only specified features. Shape: (125, 15)\n",
      "2025-01-09 16:02:30,485 [INFO] ✅ Column filtering completed successfully.\n",
      "2025-01-09 16:02:30,485 - INFO - ✅ Column filtering completed successfully.\n",
      "2025-01-09 16:02:30,487 [INFO] Step: Split Dataset into Train and Test\n",
      "2025-01-09 16:02:30,487 - INFO - Step: Split Dataset into Train and Test\n",
      "2025-01-09 16:02:30,489 [INFO] Step: Handle Missing Values\n",
      "2025-01-09 16:02:30,489 - INFO - Step: Handle Missing Values\n",
      "2025-01-09 16:02:30,495 [INFO] Step: Test for Normality\n",
      "2025-01-09 16:02:30,495 - INFO - Step: Test for Normality\n",
      "2025-01-09 16:02:30,500 [INFO] Step: Handle Outliers\n",
      "2025-01-09 16:02:30,500 - INFO - Step: Handle Outliers\n",
      "2025-01-09 16:02:30,501 [INFO] Applying univariate outlier detection for classification.\n",
      "2025-01-09 16:02:30,501 - INFO - Applying univariate outlier detection for classification.\n",
      "2025-01-09 16:02:30,515 [INFO] Step: Generate Preprocessor Recommendations\n",
      "2025-01-09 16:02:30,515 - INFO - Step: Generate Preprocessor Recommendations\n",
      "2025-01-09 16:02:30,520 [INFO] ✅ Preprocessor fitted on training data.\n",
      "2025-01-09 16:02:30,520 - INFO - ✅ Preprocessor fitted on training data.\n",
      "2025-01-09 16:02:30,524 [INFO] Step: Implement SMOTE (Train Only)\n",
      "2025-01-09 16:02:30,524 - INFO - Step: Implement SMOTE (Train Only)\n",
      "2025-01-09 16:02:30,525 [INFO] Class Distribution before SMOTE: {1: 52, 0: 27}\n",
      "2025-01-09 16:02:30,525 - INFO - Class Distribution before SMOTE: {1: 52, 0: 27}\n",
      "2025-01-09 16:02:30,526 [INFO] Imbalance Ratio (Minority/Majority): 0.5192\n",
      "2025-01-09 16:02:30,526 - INFO - Imbalance Ratio (Minority/Majority): 0.5192\n",
      "2025-01-09 16:02:30,527 [INFO] Dataset contains only numerical features. Using SMOTE.\n",
      "2025-01-09 16:02:30,527 - INFO - Dataset contains only numerical features. Using SMOTE.\n",
      "2025-01-09 16:02:30,529 [INFO] Applied SMOTE. Resampled dataset shape: (104, 14)\n",
      "2025-01-09 16:02:30,529 - INFO - Applied SMOTE. Resampled dataset shape: (104, 14)\n",
      "2025-01-09 16:02:30,530 [INFO] Step: Save Transformers\n",
      "2025-01-09 16:02:30,530 - INFO - Step: Save Transformers\n",
      "2025-01-09 16:02:30,535 [INFO] Transformers saved at 'C:\\Users\\ghadf\\vscode_projects\\docker_projects\\ml_preprocessor\\examples\\preprocessor\\transformers\\transformers.pkl'.\n",
      "2025-01-09 16:02:30,535 - INFO - Transformers saved at 'C:\\Users\\ghadf\\vscode_projects\\docker_projects\\ml_preprocessor\\examples\\preprocessor\\transformers\\transformers.pkl'.\n",
      "2025-01-09 16:02:30,537 - DEBUG - [DEBUG Inverse] Starting inverse transformation. Input shape: (25, 14)\n",
      "2025-01-09 16:02:30,537 - DEBUG - [DEBUG Inverse] pipeline.transformers_: ['num']\n",
      "2025-01-09 16:02:30,538 - DEBUG - [DEBUG Inverse] Transformer 'num' has features ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z'], slicing X_transformed from 0 to 14 => shape (25, 14)\n",
      "2025-01-09 16:02:30,539 - DEBUG - [DEBUG Inverse] Found scaler for numeric features ['release_ball_direction_x', 'release_ball_direction_z', 'release_ball_direction_y', 'elbow_release_angle', 'elbow_max_angle', 'wrist_release_angle', 'wrist_max_angle', 'knee_release_angle', 'knee_max_angle', 'release_ball_speed', 'calculated_release_angle', 'release_ball_velocity_x', 'release_ball_velocity_y', 'release_ball_velocity_z']. Inverting...\n",
      "2025-01-09 16:02:30,540 - DEBUG - [DEBUG Inverse] Inverse DataFrame shape: (25, 14)\n",
      "2025-01-09 16:02:30,546 - DEBUG - [DEBUG Inverse] Sample:\n",
      "   release_ball_direction_x  release_ball_direction_z  \\\n",
      "0                  0.389917                  0.918894   \n",
      "1                  0.254867                  0.949685   \n",
      "2                  0.285478                  0.953757   \n",
      "3                  0.379350                  0.924839   \n",
      "4                  0.151629                  0.983647   \n",
      "\n",
      "   release_ball_direction_y  elbow_release_angle  elbow_max_angle  \\\n",
      "0                 -0.059987            73.619348       103.832024   \n",
      "1                 -0.182048            67.358777       105.506006   \n",
      "2                 -0.094078            66.195867       104.714966   \n",
      "3                 -0.027690            57.723558       104.086466   \n",
      "4                 -0.097198            62.628834       104.002652   \n",
      "\n",
      "   wrist_release_angle  wrist_max_angle  knee_release_angle  knee_max_angle  \\\n",
      "0            21.754498        34.532455           32.856306       64.165568   \n",
      "1            26.738474        35.990742           33.981724       63.757296   \n",
      "2            24.793301        37.829797           29.563399       61.355174   \n",
      "3            27.624330        33.893509           27.569106       64.080024   \n",
      "4            29.715538        39.048699           32.831332       64.880979   \n",
      "\n",
      "   release_ball_speed  calculated_release_angle  release_ball_velocity_x  \\\n",
      "0           11.113489                 60.900817                 4.333333   \n",
      "1            9.987366                 60.402805                 2.545455   \n",
      "2            9.341053                 59.661842                 2.666667   \n",
      "3           10.943758                 63.128630                 4.151515   \n",
      "4            7.564887                 68.267426                 1.147059   \n",
      "\n",
      "   release_ball_velocity_y  release_ball_velocity_z  \n",
      "0                -0.666667                10.212121  \n",
      "1                -1.818182                 9.484848  \n",
      "2                -0.878788                 8.909091  \n",
      "3                -0.303030                10.121212  \n",
      "4                -0.735294                 7.441176  \n",
      "2025-01-09 16:02:30,546 [INFO] ✅ Inverse transformations applied successfully.\n",
      "2025-01-09 16:02:30,546 - INFO - ✅ Inverse transformations applied successfully.\n",
      "2025-01-09 16:02:30,547 [INFO] ✅ Preprocessing complete. X_train shape: (104, 14), X_test shape: (25, 14)\n",
      "2025-01-09 16:02:30,547 - INFO - ✅ Preprocessing complete. X_train shape: (104, 14), X_test shape: (25, 14)\n",
      "2025-01-09 16:02:30,548 - INFO - Starting the Bayesian hyperparameter tuning process...\n",
      "2025-01-09 16:02:30,549 - WARNING - Unsupported model: XGBoost. Skipping.\n",
      "2025-01-09 16:02:30,550 - INFO - 📌 Tuning hyperparameters for Random Forest...\n",
      "2025-01-09 16:02:30,550 - INFO - Starting hyperparameter tuning for Random Forest...\n",
      "2025-01-09 16:02:30,554 - INFO - Parameter space: {'n_estimators': Integer(low=10, high=500, prior='uniform', transform='identity'), 'max_depth': Integer(low=2, high=50, prior='uniform', transform='identity'), 'min_samples_split': Integer(low=2, high=20, prior='uniform', transform='identity'), 'min_samples_leaf': Integer(low=1, high=10, prior='uniform', transform='identity'), 'max_features': Categorical(categories=('sqrt', 'log2', None), prior=None), 'bootstrap': Categorical(categories=(True, False), prior=None), 'criterion': Categorical(categories=('gini', 'entropy'), prior=None)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "types of all variables starting with X_train <class 'pandas.core.frame.DataFrame'> X_test type <class 'pandas.core.frame.DataFrame'> y_train type = <class 'pandas.core.series.Series'> y_test type = <class 'pandas.core.series.Series'> X_test_inverse type = <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghadf\\anaconda3\\envs\\data_science_ml_preprocessor\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [True, 'gini', 50, 'log2', 2, 2, 10] before, using random point [True, 'entropy', 43, None, 9, 17, 137]\n",
      "  warnings.warn(\n",
      "2025-01-09 16:03:44,887 - INFO - Best parameters found: OrderedDict([('bootstrap', True), ('criterion', 'gini'), ('max_depth', 50), ('max_features', 'log2'), ('min_samples_leaf', 1), ('min_samples_split', 2), ('n_estimators', 10)])\n",
      "2025-01-09 16:03:44,888 - INFO - Best cross-validation score: -0.47375842858482853\n",
      "2025-01-09 16:03:44,889 - INFO - ✅ Random Forest tuning done. Best Params: OrderedDict([('bootstrap', True), ('criterion', 'gini'), ('max_depth', 50), ('max_features', 'log2'), ('min_samples_leaf', 1), ('min_samples_split', 2), ('n_estimators', 10)]), Best CV Score: -0.47375842858482853\n",
      "2025-01-09 16:03:44,890 - INFO - Evaluating model...\n",
      "2025-01-09 16:03:44,934 - INFO - Predicted probabilities: [0.1 0.7 0.8 0.3 1.  0.5 0.7 0.6 0.9 1.  1.  0.4 0.9 0.9 0.2 0.8 0.7 0.5\n",
      " 0.4 0.5 0.9 0.6 1.  0.9 1. ]\n",
      "2025-01-09 16:03:44,941 - INFO - Evaluation Metrics: {'accuracy': 0.72, 'precision': 0.7329411764705881, 'recall': 0.72, 'f1_score': 0.7253333333333333, 'roc_auc': 0.7182539682539683, 'log_loss': 1.891565604167116}\n",
      "2025-01-09 16:03:44,944 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.57      0.53         7\n",
      "           1       0.82      0.78      0.80        18\n",
      "\n",
      "    accuracy                           0.72        25\n",
      "   macro avg       0.66      0.67      0.67        25\n",
      "weighted avg       0.73      0.72      0.73        25\n",
      "\n",
      "2025-01-09 16:03:44,945 - INFO - Classification report saved to C:\\Users\\ghadf\\vscode_projects\\docker_projects\\ml_preprocessor\\examples\\preprocessor\\models\\classification_report.txt\n",
      "2025-01-09 16:03:45,071 - INFO - Confusion matrix saved to 'C:\\Users\\ghadf\\vscode_projects\\docker_projects\\ml_preprocessor\\examples\\preprocessor\\models\\confusion_matrix.png'\n",
      "2025-01-09 16:03:45,072 - INFO - Original X shape: (25, 14)\n",
      "2025-01-09 16:03:45,072 - INFO - X has more than 2 features, applying PCA for visualization.\n",
      "2025-01-09 16:03:45,074 - INFO - PCA explained variance ratios: [0.45925915 0.23948802]\n",
      "2025-01-09 16:03:45,074 - INFO - Transformed X shape for plotting: (25, 2)\n",
      "2025-01-09 16:03:45,081 - INFO - Mesh grid created with shape xx: (1375, 1319), yy: (1375, 1319)\n",
      "2025-01-09 16:03:45,087 - INFO - Grid points in 2D PCA space shape: (1813625, 2)\n",
      "2025-01-09 16:03:45,088 - INFO - Inverse transforming grid points back to original feature space for prediction.\n",
      "2025-01-09 16:03:45,173 - INFO - Grid points in original feature space shape: (1813625, 14)\n",
      "c:\\Users\\ghadf\\anaconda3\\envs\\data_science_ml_preprocessor\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-01-09 16:03:45,332 - INFO - Decision boundary predictions reshaped to: (1375, 1319)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0wAAAK7CAYAAADBfQ+iAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAjABJREFUeJzs3Xl4VOX5xvH7TJbJHgIJYU/YgiCyIyKKAiriUtyLGyVWfoootFhraaiiElHRtqKFVmqj1KoognUpIgYVNxQRBEUSA7IFCHsWyJ7z+yNkTEgGMmEmZ5bv57pySc45M/Mkk8S5533f5zVM0zQFAAAAAKjHZnUBAAAAAOCtCEwAAAAA4ASBCQAAAACcIDABAAAAgBMEJgAAAABwgsAEAAAAAE4QmAAAAADACQITAAAAADhBYAIAAAAAJwhMAHzaCy+8IMMwHB/BwcFq27atxo0bpx9//NGyumbOnCnDMCx7/BN99NFHdb5PtT+uu+46q8tr0Lx58/TCCy80+vrk5GTH12Sz2RQbG6uePXtq/Pjxev/99z1X6HETJkxQcnKyS7fZtm2bDMNw6et0l5qf0drfs7Zt2+qyyy7TZ5991uz1uMrK7x2AwBJsdQEA4A4ZGRk644wzVFJSos8++0zp6en68MMPtXnzZsXFxVldntd49NFHNWLEiDrHWrVqZVE1Jzdv3jzFx8drwoQJjb7NsGHD9OSTT0qSioqKlJWVpVdffVWjR4/Wtddeq1deeUUhISEeqfdPf/qTpk6d6tJt2rZtqy+++EJdu3b1SE2N8d577yk2NlZVVVXasWOHnnjiCV144YX68ssvNWDAAMvqAgBvQWAC4Bd69+6tQYMGSZIuvPBCVVZW6sEHH9Sbb76p1NRUi6vzHt27d9c555zj9vstLi5WWFiY5aNqLVq0qPP1XXTRRZo8ebJmzpyphx56SDNmzNDjjz/ukcduSuix2+0eeT5cMXDgQMXHx0uSzj33XJ199tnq2rWrFi9eHFCByVt+hgF4H6bkAfBLNeEpLy/PcaykpET33nuv+vXrp9jYWLVs2VJDhw7Vf//733q3NwxDd999t/7973+rZ8+eioiIUN++ffXOO+/Uu/bdd99Vv379ZLfb1blzZ8cIx4lKSko0ffp0de7cWaGhoWrfvr0mT56sI0eO1LkuOTlZV1xxhd555x31799f4eHh6tmzp+OxX3jhBfXs2VORkZE6++yz9fXXXzf121TPp59+qlGjRik6OloRERE699xz9e6779a5pmYa5Pvvv6/bbrtNCQkJioiIUGlpqSRp0aJFGjp0qCIjIxUVFaXRo0dr3bp1de5j69atGjdunNq1aye73a7ExESNGjVK69evd3wPvv/+e3388ceOKWOuTnerbebMmTrzzDP17LPPqqSkxHG8rKxMs2bN0hlnnCG73a6EhASlpqZq//799e7j5Zdf1tChQxUVFaWoqCj169dPzz//vON8Q1PyXn/9dQ0ZMkSxsbGKiIhQly5ddNtttznOO5tW5srz8OGHH2rSpEmKj49Xq1atdM0112j37t1N/l7FxsZKUr2RuB07duiWW25R69atZbfb1bNnTz311FOqqqpyXFMz9fOjjz6qc9uGvs4JEyYoKipKOTk5uuyyyxQVFaWOHTvq3nvvdfws1di9e7duuOEGRUdHKzY2Vr/85S+1d+/eerV//fXXGjdunJKTkxUeHq7k5GTdeOON2r59e53rnP0Mf/rppzIMQ6+88kq9+164cKEMw9CaNWsa9X0E4D8ITAD80k8//SRJSklJcRwrLS3VoUOH9Lvf/U5vvvmmXnnlFZ133nm65pprtHDhwnr38e677+rZZ5/Vww8/rDfeeEMtW7bU1Vdfra1btzquyczM1NixYxUdHa1XX31Vc+bM0WuvvaaMjIw692Wapq666io9+eSTuvXWW/Xuu+9q2rRpevHFFzVy5Mh6LxC//fZbTZ8+Xffff7+WLFmi2NhYXXPNNXrwwQf1z3/+U48++qj+85//KD8/X1dccYWKi4sb9X2pqqpSRUVFnY8aH3/8sUaOHKn8/Hw9//zzeuWVVxQdHa0rr7xSixYtqndft912m0JCQvTvf/9bixcvVkhIiB599FHdeOON6tWrl1577TX9+9//VmFhoc4//3xt2rTJcdvLLrtMa9eu1RNPPKEVK1Zo/vz56t+/vyM8Ll26VF26dFH//v31xRdf6IsvvtDSpUsb9TU6c+WVV+rYsWOOgFlVVaWxY8fqscce00033aR3331Xjz32mFasWKELL7ywzvf0gQce0M0336x27drphRde0NKlS/WrX/2q3gvx2r744gv98pe/VJcuXfTqq6/q3Xff1QMPPFDne94QV5+H22+/XSEhIXr55Zf1xBNP6KOPPtItt9zS6O9LZWWlKioqVFZWppycHE2ePFl2u73O2rb9+/fr3HPP1fvvv69HHnlEb731li666CL97ne/0913393oxzpReXm5fvGLX2jUqFH673//q9tuu01/+ctf6owCFhcX66KLLtL777+v2bNn6/XXX1ebNm30y1/+st79bdu2TT169NBf//pXLV++XI8//rj27NmjwYMH68CBA/WuP/Fn+Nxzz1X//v31t7/9rd61zz77rAYPHqzBgwc3+esF4KNMAPBhGRkZpiRz9erVZnl5uVlYWGi+9957Zps2bczhw4eb5eXlTm9bUVFhlpeXm7/+9a/N/v371zknyUxMTDQLCgocx/bu3WvabDZz9uzZjmNDhgwx27VrZxYXFzuOFRQUmC1btjRr/4l97733TEnmE088UedxFi1aZEoyn3vuOcexpKQkMzw83Ny1a5fj2Pr1601JZtu2bc2jR486jr/55pumJPOtt9466ffpww8/NCU1+PHjjz+apmma55xzjtm6dWuzsLCwzveod+/eZocOHcyqqirTNH/+no8fP77OY+zYscMMDg4277nnnjrHCwsLzTZt2pg33HCDaZqmeeDAAVOS+de//vWkNZ955pnmBRdccNJraktKSjIvv/xyp+fnz59vSjIXLVpkmqZpvvLKK6Yk84033qhz3Zo1a0xJ5rx580zTNM2tW7eaQUFB5s0333zSx//Vr35lJiUlOT5/8sknTUnmkSNHnN7mp59+MiWZGRkZjmOuPg933XVXnft84oknTEnmnj17Tlrvgw8+2ODPQ0xMjLlkyZI61/7hD38wJZlffvllneOTJk0yDcMws7KyTNP8+efsww8/POXX+atf/cqUZL722mt1rr3sssvMHj16OD6ved7++9//1rlu4sSJ9e7zRBUVFWZRUZEZGRlpPv30047jzn6Ga59bt26d49hXX31lSjJffPFFp48FwH8xwgTAL5xzzjkKCQlRdHS0Lr30UsXFxem///2vgoPrLtV8/fXXNWzYMEVFRSk4OFghISF6/vnn9cMPP9S7zxEjRig6OtrxeWJiolq3bu0YVTh69KjWrFmja665RmFhYY7rakYDalu5cqUk1WtgcP311ysyMlKZmZl1jvfr10/t27d3fN6zZ09J1euzIiIi6h0/2UhHbY8//rjWrFlT56Njx446evSovvzyS1133XWKiopyXB8UFKRbb71Vu3btUlZWVp37uvbaa+t8vnz5clVUVGj8+PF1RrDCwsJ0wQUXOKZptWzZUl27dtWcOXP05z//WevWraszrctTTNOs8/k777yjFi1a6Morr6xTb79+/dSmTRtHvStWrFBlZaUmT57s0uPVjETccMMNeu2115Sbm3vK2zTlefjFL35R5/M+ffpIavzPxAcffKA1a9boq6++0jvvvKOLLrpI48aNqzOit3LlSvXq1Utnn312ndtOmDBBpmk6fr5dZRhGvd+VPn361Kn9ww8/VHR0dL2v86abbqp3f0VFRbr//vvVrVs3BQcHKzg4WFFRUTp69GiDv+Mn/gxL0o033qjWrVvXGWV65plnlJCQ0OCoFgD/R2AC4BcWLlyoNWvWaOXKlbrjjjv0ww8/6MYbb6xzzZIlS3TDDTeoffv2eumll/TFF19ozZo1uu222+qsa6nRUPc4u93umKp1+PBhVVVVqU2bNvWuO/HYwYMHFRwcrISEhDrHDcNQmzZtdPDgwTrHW7ZsWefz0NDQkx5vqP6GdOnSRYMGDarzYbfbdfjwYZmmqbZt29a7Tbt27RxfQ20nXluzXmzw4MEKCQmp87Fo0SLHlCjDMJSZmanRo0friSee0IABA5SQkKApU6aosLCwUV9HU9S8CK/5evLy8nTkyBGFhobWq3fv3r2OemvWM3Xo0MGlxxs+fLjefPNNR4js0KGDevfu3eD6mBpNeR5O/Dm12+2S1Ohpmn379tWgQYM0ePBgXX755Xr99dfVrVu3OgHx4MGDLtXUWBEREXXebKipv/bP88GDB5WYmFjvtg393t1000169tlndfvtt2v58uX66quvtGbNGiUkJDT4/Wjoa7Lb7brjjjv08ssv68iRI9q/f79ee+013X777Y7vLYDAQpc8AH6hZ8+ejkYPI0aMUGVlpf75z39q8eLFjrUYL730kjp37qxFixbV6YR14vqhxoqLi5NhGA0uPj/xWKtWrVRRUaH9+/fXCU2maWrv3r2Wr4uIi4uTzWbTnj176p2raSBQ00mtxondxGrOL168WElJSSd9vKSkJEfDhOzsbL322muaOXOmysrK9Pe//73JX4czpmnq7bffVmRkpOPnpKZJwnvvvdfgbWpGF2uer127dqljx44uPe7YsWM1duxYlZaWavXq1Zo9e7ZuuukmJScna+jQofWub8rz4G42m01nnnmmXn/9de3bt0+tW7dWq1atGlVTTfg58XeqofVDjdWqVSt99dVX9Y6f+DuWn5+vd955Rw8++KD+8Ic/OI7XrF1siLOOeJMmTdJjjz2mf/3rXyopKVFFRYXuvPPOJn8NAHwbI0wA/NITTzyhuLg4PfDAA47pXoZhKDQ0tM6LpL179zbYJa8xarrULVmypM474oWFhXr77bfrXDtq1ChJ1aGttjfeeENHjx51nLdKZGSkhgwZoiVLltR5J76qqkovvfSSOnToUKeBRkNGjx6t4OBgbdmypd4oVs1HQ1JSUjRjxgydddZZ+uabbxzHa4/mna6HHnpImzZt0tSpUx0v6q+44godPHhQlZWVDdbao0cPSdIll1yioKAgzZ8/v8mPb7fbdcEFFziaGZzYNbCGO56H01VZWamNGzfKbrcrJiZGUvXP76ZNm+o8P9LPneNq9vaq6RK4YcOGOte99dZbTa5nxIgRKiwsrHcfL7/8cp3PDcOQaZr1RoH++c9/qrKy0qXHbNu2ra6//nrNmzdPf//733XllVeqU6dOTfsCAPg8RpgA+KW4uDhNnz5dv//97/Xyyy/rlltu0RVXXKElS5borrvu0nXXXaedO3fqkUceUdu2bfXjjz826XEeeeQRXXrppbr44ot17733qrKyUo8//rgiIyPrvKt98cUXa/To0br//vtVUFCgYcOGacOGDXrwwQfVv39/3Xrrre760pts9uzZuvjiizVixAj97ne/U2hoqObNm6fvvvtOr7zyyin3p0lOTtbDDz+stLQ0bd261bGWLC8vT1999ZUiIyP10EMPacOGDbr77rt1/fXXq3v37goNDdXKlSu1YcOGOiMDZ511ll599VUtWrRIXbp0UVhYmM4666yT1nDkyBGtXr1aUvV6oJqNaz/55BPdcMMNeuihhxzXjhs3Tv/5z3902WWXaerUqTr77LMVEhKiXbt26cMPP9TYsWN19dVXKzk5WX/84x/1yCOPqLi4WDfeeKNiY2O1adMmHThwoM591vbAAw9o165dGjVqlDp06KAjR47o6aefVkhIiC644AKPPQ+uWrt2raOVeF5env71r39p8+bN+u1vf+sIl7/97W+1cOFCXX755Xr44YeVlJSkd999V/PmzdOkSZMcIa5Nmza66KKLNHv2bMXFxSkpKUmZmZlasmRJk+sbP368/vKXv2j8+PFKT09X9+7d9b///U/Lly+vc11MTIyGDx+uOXPmKD4+XsnJyfr444/1/PPPq0WLFi4/7tSpUzVkyBBJqtf1EkCAsbDhBACctpqOVmvWrKl3rri42OzUqZPZvXt3s6KiwjRN03zsscfM5ORk0263mz179jQXLFjg6BZWmyRz8uTJ9e4zKSnJ/NWvflXn2FtvvWX26dPHDA0NNTt16mQ+9thjDd5ncXGxef/995tJSUlmSEiI2bZtW3PSpEnm4cOH6z1GQ93eGqqppvvYnDlznH6PTPPn7mWvv/76Sa/75JNPzJEjR5qRkZFmeHi4ec4555hvv/12nWtO9j03zerOfSNGjDBjYmJMu91uJiUlmdddd535wQcfmKZpmnl5eeaECRPMM844w4yMjDSjoqLMPn36mH/5y18cz5Npmua2bdvMSy65xIyOjjYl1elA15CkpCRHpzfDMMyoqCizR48e5q233mouX768wduUl5ebTz75pNm3b18zLCzMjIqKMs844wzzjjvucHQPrLFw4UJz8ODBjuv69+9fr+tb7Rrfeecdc8yYMWb79u3N0NBQs3Xr1uZll11mfvLJJ45rGuoeZ5qn9zw461R3ooa65LVs2dIcMmSI+a9//cusrKysc/327dvNm266yWzVqpUZEhJi9ujRw5wzZ0696/bs2WNed911ZsuWLc3Y2FjzlltuMb/++usGu+RFRkY6rau2Xbt2mddee60ZFRVlRkdHm9dee635+eef17vPmuvi4uLM6Oho89JLLzW/++67er+3p/oZrpGcnGz27NnzpNcA8H+GaZ7QNggAACDAbdiwQX379tXf/vY33XXXXVaXA8BCBCYAAIDjtmzZou3bt+uPf/yjduzYoZycnDqt/AEEHpo+AAAAHPfII4/o4osvVlFRkV5//XXCEgBGmAAAAADAGUaYAAAAAMAJAhMAAAAAOEFgAgAAAAAnAmrj2qqqKu3evVvR0dFu3/gPAAAAgO8wTVOFhYVq166dbDbn40gBFZh2796tjh07Wl0GAAAAAC+xc+dOdejQwen5gApM0dHRkqQbp72iULvzNqH7ikr1wNSzpHt+31ylwcc83O0WtY4Ks7oMAAAANFFZ6TG98ucbHRnBmYAKTDXT8ELtEQoNi3R6XUh5kKKio6WQkOYqDT4mxB6h0LBwq8sAAADAaTrVUh2aPgCuWjDX6goAAADQTAhMQJPQNAQAACAQEJgAAAAAwAkCEwAAAAA4QWACAAAAACcITA0yrS4AAAAAgBcgMDkzcYrVFQAAAACwGIEJAAAAAJwgMAEAAACAEwQmAAAAAHCCwAQAAAAAThCYAAAAAMAJAhPgorQ565QYHWZ1GQAAAGgGBCYAAAAAcILABAAAAABOEJgAAAAAwAkCEwAAAAA4QWACAAAAACcITCfIKyy2ugQAAAAAXoLA1IDFo1ZaXQIAAAAAL0BgAgAAAAAnCEwAAAAA4ASBCQAAAACcIDABAAAAgBMEJsAFaSmpVpcAAACAZkRgAlyUGB1udQkAAABoJgQmAAAAAHCCwAQAAAAAThCYAAAAAMAJAhMAAAAAOEFgAgAAAAAnCEwNKPrfZqtLAAAAAOAFCEwNyN1O22gAAAAABCYAAAAAcIrABAAAAABOEJgAAAAAwIlgqwsAfEX7pGKrSwAAAAGs+OgR/fT9xyo+mq+o2AR17jVcoWGRVpfl9whMAAAAgBczTVNrP3xR337yqkzTVHBIlMrLCvT5/+ZpyCW3q9fZY60u0a8RmAAAAAAvtu7j/2jdxy+pTbsxSki8UMEhUSorO6K83cv02bvPKDg0XCn9LrG6TL/FGiYAAADAS5WVHNW3ny5S6zYXqW2HKxQcEiVJCg1toQ5J49SiZX+tXblQVVWVFlfqvwhMAAAAgJfa+eNXqigvVkKbC+udMwxDCYkjVJS/V/tzs5q/uABBYAIAAAC8VGlxoSRDISEtGjwfam8pSSorKWq+ogIMgQkAAADwUjEt20kydezotgbPHy3cKkmKjmvXfEUFGAITAAAA4KXademvqNg22pP7jswT1ilVVpYob89ytel0llrEd7CoQv9HYKolr5B9dgAAAOA9bLYgnf+L36ioMEfZm5/SoYNf69jRHTqw7zNlb5qjiorDOvfyu60u06/RVvwE6dkZVpcAAAAAOHToNkiXT5ijrzMztH1LzWtVQx27n62zL75dLRM7W1qfvyMwAQAAAF6ubdJZuvK2P6voSJ6Kj+UrMjpeEdEtrS4rIDAlD2ik2EfusLoEAAAQ4KJaJCqhXQphqRkRmIBGunpWkGyGYXUZAAAAaEYEJsAFCVFhVpcAAACAZkRgAgAAAAAnCEwAAAAA4ASBCQAAAACcIDABAAAAgBMEJgAAAABwgsAEAAAAAE4QmAAAAADACQLTcXmFJVaXAAAAAMDLEJhqSb+vv9UlAAAAAPAiPhWYcnNzdcstt6hVq1aKiIhQv379tHbtWqvLAgAAAOCnfCYwHT58WMOGDVNISIiWLVumTZs26amnnlKLFi2sLg0BoNfC8VaXAAAAAAsEW11AYz3++OPq2LGjMjIyHMeSk5NPepvS0lKVlpY6Pi8oKPBUeQgIhtUFAAAAoJn5zAjTW2+9pUGDBun6669X69at1b9/fy1YsOCkt5k9e7ZiY2MdHx07dmymagEAAAD4A58JTFu3btX8+fPVvXt3LV++XHfeeaemTJmihQsXOr3N9OnTlZ+f7/jYuXNnM1YMAAAAwNf5zJS8qqoqDRo0SI8++qgkqX///vr+++81f/58jR/f8PoSu90uu91e7/i+ohJ1CIv0aL0AAAAAfJ/PjDC1bdtWvXr1qnOsZ8+e2rFjR5PuL6+wWHmFxe4oDQAAAICf8pkRpmHDhikrK6vOsezsbCUlJbl8Xw/kvKSokBClpaTWCk0s6AcAAABQl8+MMP32t7/V6tWr9eijjyonJ0cvv/yynnvuOU2ePLnJ95menaEXSucd/8x0T6EAAAAA/IbPBKbBgwdr6dKleuWVV9S7d2898sgj+utf/6qbb775tO43d3u40rMzNHxMN/Wyf+2magEAAAD4A5+ZkidJV1xxha644gqP3Pfop9O0ySP3DAAAAMBX+cwIEwAAAAA0NwITAAAAADhBYAIa4epZQVaXAAAAAAsQmIBGSowOs7oEAAAANDMCEwAAAAA4QWACAAAAACcITAAAAADgBIEJAAAAAJwgMAEAAACAEwQmAAAAAHCCwAQAAAAAThCYAAAAAMAJAhMAAAAAOEFgAgAAAAAnCEzAKSyfmm51CQAAALAIgQloBJthWF0CAAAALEBgAgAAAAAnCEwAAAAA4ASBCQAAAACcIDABAAAAgBMEJgAAAABwgsAEAAAAAE4QmAAAAADACQITAAAAADhBYAIAAAAAJwhMAAAAAOAEgQk4hVXLcqwuAQAAABYhMAEn0T6pWJKUEBVmcSUAAACwAoEJAAAAAJwgMAEAAACAEwQmAAAAAHCCwAQAAAAAThCYAAAAAMAJAhMAAAAAOEFgAgAAAAAnCEwAAAAA4ASBCQAAAACcIDABAAAAgBMEJuAkJtjvsroEAAAAWIjABJxCYnS41SUAAADAIgQmAAC8TF5hsfIKi60uAwAgKdjqAgAAQDVCEgB4H0aYAACwWM2I0vAx3ZSenaH07AyrSwIAHMcIEwAAFskrLJFkKv2+/tLEKVK21RUBAE5EYAIAoJnVBCVJeqF0nnIn0lwGALwVgQkAgGayv6hEVWZ1UFo8aqWy5m9XrghLAODNCEwAAHhY7RGlpTMqtWn8QmUx/Q4AfAKBCQAAD6rpfFezTmnT+FPfpn0S3fIAwFsQmAAA8ICaoDR8TDeNfjpNmkjnOwDwRQQmAADcqPZeSunZGXS+AwAfR2ACnOgxKUnKtLoKAL6iXlACAPgFAhPgRNDQC6RMw+oyAPgQghIA+B+b1QUAAAAAgLciMAEAAACAEwQmAABO0/6iEqtLAAB4CIEJAAA3GD6mm9UlAAA8gMAEAAAAAE4QmAAAAADACQITAAAAADhBYAJw2vYXlSivkEXvgLtMsN8liX3gAMAbsHEtgCapDkhmvWOJ0WHWFAT4GX6XAMA7EJgANNqJIWnpjEptGr+w+pMFc5U2Z70ldQEAAHgKgQlw4upZQVaX4BVODEkvlM5T7vZwSdKm8SdebZ54AAAAwKcRmICTCNQpMfuLSlRl/hx+0rMzHP/OVXjDN5o4RUpJ9XRpAAAAzYrABEBS3ZGkmg04Rz+dZmFFAAAA1iMwAQEsr7DY8e+lMyolqXpNUvbp3WditJNRKAAAAB9DYAICTO2QJEmLR61U1vztDaxHct3iUSt1XebI078jAAAAL0FgAgLAiSGp9pqkrNMYTQJQrco0Nbp3tNVlAAA8gMAE+KnaIWn4mG7Nsh4pa/52KcXjDwN4p4lTrK4AAOABNqsLAOAphuNfq5blqNdCN8y5AwAACDCMMAF+qnZL9LzCkup9pY63/a5Zt+QpNH4AAAD+ghEmIAAkRocpMTr8eIgxdF3mSKWlpCrNA/sm1V4fBcBFC+Z65PcSANB0jDABAabuyFOx48XZC6XzlLudUSHACr0Wjq8eBZ6zjtFZAPAyBCYggNW8MMsrLNEE+12Ohg1LZ1RW78d0GvYXlSghKuzUFwIBrMekpOpW/LNEUAIAL0VgAhrQY1KSlGl1Fc2n9qjT/qK6652aEp6Gj+mmT9/b4tYaAX/SPqm4+k2KTEky6vwOAgC8C4EJaMDc0P+TFJgv+GuPCp3YLMKV9UlVpun22gB/8PMaJYISAPgCAhPghM049TX+ztl6p1ONOo1+Ok2rWLgO1FG7mQPT7wDAdxCYACcYIamr5gXeiVP2PN2iHPB1BCUA8G0+21Z89uzZMgxDv/nNb6wuBX5o9NNpGj6mm/IKi5VXWGx1OV4lIap2i3LVbVG+YG6da/MKS6woEfAKtVv31/6dAQD4Fp8cYVqzZo2ee+459enTx+pS4MdGP52m244vzM4rLJbNMOj6doLaLwDzCkuUNmedlJKq4WO6aenALF09yyf/xPi8mpDPC3RrMKIEAP7F50aYioqKdPPNN2vBggWKi4uzuhz4udzt4UrPztDSGZWqMk1Gm06i9ua4q5blVE/bQ7OqGRFdOqPS6lICSs1I6vKp6YwoAYAf8rnANHnyZF1++eW66KKLTnltaWmpCgoK6nwATbFp/EKlZ2co/b7+x1+UMtXsZGpeLNIBrHnkFZYor7BYw8d0U3p2xmnvoYWmWbUsh6AEAH7Ip+bLvPrqq/rmm2+0Zs2aRl0/e/ZsPfTQQx6uCgFl4hS9UGuaHm2BYaWaEc/hY7rptjenKfdpXqhbgb8BAODffGaEaefOnZo6dapeeuklhYU17n9O06dPV35+vuNj586dHq4SgaBmmt7iUSslMU0Pza92M5LFo1Zq9NNpyt1OWAIAwBN8ZoRp7dq12rdvnwYOHOg4VllZqVWrVunZZ59VaWmpgoLqrpmw2+2y2+3NXSoCRNb87UpXhtJSUllkj2ZT87P2Quk85W4PV1a2xQUBAODnfCYwjRo1Shs3bqxzLDU1VWeccYbuv//+emEJaC7p2RmSVCs4MU0P7lW9Zq56X7D0+/pLE6coV87DefskRj0BAHAXnwlM0dHR6t27d51jkZGRatWqVb3jgBVODE6MNuF0NRSUNDHjlLebYL9LkuHZ4gAACBA+s4YJ8BU1wYlNb9FUNV3vJFNLZ1RW/0xNnOLSfTDKCQCAe/jMCFNDPvroI6tLABrEaBOa6sQ1SpvGW1wQAAABjhEmwIMYbUJj1f4ZSc/OoOsdAABewqdHmABfUL8pBN308LPaeymNfjrN4moAAMCJCExAM2GaHmpzjCbVNHPwovbgP4+G0vERAACm5AHNLD07Q8PHdGOaXoD6uaFD9TolV5s5eFLtn8kXSueppkMfAACBjBEmwAKjn07TaLF3UyDZX1SiKrM6gCwetVJZ87efdC+l5lSnffnxkdBchSt9QX+lzVnPzyYAIKARmAALpWdnqMekJF2XOZJpen6qdhhZOqNSm8YvVFYzTb+rPYLZ0M9W7dpquvLV1uObpySN9GSJAAB4PabkARbLmr9d6dkZWjqjkml6fqShvZQ2jV/YjI9fe2qds/OmFo9a6bQrX9b87XXuCwCAQMQIE+AlNo1fqHRJWjBXaXPWiWl6vql2uKiZetfceyktHrVS0vHAk1T3XE19jR3tWjxqpa7LZJQJAPxdweE9+mHNO9q9dZ1M01Tb5LPUc/Av1CK+g9WlWc4wTTNgVvUWFBQoNjZWX4y5UlEhIVaXAzjVPqlYE+x3Hf+M4OQrTtx01hvU/Vmq1ZXPBWkpqZJohw8A/mrb5s+U+dosGUaIYlucJcmmgvyNqqws1oVX/17d+oyyukSPKCs5qhdnj1V+fr5iYmKcXscIE+CFcreHK12sb/IFtZs5SMc3nfWSZg5S9c+SUmrt8zQxw+X7SM/OcIQmAIB/KTi8R5mvzVJMbG8ldR4vW1CoJKmqqlw7t72qj5Y8rpaJndUysYvFlVqHwAR4saz525WujFrT9HiX35vU20vJS6VnZ7hln6f9RSVKiGK0EwD8yQ9r3pbNCKkTliTJZgtRp+SbVFS4Wd9/+abO/8U0C6u0Fk0fAF8wcYqj3XN1Y4gSiwtCXmGxho/pVv28eHFYcpfhY7rVGUkDAPiH3C3rFNOiT52wVMOwBSm2RX/lbllnQWXeg8AE+JD07AzHhqJ0LrNWYnS4Vi3LUVpKqtJSUrV8arrVJXnU6KfTJImwDgB+xpQpw3AeCQzDpgBqedAgAhPgY3K3h58w2kRwskpidLjjo3Z4ap/kn8/J0hmVqtm3CQDgH9om9VbBkY2qqiqvd840q5R/5Fu1TT7Lgsq8B4EJ8FHp2RlM0/MiNcFJkibY73KMOvlTeGrOfaQAAM2j1+BfqKLiqHZtf02mWek4bppVyt2xVKUlB3TmkKusK9AL0FYc8AO9Fo7X1bOCJNEUwpvUHv1Lv6+/enzzlGMzWJ91vAEJP2cA4D+y17+vj998UqGhsYqN6y9DhvKPfKvSkgM697J7dOaQsVaX6BGNbStOYAL8SO3Wz7yg9R4/j/5V/7l1tPj2QTX7OvHzBQD+5eDeLfpu9dLjG9dKbZPPUu9zrlJC+zOsLs1jCEwNIDAhULDRqHerPfLkTZvcNtbyqelatSyHny8AgE9rbGBiDRPgh9KzMzR8TDe3NoXIKyyhyYSb/LzeyXCsd/KlZhG+OjoGAEBTEJgAPzX66TS3dNPbX1Ry/LamFo9a6cYKkRgdVq9ZhC8hPAMAAgGBCfBz6dkZjqDj6gvcvMJiVZmmls6oVHp2hqNhwf4iOvK5U83zUhNwfYEv1QoAwOkItroAAJ6XNX+70pXh6HAmnXx9k+MF/H39pYlTtGn8z+eWzqjU1bP40+EOJ36fa+sxKUnXZY6sc2zpjEqva+2dV1jMWiYAgF+j6QMQgGoW7UuGEqPDHMdrXsCfrItbTQtzXiQ3XXXXPLPB73NNFzpJshmGEqKqn5/9RSWqqvXn2huaRdAxDwDgyxrb9IG3iYEANPrpNN12/MVudUgyVNPyOj07Q8p2fttN4xdKtdqXwzU1ofSF0nnKfbpu0Pi5LXzdICvJEZxq7mOC/a7qUUML5W4Pl1KqA+CJ9QIA4C8ITECAyt0ernRlqMekJAUNvUCVX3zs+5uqerE6m9hmZyhXP4clV/fPSowO95qGC4tHraw3dRAAAH9CYAICXNb87dJ819fFsHal8Zw1dfCHjYaz5m/X8KndtGrZFkaZAAB+iS55AFz2Quk8q0vwCT+3ZK8blmr2XZJUp614Y1WvgfIevx2YpZopnQAA+BtGmADAA2qCUu3Odu4cUaq+39O6C7epWdfGqCMAwB8RmADAjWo64NVuye4PU+9OhbVMAAB/RWAC4LKa7mj4WU1Qko53wJsYXqt9u/8GpRpZ87cf75jHKBMAwL+whgkATlP19DtTi0etVHp2hmIfuUNpKalatSynSWuUfNWJTS0AAPAHBCYATZJ+X3+vaW1tpRObOqSlpDo29g2UoHSi/UXe1ZQCAIDTQWAC0DQTp1hdgaXyCkvqbEKblpKq6zJHymYYARuUJGn4mG6qMumYBwDwHwQmAE02fEw35RUWB9xIU+0peJI0wX6XpOqglBAV2HsRjX46TRKjTAAA/0FgAtBko59Oc0xFyyss9skXyVWVFSo8kqdjhYdOeW3NqFL6ff0lydEVrnr6XWAHpdqWzqhklAkA4DfokgfgtKVnZ6jXwvG6elaQS13S9heVHH9hbTR74KgoL9X6VS/rh6/fVcmxI5KkVm26q9/wcepy5gV1rq3dAU+S0uask+T/ne+aqmZfJgAA/AEjTADcYtP4hUrPznA0g6gOGQ2rGampMo/vV6TmHY2oKC/TsoV/0Lefvq7o6L7qmnKXkrvepvLiEGW+9oi+/XRRrVqL69UXyA0dGqtmuiYAAL6OwATAvSZO0Qul8zR8TNd6wenn9U6mls6orJ7OZ0HziE1f/Vd5Ozepa4971CHpBsW0OFNxrQaqS8pdat32Yn214p8qOLS73gt+glLj3fbmNKtLAADALQhMANwud3u4Rj+ddrwpglmnMcQLpfOUnp1RPW3LIpvWvKMWLQcoKrpLneOGYahtu8sUFBymb1a/7TjufUHJ+9cH5W4PZ5QJAOAXCEwAPCZr/nalZ2do6YxKSdVrnXK3Nxw8muuFdVVVpQoP5yoqunuD521BoYqI7KzCQ7u8MCj9zMrA2Vg1HfNONj0TAABvR2AC4HE165uceaF0XrPVYhg2BQWHqqK8wOk1FeX5ioqIbLaa/Fl1WPb+ETEAAJwhMAEIKIZhqHOv4Tp0cLWqqsrrnS8q3KriY7nq0mu4BdX5H18YCQMA4GQITAAs52yanqf0Pe8GVZQX6Kcfn1NpyT5JkmlWqeDI99q25Z9q1aabOqYMadaa/B1rmQAAvop9mAAEnJaJXTT65keU+Xq6Nm14SGERbVRVWaKy0iNq3aGXLr7xIdlsQVaX6TdeKJ2nCfa7rC4DAIAmITAB8BrVoxDNs4lt+64DddO9r2jr9x/r4J4cBQWHqFPKOUrs1FuGYXj88QNJ7vZwKUUubWoMAIC3YEoeAK9Qs+ltTRvy5hAcYldKv0s0dMxdOvviiWqTdBZhyUNO1vQDAABvRmAC4D0mTnG8sK69dxP8By3GAQC+hsAEwOukZ2c4Wo0TmvxHzQgiAAC+hMAEwCvlbg9ntMnfTJwiiVEmAIBvITAB8Grp2Rl1ghN82+JRK9Uco0w1IZtwBgA4XQQmAD4hPTtDS2dUBvxok69/7Vnzt0tqnlGmpTMqVdNEJK+wWPuLCE8AANcRmAD4jE3jFzq66QVycKpZ3+Wrquv3/CjT1bOCHCOUS2dUqsokPAEAXMc+TAB8z8QpSpeUlpLq0t5N1aMa1S/U2Q/IOjX7Mu0vKlFClGf23EqMDq8TqDeNX6j04//uMSlJ12WOdJy3GYbH6gAA+D5GmAD4rPTsDMeamFONNlWfrxnVYK8lqw0f001VZjN0zFswt96hrPnbHSNPNXWw3gkA4AyBCYBPq3nxe7L1TTXHappHNGY0Cp41+uk0SZ5ey3TqYDz66bR6wZvwBACojcAEwC/UrG+S5HjBW/1RrOFjujnOwXvUNGXwBrVHnU4MTwCAwEZgAuBXft701pRkavGolY7RDHiXTeMXevT+bYaUNmedy7erHZ6k2i3KCU8AEIho+gDA7+RuD1e6ql/sZmVbXAxOKa+w2CNNOBKiwk475NQemVw+NV2rluUc/6xxjUYay5MNMAAAp4cRJgCAZZqjRXpaSqpb7qdmvVPNCKY7RpxqRq6apQEGAKBJCEwAAMvkbg/X8DHdPDbdzRMjV7nbw4+vc2q62lP8WF8HAN6NKXkAAk7NC1X2YvIOo59O06qU1ICYllY7GBKUAMA3MMIEIKCcuJh/fxHto71B+n39VeXBWWntk6xt2HDiiBJhCQB8B4EJQEBKz844/iLdPWtRcHraz5oob2kx7k4EJQDwfQQmAIFr4pR6raN9Qe52/5tKWPM1eeo5+NdVf/bI/TpDUAIA/0FgAhDwfu585rkX7Dg1T3XMS4wOr9UO3LNqNkuWCEoA4C9o+gAAqrV304K5js1OaQrRvHK3h0spntuXyZP2F5U4WoO/UDrPL0cBASBQMcIEALUdn6ZX0+o6r5CmEM3JkyMyvRaO98j91uyjtHjUSqVnZ7gelhbM9UhdAAD3IDABQANGP51WZ4NSuuk1L/cHVcPN91ctr7BYS2dUKj07Q1nztzf5fmyGZ+oDAJw+AhMAOJG7PVzp2RlaPGol3fSaUfp9/eWJjnlXzwpy231lzd+uF0rnKT07Q5vGL3Tb/QIAvI/LgWnXrl0qKiqqd7y8vFyrVq1yS1EA4E2y5m93tCH3pW56PmviFEnubcCRGO3+DXFZpwQAgaHRgWnPnj06++yzlZSUpBYtWuhXv/pVneB06NAhjRgxwiNFAoBXYH1Ts1k8aqXVJQAAIMmFwPSHP/xBQUFB+vLLL/Xee+9p06ZNuvDCC3X48GHHNabpf5sOAsCJWN/keTXrgdwdSpdPTXfr/QEA/F+jA9MHH3ygp59+WoMGDdJFF12kTz/9VB06dNDIkSN16NAhSZLBolUAAYL1TZ5XPcrkvjfiaKwAAGiKRgem/Px8xcXFOT632+1avHixkpOTNWLECO3bt88jBQKAN6tZ3ySJ9U1uVjPK5M4RvObawBYA4D8aHZi6dOmiDRs21DkWHBys119/XV26dNEVV1zh9uIAwFekZ2fUCU6eEIhhLP2+/o4NYU9XQlR144f2SYH3fQQANF2jA9OYMWP03HPP1TteE5r69evnzroAwCd5erTJkxu7eiVHxzz3jTLFPnKH2+4LAOD/Gh2Y0tPT9frrrzd4Ljg4WEuWLNHWrVvdVhgA+KoTR5sCcWTInZbOqJS71jLZDMOt+zEBAPxfowNTcHCwYmJinJ4PCgpSUlKSW4oCAH+Qnp1xvJteYE6ncxd3bgxbMy0PAIDGcnnjWgBA49V005MYbTpd7vze9ZjkHW/wpaWkKm3OOqvLAACchM8EptmzZ2vw4MGKjo5W69atddVVVykrK8vqsgCgUZqjKYQ/c+/aLUNBQy9w4/25bvnUdKWlpEqSEqPDGfkCAC/mM4Hp448/1uTJk7V69WqtWLFCFRUVuuSSS3T06FGrSwPQzEzT1LGKCh2rqLC6FJelZ2co/b7+jDY1wfAx3dz2PbNyHVNaSqpWLctRYnS4EqPDLasDANA4wa7eYMeOHerYsWO9TWpN09TOnTvVqVMntxVX23vvvVfn84yMDLVu3Vpr167V8OHDPfKYALyLaZpasmObXtqSo5yiQknSWbFxGt+tuy5t38Hi6lwwcYrSVT3KUL0vkKHEaEYYTmX002ladXxU5nQkRodZElbbJxVrgv2u4zUQlADAV7g8wtS5c2ft37+/3vFDhw6pc+fObimqMfLz8yVJLVu2dHpNaWmpCgoK6nwA8E2maerBb7/RzG/XKa7I1CS10f8pUcov1X1rv9Izm7+3ukSXjX46TYtHrZRkKq+w2K0btPqr6tE53/s+paWkHg9LBmEJAHyMy4HJNM16o0uSVFRUpLCw5nmH1DRNTZs2Teedd5569+7t9LrZs2crNjbW8dGxY8dmqQ+A+324d4+W7tiuO9VGv1E7nacYXaBY/UEdNE7xei47S98dPmR1mS7Lmr9d6dkZWjqjUlWmyTS9U+jxzVNyV4txLZjrnvs5xWPUXqvESCIA+J5GT8mbNm2aJMkwDP3pT39SRESE41xlZaW+/PLLZtu89u6779aGDRv06aefnvS66dOnO+qWpIKCAkIT4KMWbduq7ka4zjfrb29wueKUaeTrtW0/qXec81Fnb7Zp/EKlS9UvsOesE9P0GpY1f7uGT+3mWAPUVDbD0PLvCjXajbWdKC0lVZqzjhElAPBxjQ5M69ZVtz01TVMbN25UaGio41xoaKj69u2r3/3ud+6v8AT33HOP3nrrLa1atUodOpx8zYLdbpfdbvd4TQA878f8fJ1nRjZ4ziZDZ5rhyj4+VdenHV/flJaSeny0ieB0otvenKZVx9cCnY5Vy3I8EpjSaq2zIiwBgO9rdGD68MMPJUmpqal6+umnT7qJrSeYpql77rlHS5cu1UcffdSs66UAWC8sKEiFqnR6vkiVCgsOacaKPCs9O0M9JiXpusyRyisslq2BqdCBKnd7uJRS3Z69qYEkIcozjR9qT78DAPgHl9cwZWRkNHtYkqTJkyfrpZde0ssvv6zo6Gjt3btXe/fuVXEx8/2BQDCyXXutNopUrKp65w6rQut1TCPbtrOgMs+pWd8kSVWmqfT7+ltckfdw775Mp6/HpCTCEgD4KcM0TZdWzx49elSPPfaYMjMztW/fPlVV1X3xsnXrVrcWWKOhRhNSdYCbMGFCo+6joKBAsbGx+mLMlYoK8Z93ooFAkHvsqK758AMlV4Zqotqotap/h3epVPONvSoMkf478mLF1pouDP92ugGlZoTpdMPXz1PwmD4JAL6krOSoXpw9Vvn5+ScdEHJ5H6bbb79dH3/8sW699Va1bdvWaZBxNxdzHQA/0z4iUvPOGabffLVa08p/UmcjTJUytd0sVRt7uJ4751zCUoBJz86os17IVYnR4ac3LY8GHQAQEFwOTMuWLdO7776rYcOGeaIeAHBqYKt4Lb/4Ur2Xu0vrDh2UzZDuim+ti9u1V4jN5RnG8BOns5apqeiABwCBw+VXGHFxcSfdLBYAPCkiOFjXJCXrkf4D9VC/gbqsQ0fCUgCr3vj39PSYlOTaDY7v30RYAoDA4PKrjEceeUQPPPCAjh075ol6AABotKz52yVJ+4tKmvmR6VoIAIHC5Sl5Tz31lLZs2aLExEQlJycr5ITmCd98843bigMA4FSWzqjU1bOCmnz76zJHKl3e1XUP/qWqslJ7tn+r4qLDiohupTZJZ8lma/rPLIDm5XJguuqqqzxQBgAATbNp/EIpJVX7i0qUEOVa84WmNH5Im7OOfbHQaFs2fqjVy5/TscL9jmNRsW00dMwkJfdkPTjgC1wOTA8++KAn6gAAoMnS7+t/vGNd83A1mCEwbdn4oVYuTleLuH7q2CtVYeFtVVycq72739OKV2fq4htnKvkMQhPg7Zq0UvrIkSP65z//qenTp+vQoUOSqqfi5ebmurU4AAAaZeIUSVJeYRPXMh1v5AC4S1VlpVa/93e1iOuv5G63KyIqSbagUEVGdVaX7ncopkUvffneczKr6m/GDcC7uByYNmzYoJSUFD3++ON68skndeTIEUnS0qVLNX36dHfXBwBAoyydUSmpKXv2Mb0O7rf7p3U6VnRQie0uqbdnpWHYlNj2EhUczlXerk0WVQigsVwOTNOmTdOECRP0448/Kizs5ykJY8aM0apVq9xaHAAAjbVp/EJJTRtlas7pfAgMx4qqZ+CEhbdt8HzN8WOFh5qtJgBN43JgWrNmje644456x9u3b6+9e/e6pSgAAJrihdJ5cnWUKTGa9Uhwv4joVpKkkuI9DZ4vObZbkhR5/DoA3svlwBQWFqaCgoJ6x7OyspSQkOCWogAAaIrc7WwmC+/QLrmfIqLjtXf3cplm3RBvmlXK2/O+Ylq2V+sOPS2qEEBjuRyYxo4dq4cffljl5eWSJMMwtGPHDv3hD3/Qtdde6/YCAQBwlautwiUpLSX15BcsmHv8GtY84dRsQUEaOmaS8g+v1085C3S06CdVVharqDBHW7Pnq6Bgs8659E4Ztib13wLQjAzzxLc9TqGgoECXXXaZvv/+exUWFqpdu3bau3evhg4dqv/973+KjIz0VK2nraCgQLGxsfpizJWKOmHDXQCA/0hLSVVitGujTXmFxUrPbngD25ow5ep9Alu/X6Uvl/9DRfl5jmPRce00dMwkJfUYamFlAMpKjurF2WOVn5+vmJgYp9e5vA9TTEyMPv30U61cuVLffPONqqqqNGDAAF100UWnVTAAAO5SvS/TepfXJ7VPKq4zrW/51HStWpYjibCEpuly5nAl9xymvB3f6VjRIUVGxyux45mMLAE+xOXAVGPkyJEaOXKkO2sBAMAtetm/lhR0WveRlpIqLcshKOG02WxBapvc1+oyADRRkwJTZmamMjMztW/fPlWdsOHav/71L7cUBgBAU20av1BKSVVeYbFLgSf2kTsU9cXHui6z+g1BwhIAwOXx4IceekiXXHKJMjMzdeDAAR0+fLjOBwAA3mDxqJUuXW8zDF09K+h4WDIISwAASU0YYfr73/+uF154Qbfeeqsn6gEAwC2y5m+XUtToUaaEKPZjAgDU5/IIU1lZmc4991xP1AIAgFs563oHAEBjuRyYbr/9dr388sueqAUAAI/IKyyxugQAgI9yeUpeSUmJnnvuOX3wwQfq06ePQk7Yz+jPf/6z24oDAOB0vVA6TxPsd1ldBgDAR7kcmDZs2KB+/fpJkr777rs65wyD3c8BAN4ld3u4S2uZAACozeXA9OGHH3qiDgAAPGbxqJWOVuEAALjitLaZ3rVrl3Jzc91VCwAAbrd8arqjVTgAAK5yOTBVVVXp4YcfVmxsrJKSktSpUye1aNFCjzzySL1NbAEAsEqPSUlKS0nVqmU5SowOV2I0bcMBAK5zeUpeWlqann/+eT322GMaNmyYTNPUZ599ppkzZ6qkpETp6emeqBMAgEZLS0mVMqXqDWgJSgCApnM5ML344ov65z//qV/84heOY3379lX79u111113EZgAAJZKS0mVJBo8AADcwuXAdOjQIZ1xxhn1jp9xxhk6dOiQW4oCAMBVNUFJIiwBANzH5TVMffv21bPPPlvv+LPPPqu+ffu6pSgAABqrZq2SpONrlQhLAAD3cXmE6YknntDll1+uDz74QEOHDpVhGPr888+1c+dO/e9///NEjWikKtPUqry9WrJju3KPFaulPVRXduigS9t1UGhQkNXlAYDbLZ+arrRlOWKtEgDAU1weYbrggguUnZ2tq6++WkeOHNGhQ4d0zTXXKCsrS+eff74nakQjlFVWaspXq3XPV19oTWGQDtrP1KbSWKWtW6ubPl2lI2WlVpcIAO6zYC4d8AAAzcLlESZJateuHc0dvMwzmzfpk3371KX7nYqNO8tx/NjRHfop61n9cd03mjdkqIUVAoB7pKWkSnPWyWYYSogiKAEAPKtJgenw4cN6/vnn9cMPP8gwDPXs2VOpqalq2bKlu+tDIxyrqNBr27cpoc2oOmFJkiIiO6lNp2v1ydaF2lZUqOSoaIuqBIDTRwc8AEBzc3lK3scff6zOnTtr7ty5Onz4sA4dOqS5c+eqc+fO+vjjjz1RI07h+yOHdayiXHGtBjd4Pq7lABky9NWB/c1cGQC4R1pKKmEJAGAJl0eYJk+erBtuuEHz589X0PFGApWVlbrrrrs0efJkfffdd24vEidnHv+vYTScfw3ZJMOQaTZ4GgC8Vo9JSbouc6QkghIAwBoujzBt2bJF9957ryMsSVJQUJCmTZumLVu2uLU4NE6PmFiF2oJ05PD6Bs/nH9kg06xSP6ZMAvAxWQPulURYAgBYx+XANGDAAP3www/1jv/www/q16+fO2qCi2JDQzW2Yyft3/O+jhb9VOdcackB7dn5hga0TFCP2BbWFAgALuq1cHz1NLw56whLAABLuTwlb8qUKZo6dapycnJ0zjnnSJJWr16tv/3tb3rssce0YcMGx7V9+vRxX6U4qd+deZayCwr07aYnFRt7psIjk1Rakqf8w+vVJjxcjw8cYnWJAHBKjil4s0QXPACAVzBM07WVLTbbyQelDMOQaZoyDEOVlZWnVZy7FRQUKDY2Vl+MuVJRISFWl+N2ZZWVenvXDi3evkO7i4+ppd2uX3TooGuTkhUTEmp1eQBwUjVNHdiEFgDQHMpKjurF2WOVn5+vmJgYp9e5PML0008/nfoiWCI0KEjXJnXWtUmdrS4FABqNoAQA8GYuB6akpCRP1AEACDC9Fo7X1bOqGwixTgkA4K2atHFtbm6uPvvsM+3bt09VVVV1zk2ZMsUthQEA/BPrlAAAvsTlwJSRkaE777xToaGhatWqlQzDcJwzDIPABABwavnUdKUty5HEqBIAwDe4HJgeeOABPfDAA5o+ffopG0AAAFAjLSVVWpZDUAIA+BSXA9OxY8c0btw4whIAoFHaJxVrgv0uSYwqAQB8j8up59e//rVef/11T9QCeERFVZU+2rtHL+b8qDe2/6SDpSVWlwQEjLSU1ONhySAsAQB8ksv7MFVWVuqKK65QcXGxzjrrLIWcsJ/Rn//8Z7cW6E7+vg8T6vt03179af06HSgpVrAtVJVV5QoyDN3UuYt+26u3ghkpBTyCDngAAG/nsX2YHn30US1fvlw9evSQpHpNHwBvse7gQd395WpFxfRQj65jFRHZURXlRTqw7xP9e+u7qjBNTT+rr9VlAn6ldgc8ghIAwB+4HJj+/Oc/61//+pcmTJjggXIA93lm8yaFRbRX5+6TZNiq3+kODolSm/ZjZNhC9MpPb2pC1+5qGxFhcaWAf0hLSZUyaRUOAPAvLs9HstvtGjZsmCdqAdzmQEmJ1hzcr1aJIxxhqbb41ufJZgvWe7t3WVAd4H/SUlIlVY8qEZYAAP7E5cA0depUPfPMM56oBXCb/PIySZLdHt/g+aCgMNlDonWkrKw5ywL8TlpKap2wBACAv3F5St5XX32llStX6p133tGZZ55Zr+nDkiVL3FYc0FQJYWEKMmw6dnS7oqK71jtfXpav4rIjah/RyYLqAP9AUAIABAKXA1OLFi10zTXXeKIWwG1iQkJ1cdt2+mhvplq2OlvBIVGOc6Zpau/u/ynUZtOl7TtYWCXgoxbMVdqcdapuFc70OwCAf3M5MGVkZHiiDsDtpvQ8U6s/+Vg5m55QfNvRiorupvKyw9qf95Hyj2zUjLP6KSYk1OoyAZ/haBU+Zx2jSgCAgOFyYKqxf/9+ZWVlyTAMpaSkKCEhwZ11AaetY2Sk/nPecD32/QZ9uu1lmY7j0frjgMG6rEPHZqnjcGmp1h8+qCpTOisuTq3DeKEJ35OWkirNogMeACDwuByYjh49qnvuuUcLFy5UVVWVJCkoKEjjx4/XM888owhaNMOLdIqK0rwh52pv8THtOnZMUcHB6hET2yx7hh2rqNAT323Q2zt3qMw8/rsiQxe3a68ZffopNpTRLfgG1ioBAAKZy4Fp2rRp+vjjj/X222872ot/+umnmjJliu69917Nnz/f7UUCp6tNeITahDdfmK+oqtKUL7/QtwcP6hq11LmKlk2G1qhQS/bs0e1FhVp43gUKD27yIK/f2Xn0qPJKitUyNFSdo6LZCNsL1AQlibAEAAhcLr9ae+ONN7R48WJdeOGFjmOXXXaZwsPDdcMNNxCYAEkf7t2jLw/u13R1UG/9HNQuUZx6mBGaUbBdb+3coV927mJhld7h+yOH9eR3G/X1oQOOYz1jYvWbXr11butECysLXO2TijXBfpckghIAAC7vw3Ts2DElJtZ/EdO6dWsdO3bMLUUBvu7NHdvUXeF1wlKNJNk1QFFaun1b8xfmZb4/clipn67S/kOFmqw2mqNk3at2UkGZ7lr9uT7cu9vqEgPPgrnHw5JBWAIAQE0ITEOHDtWDDz6okpISx7Hi4mI99NBDGjp0qFuLA3zVvuISdZTzNUodFap9JcXNWJF3mr3hWyVWBetBddS5ilE7hWqAovRHdVAfRSj92/WqOL5WEp7Va+H46k1oj3fAo104AADVXJ6S9/TTT+vSSy9Vhw4d1LdvXxmGofXr1yssLEzLly/3RI2Az0kIC9PuwgKn53NVpviwwH5BurWwUN8eOaQpaiv7Ce/d2GToWrXSjNId+nz/Pg1PbGNRlYGhpgMeI0oAANTncmDq3bu3fvzxR7300kvavHmzTNPUuHHjdPPNNys8nP/ZApL0i05Jum//V8pSsXqo7u9Frkq1Vkd1X6ezLKrOO+wuPipJ6qqGg2Oy7AqStPvY0WasKvDQAQ8AgJNrUouu8PBwTZw40d21AH5jVNt26hfXUk8eydX1ZiudqxjZJK1RkV4zDio5IkpXdUqyukxLtTi+afA+lSteIfXOH1CFKiW1CLU3c2WBgQ54AAA0TqPXMK1du1YjRoxQQUH9aUb5+fkaMWKEvv32W7cWB/iqEJtN888ZpgvbttNLOqA7tEUTtUULlKd+reP1/HnnKzK4fkgIJL1axKlTRKSW6bBMx7bCP1umw4oMCmY6npu1TyquM6pEWAIA4OQaPcL01FNPaeTIkYqJial3LjY2VhdffLHmzJmjl156ya0FAr4qKiREjw86W9OKi/XNoQOqMqU+cS3VMTLS6tK8gs0wNKXXmfrd119pvvbqGrVSG4XqsCr0rg5ruY5oWo/eimCvqtOzYK7S5qxT+n39tfy7Qq1alqPqDniBvYYOAIDGMkzTrP/WbgO6du2qpUuXqk+fPg2e37hxo8aOHautW7e6tUB3KigoUGxsrL4Yc6WiQgL73X3AW7y1c7se37hBBRXlijBsKjarFGYL0v/1OEO/7pbCBrZN1GvheF09K0hS9UhSXmHJ8X8TlAAAkKSykqN6cfZY5efnNzgoVKPRb93m5uYqOjra6fmoqCjt2bPHtSoBBLxfdEzSJe066KO9e7S3+JjiQu0a2badonlTo8lqut7ZDEMJUdUBiaAEAEDTNDowJSQkKCsrS507d27w/ObNmxUfH++2wgAEjrCgIF3avoPVZfi8HpOSdF3mSEk0cgAAwF0a3fThoosuUnp6eoPnTNPUo48+qosuushthQGAL9t19KjWHNivnIICNXLms0OPSUnVm8impEoL5jbqNmkpqYQlAAA8oNEjTDNmzNDAgQM1ZMgQ3XvvverRo4cMw9APP/ygp556StnZ2crIyPBkrQDg9TbnH9ET323UmoP7Hce6Rcfqt716aXhiW6e3qz06pExJMiSZ0sQpJ3289knFmmC/SxJBCQAAT2h0YOratas++OADTZgwQePGjXMsxDZNU7169dKKFSvUrVs3jxUKAN7uh/wjGv/pKtlCE5TU5VeKiExSael+7dubqbu//EJPDhqiS9q1d1xfuzGDMuuuOZKkvMLikz7ez3sp0fUOAABPcalf76BBg/Tdd99p/fr1+vHHH2WaplJSUtSvXz8PlQcAvuPx7zbKFpqgbr1+p6Cg6gATFp6omNhe2pbzvGZt+FYj2rTVzDN+XX2DWU0cFTreKlxiVAkAAE9r0gYn/fr1IyQBQC07jxZp7cH9Suqa6ghLNQzDpjbtL9fm79brp3FnSOubHnTSUlKlOesISgAANBN2hASAWnIKCrRo21Z9e/iIgmyGzk9I0HXJndU67OQBZfexY5KkyMikBs+HR7RTkC1E23fsU/X6JNf8PP2OUSUA8EVH9u/Qd18u1a4fPlNlZYVateuunkOuVqeUIew56OUITABw3KKftip943qFhkQrMra3zKpyLcjZoBe2bNGzQ87R2fEJTm/bIjRUklRaekD2sPrXlZcdUWVVuVq2jJYOuVZXTVgiKDWOaZrK2/m9ftr0iSrKStQioZO6971YYRHONyUEAE/akb1aH7wyU1Gy6byqSEUoROu2/qD3t6zVmWdfpaGXTSY0eTECEwBIWnfwoGZtXK+ExAvVruPVstmq/zxWVBzT9px/6p6vVmvZqEvU0m5v8PYpMbHqHBWr/XszFR3TQ4ZRd9eGfXtXyh4UrF+MOVtLnml8XYQl15QWF2rFqw9pz7b1CrXHKTgkWlnrlmvNiud13i9+o5R+l1hdIoAAU3IsXysXPaK+VWG6R20UenxXn2tMKVNH9K+v3lRi0pnq2nuExZXCmUbvwwQA/mzh1hxFhCeqfadrHWFJkoKDI5TU9TaVVJpaumOb09sbhqHf9uqpwvwftH1LhkqK90qSysvylbtjqfbtzdQd3VMUGxvpYmUGYamRTNPUB4se1v7cH9Wl+53q1edh9eh1v87sO0uxcQP08dI52rVlrdVlAggw2euWy6ws1/8p0RGWaoxSC/UyIrXpiyUWVYfGaNQI04YNGxp9h3369GlyMQBgldUHDiim9UX1RoYkKTgkStGxPbX6QJ5+3b2H0/sY0aadHh84WOkbN+qHjd8oOChUFZVlsgcF6+4zeun2k9y2IQQl1+zb9YN2/7ROnbv/n2LjznIcDwmJVqfON6u0dJ/WffyyOnQdaGGVAAJN3s5N6mGGK1pBDZ4/24zUi7mbZZom0/K8VKMCU79+/WQYhtPd6mvOGYahyspKtxYIAM2h+m/YSQbdjSA5+RNYx5j2HTWqTTt9nLdXu4uPqUVIqEa2bafokBD3FYsGbfvhM4WExiq2xVn1zhmGTa3iz9WOn15SybEC1jMBaDaGYVOFYUpO/h9SoVP8/weWa1Rg+umnnzxdR6PNmzdPc+bM0Z49e3TmmWfqr3/9q84//3yrywLg4/q3bKn1h75RYtvR9d7hq6ws1tH8TRrQrUuj7is0KEgX19qgVpKqTFOf7cvT5ef9TRVlxUpsk6QeA8YoOq6N276GQFdRXqKQkGinLzyCQ6KPX1fanGUBCHDtuw7QZ5s+0X6VK0F13zwzZeoz46jad+7P6JIXa1RgSkpquE1uc1u0aJF+85vfaN68eRo2bJj+8Y9/aMyYMdq0aZM6depkdXkAfNitXbrq09WfKW/P8jqhqaqqQjt/+o8MVerapM5Nuu/DpaWavPpzbcw/rHZGmOIUpM0/rtb6T17W2RdPVJ9hN7jzSwlYcQlJ+uHY2yovO6KQ0Bb1zhfmZ8keFqOIqLjmLw5AwOp21iit/eBfeqYkT9PMNmpx/OV3hUy9pgP6yTymMcOut7hKnIxhOptndwqbNm3Sjh07VFZWVuf4L37xC7cU1pAhQ4ZowIABmj9/vuNYz549ddVVV2n27Nn1ri8tLVVp6c/vJBYUFKhjx476YsyVimJ6DIATzM/6QfOyflBEeKKiW/RVVVW5Cg59rcqKo3py0GCNatu+wdsVlZdrxZ5cHSgpUXxYmC5u297xN8Y0TaV+uko/Hjmie8y26qlwGTJUoiot1UG9o8MadcOf1OXMC5rzS/VLZSVF+s+TNyo65kwldflVnZGmY8d2KeeHv+jMc8ZqyCUTLawSQCDan5ul5Qv/oLLSo+pnRihCNn1rK1ZBVbnOuXSSzhp6rdUlBqSykqN6cfZY5efnKybG+VRtl9uKb926VVdffbU2btxYZ11TzbuxnlrDVFZWprVr1+oPf/hDneOXXHKJPv/88wZvM3v2bD300EMeqQeA/5nUo6cGtYrXyz9t1beHP1WQYdNV7RN0Y+ch6hrd8B/Sf2/J0dObN6msslIhweEqryhW+sYNmnJGT43v2l0bDh/W2sMHda/aqZciHLcLk03jFK8dRpm+/fg/6txrONMxTlNoWJSGX3WvVi5+VKUl+9Qq4VwFh8SoqCBbBw98obiEjuo//CarywQQgBLa99B1U19U9rrl2pn1uSrLy9ShwxnqOfhKtWydbHV5OAWXA9PUqVPVuXNnffDBB+rSpYu++uorHTx4UPfee6+efPJJT9QoSTpw4IAqKyuVmJhY53hiYqL27t3b4G2mT5+uadOmOT6vGWECAGcGxydo8Ek2qK3ttW1b9cT3G5SQeIFat71EoaEtVFZ2RPv2rNCc7z+S3RakvJJitTCC1c+s307ckKELzRjNzduq4qJDiohu5e4vJ+B07X2hIqLitG7VK9q55VVJkj08Vn3OvUZ9z79RofaIU9wDAHhGWESM+gy7Xn2YfudzXA5MX3zxhVauXKmEhATZbDbZbDadd955mj17tqZMmaJ169Z5ok6HE9+BPVkLRrvdLruTTSYB4HSUV1Xpmc2b1TL+HHVI+nkNUmhoC3VIul6VlaV6NmudrujQXuGyyaaG/05FHt+To6KirMHzcF3b5L5qm9xXZaXHVFFeqrDwGNmCGm7nCwDAqbjcw7CyslJRUVGSpPj4eO3evVtSdWOIrKws91ZXS3x8vIKCguqNJu3bt6/eqBMAeNqaA/t1pKxErduMbPB86zYjdKSsRMGGoT1mmfaq4UC0XkcVHhalyOh4T5YbkELtEYqIiiMsAQBOi8uBqXfv3o6NbIcMGaInnnhCn332mR5++GF16dK4lrtNERoaqoEDB2rFihV1jq9YsULnnnuuxx4XABqSX14dgELtDU+jqzneNTpWLUJC9YKxX2WqqnPNFhUr0yhUyqArFBRMIxoAALyRy1PyZsyYoaNHj0qSZs2apSuuuELnn3++WrVqpUWLFrm9wNqmTZumW2+9VYMGDdLQoUP13HPPaceOHbrzzjs9+rgAcKL2EdVrko4W/aSY2J71zh8t2iZJWt5rnM7oNlZrljys3xs7NaIqWi0UpB9UrC+MIrVql6L+F9zcnKUDAAAXuByYRo8e7fh3ly5dtGnTJh06dEhxcXEe7/D0y1/+UgcPHtTDDz+sPXv2qHfv3vrf//7n8j5RmZMe0Fer9mrpjEptGr/QQ9UC8GdntYhTl+hY7ct9V1HR3WSz/TxCVFVVrn173lV0q06Ka9tDbWIi1C7hb9rw6SK98f0qVVZVKCamtfqffYN6D7lKwaFhFn4lAADgZJq8D5Mk7dy5U4ZhqEOHDu6syWMKCgoUGxurMfcsUog9UsPHdNXop9NOepsek5KUNX97M1UIwJd8c/CAbv/iM4WGt1N8m4sUHt5WxcV7tH9vpkpK9ujc6x9Rz56D6tzGNE1VVVYwBQ8AAIt5bB+miooKPfTQQ5o7d66KiookSVFRUbrnnnv04IMPKsQHNoRtHRWm0LAwrVqWo9EnnGufVKwJ9rt+PpApLV3ISBSA+ga0ilfGuefrLz98r7VbMhzHW3XorYsu/Z0SO/aqdxvDMAhLAAD4EJcD0913362lS5fqiSee0NChQyVVtxqfOXOmDhw4oL///e9uL9KTlk9N15Sy53RdZu1OV4YSo6unyOQVllhTGACf0LdlS70w7Hz9NvFylRw9pLDIlurcwbVpwgAAwHu5PCUvNjZWr776qsaMGVPn+LJlyzRu3Djl5+e7tUB3qpmS96vp/1VoWPWC7bzC4uNnfw5JtVUHJlPp2Rn1zgFAWkqq49+J0eEWVgIAAFzhsSl5YWFhSk5Ornc8OTlZoaGhrt6d5U71AicxOqxWqAIQ6HpMSjphRJqgBACAP3N5H6bJkyfrkUceUWlpqeNYaWmp0tPTdffdd7u1OADwFj0mJSktJdURlhKjwx0fAADAf7k8wrRu3TplZmaqQ4cO6tu3ryTp22+/VVlZmUaNGqVrrrnGce2SJUvcV6nFlk9NP2VHPQB+ZMFc9bJ/rU3jF1ZPu8uUnE3dBQAA/svlwNSiRQtde+21dY517NjRbQV5I5uH95cC4B1qr0fSnHWSgqTjxxhJAgAgMLkcmDIyArP5QUMtyAH4jx6TkqRMghEAAKjL5TVMgSghiik4AAAAQCBq1AjTgAEDlJmZqbi4OPXv31/GSaaoffPNN24rDgDg344WHNCOrNUqLy9RXEInte86UDZbkNVlAQDg0KjANHbsWNntdknSVVdd5cl6vFpaSir7MQF+qNfC8bp6Fi/Sm1NlRbk+/9+zyvpmmQzTVIhhU6lZqZiY1hp+7R/UNrmP1SUCACCpCRvX+rKGNq51RV5hMYEJ8LCyykp9dXC/isor1CkyUj1jW5x0VPt0LZ+arlXLcmQzDKbfNqOP3pitrRs/1DizlS5UjMJl0xaV6BXjkHJsZfrFxGfUqm03q8sEAPixxm5c6/IapjVr1ujLL7+sd/zLL7/U119/7erd+Zwek5KsLgHwS6Zp6t9bcjTi/fc0afXnum/tV/rlqg91/aqP9N3hQx573N8OzPLYfaNhh/Zt048bMnWbmaDLFKcIBcmQoW4K1/1mW8WbQVr38UtWlwkAgKQmbly7c+fOesdzc3M1efJktxQFIPAs+DFLT3y/QSEtBuuM3mnqM/BJdUmZpF0VUUr9/FNl5R/xyOPWTMVjdKn5bNm4UlG2EJ2n+u/mhcqmi6uitW3z5yovLbagOgAA6nI5MG3atEkDBgyod7x///7atGmTW4oCEFgOlZZqftZmtW57sTp1vlHhEe0UFBSu2Ba91fWM38oW2kpPb3bv35f2ScWOfZdoJd68So8VqJVCFKyGp1omKkSmWaWy0qPNXBkAAPW5HJjsdrvy8vLqHd+zZ4+Cg13e1snHGLouc6TVRQB+573du1QlQ4ltLqp3LijIrlaJo/Rp3l4dLC1xy+OlpaRqgv0uSQZhyQJRLdpoj1mqY6ps8PxWlSgk2K6wCOfzyQEAaC4uB6aLL75Y06dPV35+vuPYkSNH9Mc//lEXX3yxW4vzNonRTNkBPOFASYnsoTEKDolq8Hx4eFuZkg6Wlp7eAy2Ye3xUqToo8TttjZR+F6tCpt5S/bVph1SuFbZCdet3sYKCQy2oDgCAulweEnrqqac0fPhwJSUlqX///pKk9evXKzExUf/+97/dXqBXWjBXmjjF6ioAv9HKHqbSsgJVlBc1GJqKi/fIkNTq+PYGrnK0DZ+zjhElLxAR3UoDR6Xq7Q+e135V6CLFKlbB+k7H9LbtiMyIGPW/4BarywQAQFITAlP79u21YcMG/ec//9G3336r8PBwpaam6sYbb1RISIgnavQynmtvDASqS9u315Pfb9S+vZlq13FsnXNVlWU6mJepYa3bqJXd9RGhtJRUaZZUParEiJK36Hf+jQqLiNW3H72k1QW7JEmGYVNyj2E6Z8wkRcbEW1whAADVmrToKDIyUv/3f//n7loABKhW9jDdkdJDf8t6X5WVxUpIvFAhoXE6WpijvNx3VVl2UFN6Dnf5fmnq4N3OGHiZUvqP1qG9W1VeVqzYVh0UEd3S6rIAAKijSYEpOztbH330kfbt26eqqqo65x544AG3FOatEqPDlDZnndKtLgTwM3eknKHwoGD948ev9MO+TxzHu8e00Mxzz1PP2BaNvq+aoCQRlrydzRak+HbdrS4DAACnXA5MCxYs0KRJkxQfH682bdrIMH6eomYYht8HJgCeYRiGftWtu8Z17qIvD+xTYXmFkiIjdWaLuDp/Z06mfVLx8e53BCUAAOAeLgemWbNmKT09Xffff78n6vFq+4tKVGWaVpcB+DV7UJCGJ7Z1/YYL5mrCnHVirRIAAHAnlwPT4cOHdf3113uiFq+WV1i94/zSGZXaNH6hxdUAqEEHPAAA4EkuB6brr79e77//vu68805P1ON18gpLJJlKv6+/NHGKNo23uiIANWo64BGUAACAp7gcmLp166Y//elPWr16tc4666x6rcSnTPGf/YlqRpXSszOkiRkWVwOgNjrgAQCA5mCYpmuLcjp37uz8zgxDW7duPe2iPKWgoECxsbH61fT/KjQs0ul1NUFJOh6WAHgNOuABAAB3KCs5qhdnj1V+fr5iYmKcXufyCNNPP/10WoV5uzqjSgC8Bh3wAACAFZq0D5M/qlmrJBGWAG+zfGq6Vi3LER3wAABAc2tUYJo2bZoeeeQRRUZGatq0aSe99s9//rNbCmtONaNKi0etVNb87RZXA8BhwVylzVknLcthVAkAAFiiUYFp3bp1Ki8vlyR98803TjeRbOzmkt7ixFbhWdkWFwTAIS0llVbhAADAco0KTB9++KHj3x999JGnamk2+4pKFVJuk1Q9/Y5W4YB3oQMeAADwFi6tYaqoqFBYWJjWr1+v3r17e6qmZmDqhdJ5yt3OizHAm9ABDwAAeBuXAlNwcLCSkpJUWVnpqXqaxQM5Lyk3hBdjgLfoMSlJ12WOlERQAgAA3sXm6g1mzJih6dOn69ChQ56oB0AAaZ9UrOVT04+HJYOwBAAAvI7LbcXnzp2rnJwctWvXTklJSYqMrLsB7DfffOO24gD4sQVzNWHOOmnZFoISAADwWi4HprFjx/pcNzwA3oUOeAAAwFe4HJhmzpzpgTIABIL2ScWaYL9LEmuVAACAb2j0GqZjx45p8uTJat++vVq3bq2bbrpJBw4c8GRtAPxIWkoqYQkAAPicRgemBx98UC+88IIuv/xyjRs3TitWrNCkSZM8WRsAP9BjUlKdfZUISwAAwJc0ekrekiVL9Pzzz2vcuHGSpFtuuUXDhg1TZWWlgoKCPFYgAN/kmH6XKdkMQwlRYVaXBAAA4LJGjzDt3LlT559/vuPzs88+W8HBwdq9e7dHCgPgu5ZPTT8+/a66VThhCQAA+KpGjzBVVlYqNDS07o2Dg1VRUeH2ogD4rrSUVGlZDlPvAACAX2h0YDJNUxMmTJDdbnccKykp0Z133llnL6YlS5a4t0IAPqFmnZJEUwcAOFFpcaE2rXlb2euWq7josCKiWyml/2j1GnyFQsOirC4PwEk0OjD96le/qnfslltucWsxAHxT7aYOAIC6jhYc0Dv/uldF+fvUouVAJSSereJjufp65QvKXve+rrjtKUVExVldJgAnGh2YMjIyPFkHAB/Ua+F4XT2ruukLYQkAGrbqv0+p5NgxndF7huxh8Y7jJcWXKifraX369l91yY0PWVghgJNxeeNaAOgxKUnXZY6UZtEBDwBOJv9grnblrFGnLuPrhCVJCgtPVJt2l2l71iIVHclTVItEi6oEcDKN7pIHAFJ1B7zrMkeKDngAcGr7d2dJklq06NPg+di4vpJZ5bgOgPdhhAlAo9EBDwBcY7NVT1uuMssVpPp/O82qckmSYWNPS8BbEZgAnBId8ACgadom9ZFhC9ahA18pse1F9c4fOviVgoJC1abTWRZUB6AxmJIH4KRqd8AjLAGAa8Kj4tS970Xau/tdFRz5XqZpSqreriX/8Ebl7X5PKQNGKywixuJKATjDCBOABtEBDwDcY9hld+to/n5tyZ6niMiOsoe1UUnxbhUfy1XH7kN0zuhJVpcI4CQITADqqN0Bj6DkPhXlpfrh63f0w9fvqvDwHoWGRanbWSPUe+i1iqYzFuDXgkPDNObW2dqZs0Y/rl+hY4UHFde2u1L6360OXQbKsDHhB/BmBCYADmkpqVImrcLdrby0WO8u/L0O5GYrtmU/tWs/RGVlh7R57Qplr1+hyyc8ofi23a0uE4AHGTabOqUMUaeUIVaXAsBFBCYAkuquVYJ7fb0yQ4f2bFX3nvcqMirJcTyx3aXakv2sPlj0iH455QXeZQYAwAvxf2cgwKWlpBKWPKi8rFibv1mm+MQRdcKSJAUHR6hDp+tVeHi3dm352qIKAQDAyRCYgABGBzzPyz+4SxVlxYpt0bvB8xGRyQoJidb+3OxmrgwAADQGU/JcsWCuNHGK1VUAp2351HStWpYjyVBi9OmtVTJNU7t/Wq8Du7NlCwpWx26D1SKhk3sK9QO2oBBJUlVVmZMrqlRVVS5bEH+OAQDwRvwfuhEcm3bOWacXkoqVu5134uGbHK3Cl+W4ZUTp4N4t+nDRIzp8aJfCjWBVyNTq9+YrKeUcXXDNH2QPj3JD1b6tRXxHRca01qH9Xyo6pke980cOf6vKyhJ17D7YguoAAMCpEJhOwhGUjkvPzlCuCEvwTWkpqdIs93XAKzySp//9a5oSy6p0tzqohxmuCpn6UkV68cev9f5Lf9Tlv/6LbLYgN1Tvu2y2IPUZdr2+WPY3hUd2VELicBlG9fekqHCrdm1/Te27DFSrNl0trhQAADSEwNSQBXOVNmddnUPp2RkWFQOcHk9tQLvx88UKKS9TmtlJkaq+/xAZOk8xijOD9eiuTdqV8zUtdCWdOeQqFRzare+/XKz9eZmKiEhSWdlhHTu6XfHtUjTy+j9aXSIAAHCCwFSL44VlrbC0dEalNo1faGFVQNPVjCq5Y63SibZ++4FGVkU5wlJtvRSujka4tmxcSWCSZBiGzr1sslL6X6LNa/+ngkO71TIsWV3OSlVSylDZggJ7FA4AAG9GYJLUY1KSrsscKc2qfgc+r7BYUvWo0qbxFhcHNEH7pGJNsN8lyXOtwktKjypB8Q2eM2SotWnTvmMFHnlsXxXftrvOu2Kq1WUAAAAXBHRgcryozJRq3oGvHZYAX/Tz2jv3jyrVFhPbWjlHjuniBs5VytQWW7natWznsccHAABoDgEbmE58UZlXWKy8wmKl39ef1uHwSZ5aq+RMyqArtDrzX7rMLFWS7HXOZeqIjlSVacSASz1eBwAAgCcFZGB6uNstCtHPLyrrjCpNZGQJvqdmrVJzbj575tlj9dPGlXpk3w5dbsaqvyJVKlOrlK+PVKBeZ49VfNvuzVYPAACAJwRkYGodFabQsAbCEuBjare+b86wJEkh9nBdftuf9eWKf+q/69/X4oqDkqTIyDgNOe9OnTX02matBwAAwBMCMjBJUl5hiSSTKXjwWTVhqbmDUm2hYVE6/8rfaMjFt+vw/h0KCgpRy8QudH2Dy8pKjynn2w+07YfPVFFeqlZtuqjn4CvUMrGL1aUBAAJcQAamfUUlCrFH6IXSecqdyEa08C3N0QHPVaFhUUrs2MvqMuCjjuzfoXdfvF/HCg8oJrangoIj9eO3H2vTmrc0eNRt6jf8JqtLBAAEsIAMTFL1FLxceceLTaCxmqsDHtBcKivKtezff5RZGaJefWfKbq9uVW9WVWrv7mVak/kvxSZ0Uuee51lcKQAgUNmsLsAKD+S8ZHUJgGsWzD0elgwlRocTluA3tm3+TEX5e5XUZYIjLEmSYQtSm/aXKyqmuzZ8+rqFFQIAAl3AjjABviItJVWas85rpt8B7pS7Za3CI9srPKJ9vXOGYahlq7O146f/qKKsRMGhvFEAAGh+BCbAS1nZAQ9oLmZVlWxGiNPzhlH9v6kqs6q5SgIAoI6AnJIHeLvaHfAIS/BnCR3O0NGi7SorPdzg+fzD3yo2vpNCQvk9AABYg8AEeBPHWiVGlRAYuvUZpVB7hHZs+4+qKsvqnDt8cK2OHP5Wvc+5WoZhWFQhACDQMSUP8AKOVuFz1slmGEqIYq0GAkOoPUIXjXtQy//zJ23a+KDiWg5WUHCkCgt+UFHBj+rWZ5R6Drzc6jIBtzCrqnRo3zZVlBUrpmU7hUfFWV0SgEYgMAFWWzBXE+asE63CEajadxmgayb9Q99/uVTbNn2qiooytUzsrLNHp6lLrwtk2JgMAd+Xvf59ffPRf1R4OFdSdSfI5J7n6ZzRdygqtrXF1QE4GcM0TdPqIppLQUGBYmNj9cWYKxUV4nyRMdAcekxK0nWZIyUx/Q4A/NmGzxfry+V/V4u4fopvfb6CQ2JUVJCtfXkfKDg0WFf93zOKjIk/9R0BcKuykqN6cfZY5efnKyYmxul1PvG23bZt2/TrX/9anTt3Vnh4uLp27aoHH3xQZWVlp74x4IXSUlKPhyWDsAQAfuxY0WF9teKfSmgzUp27T1R07BkKj2inhDYXqnvP36m8pETffPRvq8sEcBI+MSVv8+bNqqqq0j/+8Q9169ZN3333nSZOnKijR4/qySeftLo8wCU0dQDgDfbu+E4bP1+sXTlrZVZVKqF9D515ztXq3Ot8mmy4Uc63H8iQoTbtLq13LjS0hVq1Pl8/fvuBho65S8EhdgsqBHAqPhGYLr30Ul166c9/aLp06aKsrCzNnz+fwASfwb5KALzF5rXL9Mlbf1Z4RBslJF4smy1E+Uc2KPO1h9Xr7Kt07mWTCU1uUnhkr8LCExUcHNng+cjIZO2tKFXJ0SOKapHYzNUBaAyfCEwNyc/PV8uWLU96TWlpqUpLSx2fFxQUeLosoB5HBzwRlABYr+DQbn369l/UKmGYOib/UoZRPTu/dZuROrDvE2366lW179JfyT2HWVypf7CHR6us7LCqqipks9V/2VVaelAybAoNazhQAbCeT6xhOtGWLVv0zDPP6M477zzpdbNnz1ZsbKzjo2PHjs1UIVBt+dT042GJtUoAvMMPX7+joKAwdeh0rSMs1Yhvfb4io7vo+y/ftKY4P9S19whVlB/VoQNf1jtXVVWug/s/UaeUIQoNi7KgOgCNYWlgmjlzpgzDOOnH119/Xec2u3fv1qWXXqrrr79et99++0nvf/r06crPz3d87Ny505NfDvCz4xvQrlqWo8TocNqFA/Aa+3OzFBVzhmxBoQ2ej4k9S/tzs5u5Kv8V1zpJ3fqM0q4dr2nf3pWqrCyWJB07ukNbf/y7Skv3a8AFN1tcJYCTsXRK3t13361x48ad9Jrk5GTHv3fv3q0RI0Zo6NCheu655055/3a7XXY7CyjRvNJSUtmAFoDXsgWFqKqq2On5qqpS2YJ8dsa+Vxo+9l4FBduVvW6pdu98U0FBdlVUHFNEdLwuvSVdCe3PsLpEACdh6V/E+Ph4xcc3bt+B3NxcjRgxQgMHDlRGRoZsbGQIL0QHPADerlP3s7V66z9UXnZEIaEt6pwzqyp15NAadepxtjXF+amg4FANHztNAy68VTuyPld5WYlaJHRSx25nyxYUZHV5AE7BJ95C2r17ty688EJ16tRJTz75pPbv3+8416ZNGwsrA6rRAQ+Ar+je7xJ98/F/9FPOAiV3vV2h9jhJUmVFsXZuf1VlZUfUe+g1Flfpn6JiE9Tr7LFWlwHART4RmN5//33l5OQoJydHHTp0qHPONE2LqgKkHpOSjm9AS1AC4Bvs4VEaM3623vv3H7VpwwOKiu4uwxaiosJsSaZGXvdHxbftbnWZAOA1DDOAEkdBQYFiY2P1xZgrFRUSYnU58HHLp6Zr1bIcVXfAY60SAN9SVnpMOd+u0M6cr2VWVap1h57qMWCMImMaN1UeAHxdWclRvTh7rPLz8xUTE+P0Op8YYQK8yoK5SpuzTjreAQ8AfFGoPUK9zh7LFDEAOAUCE+CCmg54BCUAAIDAQKs5oJHogAcAABB4GGECToEOeAAAAIGLwAQ4QQc8AAAAEJiAE7RPKtYE+11SpmQzDCVE0QEPAAAgUBGYgBNMsN8liVElAAAA0PQBqCf9vv5WlwAAAAAvwQgTUAttwwEAAFAbgQkBz7Fm6TjCEgAAAGoQmBCQekxKUtDQC3T1rCDHMYISAAAATkRgQkBxtArPlJRpSJISo+mCBwAAgIYRmBAwlk9NV9qyHEkGIQkAAACNQmBCQEhLSZWW5TDtDgAAAC4hMMGvpaWkOv5NWAIAAICrCEzwWzVhiaAEAACApiIwwe/0Wjje0f2OsAQAAIDTQWCC33B0wJtFUAIAAIB7EJjgF9JSUqVMyWYYSoiiAx4AAADcg8AEn8daJQAAAHgKgQk+iw54AAAA8DQCE3wSo0oAAABoDjarCwBcsmDu8bBkEJYAAADgcYwwwSc4WoXPWUdQAgAAQLMhMMHrpaWkSrPogAcAAIDmR2CCV2OtEgAAAKxEYIJXogMeAAAAvAGBCV6lfVKxJtjvkkRQAgAAgPXokgfvsWDu8bBEBzwAAAB4B0aYYDk64AEAAMBbEZhgqZoOeAQlAAAAeCMCEyxBUwcAAAD4AgITmh2twgEAAOArCExoNnTAAwAAgK8hMKFZ/DwFz1BidJiltQAAAACNRWCCZy2Yq7Q560RQAgAAgC8iMMFj0lJSaRUOAAAAn0ZggtvRAQ8AAAD+gsAEt6IDHgAAAPwJgQlu0WNSkq7LHCmJsAQAAAD/QWDCaeu1cLyunhUkGjsAAADA39isLgC+b9P4hZJEWAIAAIDfITDh9CyYe3zdkmF1JQAAAIDbMSUPTeKYhkfbcAAAAPgxAhNclpaSKs2SbIahhCim4QEAAMB/EZjgEtqGAwAAIJAQmNAoy6ema9WyHEmEJQAAAAQOAhNOqn1SsSbY75KW5TAFDwAAAAGHLnlwbsHc6rAkQ4nR4YQlAAAABBxGmFAPHfAAAGgepmmq8MheVVVWKLpFooKCQ60uCcAJCEyoo6YDHkEJAADPMU1T2eve07efvqb8gzslSfawGJ0x6DINuPBWBYfYLa4QQA0CExzogAcAQPP4emWG1q96WS3i+qlL98tlC7Ir/8hGbfx8ifJ2fK8x4x9XcAijTYA3IDDBEZQkwhIAAJ52KO8nrV/1stp2+IXatBvtOB4dk6IWcf2Vs/mv2rz2XfU+52oLqwRQg6YPAax9UnGdUSXCEgAAnrd57f8UEhqr1m1G1TsXFd1FsXF99cOadyyoDEBDCEwBavnU9Dod8AAAQPPIP7hLEZHJstkanugTFd1NBYdym7kqAM4wJS/QLJirtDnrpGU5BCUAACwQGhap8vJ9Ts+Xlx1RSGhEM1YE4GQITAEkLSWVVuEAAFisy5nDtfW7j3S06CdFRnWuc66yskSHDn6pbn0vsKg6ACdiSl4A6DEpiQ54AAB4iaQe56plYjf9lLNA+Yc3yjSrJEnHju3S1ux5ksp11tDrrC0SgAMjTH4uLSVVyqz+N2EJAADr2YKCddn42Vrx6kPa+uPfFRwSpaAgu0pLDioiOl5jxj+m2FbtrS4TwHEEJj/VY1KSrsscKYmgBACAtwmPitOVv/6L9udu1s7sr1RZWa6E9ilK6nGubEG8PAO8Cb+RfqZ9UnF197tMqboDXpjVJQEAgAYYhqHWHXqqdYeeVpcC4CRYw+RPFsyt0yqcsAQAAACcHkaY/AQd8AAAAAD3Y4TJ1y2YSwc8AAAAwEMYYfJhNaNKNsNQQhTT7wAAAAB3IzD5IDrgAQAAAM2DwORDanfAY1QJAAAA8DwCk49YPjVdq5bliFbhAAAAQPMhMPmAtJRUaVkO0+8AAACAZkZg8mI13e8k1ioBAAAAViAweSlahQMAAADWIzB5mV4Lx+vqWUGSCEsAAACA1QhMXsLRKnwWHfAAAAAAb0Fg8gLLp6YrjQ54AAAAgNchMFnIsa8SHfAAAAAAr0Rgsggd8AAAAADvR2CyAB3wAAAAAN9AYGpGdMADAAAAfAuBqRnU7oBHUAIAAAB8h83qAlxVWlqqfv36yTAMrV+/3upyTiktJVXXZY6UzTAISwAAAICP8bnA9Pvf/17t2rWzuoxT6rVwfJ21SuyrBAAAAPgenwpMy5Yt0/vvv68nn3zS6lJOKi0l9fhaJUaVAAAAAF/mM2uY8vLyNHHiRL355puKiIho1G1KS0tVWlrq+LygoMBT5TnQAQ8AAADwHz4RmEzT1IQJE3TnnXdq0KBB2rZtW6NuN3v2bD300EOeLe64n/dVMpQYzfQ7AAAAwB9YOiVv5syZMgzjpB9ff/21nnnmGRUUFGj69Oku3f/06dOVn5/v+Ni5c6fbv4YT1yoRlgAAAAD/YZimaVr14AcOHNCBAwdOek1ycrLGjRunt99+W4ZhOI5XVlYqKChIN998s1588cVGPV5BQYFiY2P1xZgrFRUSclq1Sz+PKtkM46RNHfIKiyUxTQ8AAADwFmUlR/Xi7LHKz89XTEyM0+ssnZIXHx+v+Pj4U143d+5czZo1y/H57t27NXr0aC1atEhDhgzxZIkNWj41XauW5UhyHoJqQhIAAAAA3+UTa5g6depU5/OoqChJUteuXdWhQ4dmrSUtJVVallMvKO0vKlGVKUn1B+xONQIFAAAAwDv5RGDyBu2TijXBfpekuqNKeYUlqglJ6ff1V49vnlLQ0AuOtxVnGh4AAADgy3wyMCUnJ6s5l16d2AHvxOl2L5TOU+72cGlihq5LSZUyf74WAAAAgO/yycDUXHotHO8YKapmKq+wWMPHdNPop9McR3MV7nQECgAAAIDvIjA5kZaSKv3cZ0Lp9/WXJk6p/iS7gWslMaoEAAAA+BcCkxPp9/VXL/vX2jR+YfWBiRn1L1owV2lz1omgBAAAAPgnApMzE6do00lOp6WkSnPWMf0OAAAA8GMEJhc1Zg8mAAAAAP6BwOSCmj2Y2FcJAAAACAwEpkboMSlJ12WOlMSoEgAAABBICEwn4WgVzr5KAAAAQECyWV2A11ow9/i+SoYSo8MJSwAAAEAAYoSpAXTAAwAAACARmOr4eQNa1ioBAAAAIDA51IQlghIAAACAGgEfmOiABwAAAMCZgA1MtTvgsa8SAAAAgIYEZGDKnPSAZq/aK1qFAwAAADiZgAxMn63Yqg7xrawuAwAAAICXC8h9mFoz/Q4AAABAIwRkYAIAAACAxiAwAQAAAIATBCYAAAAAcILABAAAAABOEJgAAAAAwAkCEwAAAAA4QWACAAAAACcITAAAAADgBIEJAAAAAJwgMAEAAACAEwQmAAAAAHCCwAQAAAAAThCYAAAAAMAJAhMAAAAAOEFgAgAAAAAnCEwAAAAA4ASBCQAAAACcIDABAAAAgBMEJgAAAABwgsAEAAAAAE4QmAAAAADACQITAAAAADhBYAIAAAAAJwhMAAAAAOAEgQkAAAAAnCAwAQAAAIATBCYAAAAAcILABAAAAABOBFtdAAAAAGCVvB3fa+MXb2jXlrUyq6rUumNP9T7naiX1GGp1afASjDABAAAgIG1e+z+99fxvtOenbMXHj1DrNqOVv++w3n/5T/pqxQKry4OXYIQJAAAAASf/4C598vZfFd/6PHVIukGGUT2OkNj2Yu3bu1LffrpIbZP7qmP3sy2uFFZjhAkAAAABZ9OatxUcHKH2na51hKUaCYkjFBHZUd9/+V+LqoM3ITABAAAg4OzftVnRMT1ls4XUO2cYhmJa9NG+3CwLKoO3ITABAAAg4Bi2YFVVlTk9X1VVJpstqBkrgrciMAEAACDgdOw+WAX536u8vLDeObOqUkcOfa2O3QdbUBm8DYEJAAAAAeeMAWMUEhKmbTn/VHlZvuN4ZWWxtv+0UOXlhep9zjUWVghvQZc8AAAABJywyFhdeku63nspTd9/+ydFx/SQYQtRUcFmmWalRl43Xa3adLG6THgBAhMAAAACUmKnMzXut/9W1rrlyt2yVlVVlera5wb1GHiZomITrC4PXoLABAAAgIBlD49Wn3OvU59zr7O6FHgp1jABAAAAgBMEJgAAAABwgsAEAAAAAE4QmAAAAADACQITAAAAADhBYAIAAAAAJwhMAAAAAOAEgQkAAAAAnCAwAQAAAIATBCYAAAAAcILABAAAAABOEJgAAAAAwAkCEwAAAAA4QWACAAAAACcITAAAAADgBIEJAAAAAJwgMAEAAACAEwQmAAAAAHCCwAQAAAAAThCYAAAAAMAJAhMAAAAAOEFgAgAAAAAnCEwAAAAA4IRPBaZ3331XQ4YMUXh4uOLj43XNNddYXRIAAAAAPxZsdQGN9cYbb2jixIl69NFHNXLkSJmmqY0bN1pdFgAAAAA/5hOBqaKiQlOnTtWcOXP061//2nG8R48eJ71daWmpSktLHZ8XFBR4rEYAAAAA/scnpuR98803ys3Nlc1mU//+/dW2bVuNGTNG33///UlvN3v2bMXGxjo+Onbs2EwVAwAAAPAHPhGYtm7dKkmaOXOmZsyYoXfeeUdxcXG64IILdOjQIae3mz59uvLz8x0fO3fubK6SAQAAAPgBSwPTzJkzZRjGST++/vprVVVVSZLS0tJ07bXXauDAgcrIyJBhGHr99ded3r/dbldMTEydDwAAAABoLEvXMN19990aN27cSa9JTk5WYWGhJKlXr16O43a7XV26dNGOHTs8WiMAAACAwGVpYIqPj1d8fPwprxs4cKDsdruysrJ03nnnSZLKy8u1bds2JSUlebpMAAAAAAHKJ7rkxcTE6M4779SDDz6ojh07KikpSXPmzJEkXX/99RZXBwAAAMBf+URgkqQ5c+YoODhYt956q4qLizVkyBCtXLlScXFxVpcGAAAAwE/5TGAKCQnRk08+qSeffNLqUgAAAAAECJ9oKw4AAAAAViAwAQAAAIATBCYAAAAAcILABAAAAABO+EzTB3cwTVOSVFZ6zOJKAAAAAFipJhPUZARnDPNUV/iRXbt2qWPHjlaXAQAAAMBL7Ny5Ux06dHB6PqACU1VVlXbv3q3o6GgZhuGRxygoKFDHjh21c+dOxcTEeOQx0Lx4Tv0Tz6v/4Tn1Tzyv/onn1f/44nNqmqYKCwvVrl072WzOVyoF1JQ8m8120vToTjExMT7zw4LG4Tn1Tzyv/ofn1D/xvPonnlf/42vPaWxs7CmvoekDAAAAADhBYAIAAAAAJwhMbma32/Xggw/KbrdbXQrchOfUP/G8+h+eU//E8+qfeF79jz8/pwHV9AEAAAAAXMEIEwAAAAA4QWACAAAAACcITAAAAADgBIEJAAAAAJwgMHnYu+++qyFDhig8PFzx8fG65pprrC4JblBaWqp+/frJMAytX7/e6nJwGrZt26Zf//rX6ty5s8LDw9W1a1c9+OCDKisrs7o0uGjevHnq3LmzwsLCNHDgQH3yySdWl4TTMHv2bA0ePFjR0dFq3bq1rrrqKmVlZVldFtxo9uzZMgxDv/nNb6wuBacpNzdXt9xyi1q1aqWIiAj169dPa9eutbostyEwedAbb7yhW2+9Vampqfr222/12Wef6aabbrK6LLjB73//e7Vr187qMuAGmzdvVlVVlf7xj3/o+++/11/+8hf9/e9/1x//+EerS4MLFi1apN/85jdKS0vTunXrdP7552vMmDHasWOH1aWhiT7++GNNnjxZq1ev1ooVK1RRUaFLLrlER48etbo0uMGaNWv03HPPqU+fPlaXgtN0+PBhDRs2TCEhIVq2bJk2bdqkp556Si1atLC6NLehrbiHVFRUKDk5WQ899JB+/etfW10O3GjZsmWaNm2a3njjDZ155plat26d+vXrZ3VZcKM5c+Zo/vz52rp1q9WloJGGDBmiAQMGaP78+Y5jPXv21FVXXaXZs2dbWBncZf/+/WrdurU+/vhjDR8+3OpycBqKioo0YMAAzZs3T7NmzVK/fv3017/+1eqy0ER/+MMf9Nlnn/n1qD4jTB7yzTffKDc3VzabTf3791fbtm01ZswYff/991aXhtOQl5eniRMn6t///rciIiKsLgcekp+fr5YtW1pdBhqprKxMa9eu1SWXXFLn+CWXXKLPP//coqrgbvn5+ZLE76YfmDx5si6//HJddNFFVpcCN3jrrbc0aNAgXX/99WrdurX69++vBQsWWF2WWxGYPKTmnemZM2dqxowZeueddxQXF6cLLrhAhw4dsrg6NIVpmpowYYLuvPNODRo0yOpy4CFbtmzRM888ozvvvNPqUtBIBw4cUGVlpRITE+scT0xM1N69ey2qCu5kmqamTZum8847T71797a6HJyGV199Vd988w0jv35k69atmj9/vrp3767ly5frzjvv1JQpU7Rw4UKrS3MbApOLZs6cKcMwTvrx9ddfq6qqSpKUlpama6+9VgMHDlRGRoYMw9Drr79u8VeB2hr7nD7zzDMqKCjQ9OnTrS4ZjdDY57W23bt369JLL9X111+v22+/3aLK0VSGYdT53DTNesfgm+6++25t2LBBr7zyitWl4DTs3LlTU6dO1UsvvaSwsDCry4GbVFVVacCAAXr00UfVv39/3XHHHZo4cWKdKdK+LtjqAnzN3XffrXHjxp30muTkZBUWFkqSevXq5Thut9vVpUsXFiF7mcY+p7NmzdLq1atlt9vrnBs0aJBuvvlmvfjii54sEy5q7PNaY/fu3RoxYoSGDh2q5557zsPVwZ3i4+MVFBRUbzRp37599Uad4HvuuecevfXWW1q1apU6dOhgdTk4DWvXrtW+ffs0cOBAx7HKykqtWrVKzz77rEpLSxUUFGRhhWiKtm3b1nm9K1WvIX3jjTcsqsj9CEwuio+PV3x8/CmvGzhwoOx2u7KysnTeeedJksrLy7Vt2zYlJSV5uky4oLHP6dy5czVr1izH57t379bo0aO1aNEiDRkyxJMlogka+7xK1e1QR4wY4RgJttkYfPcloaGhGjhwoFasWKGrr77acXzFihUaO3ashZXhdJimqXvuuUdLly7VRx99pM6dO1tdEk7TqFGjtHHjxjrHUlNTdcYZZ+j+++8nLPmoYcOG1Wv5n52d7VevdwlMHhITE6M777xTDz74oDp27KikpCTNmTNHknT99ddbXB2aolOnTnU+j4qKkiR17dqVdz192O7du3XhhReqU6dOevLJJ7V//37HuTZt2lhYGVwxbdo03XrrrRo0aJBjlHDHjh2sRfNhkydP1ssvv6z//ve/io6OdowgxsbGKjw83OLq0BTR0dH11qBFRkaqVatWrE3zYb/97W917rnn6tFHH9UNN9ygr776Ss8995xfzdYgMHnQnDlzFBwcrFtvvVXFxcUaMmSIVq5cqbi4OKtLA3Dc+++/r5ycHOXk5NQLvuy64Dt++ctf6uDBg3r44Ye1Z88e9e7dW//73//86h3OQFOz/uHCCy+sczwjI0MTJkxo/oIANGjw4MFaunSppk+frocfflidO3fWX//6V918881Wl+Y27MMEAAAAAE4wUR8AAAAAnCAwAQAAAIATBCYAAAAAcILABAAAAABOEJgAAAAAwAkCEwAAAAA4QWACAAAAACcITAAAAADgBIEJAALQhRdeqN/85jduu7+ZM2eqX79+brs/Sdq2bZsMw9D69evder8AALiCwAQAPmzChAkyDEOGYSgkJERdunTR7373Ox09evSkt1uyZIkeeeQRt9Xxu9/97v/bu/uYpq43DuDflndaEFrlRUFAFBVfKgqaigMnJhrxBZPFoM6IGBw6nRFEjSFWjDOwhUWiDsGoMf7hy+IQgyjbUNHIrIIUmYBGsFEnhAx8K2oUe35/GK90Uqib+W247ydp0nPvuc95evoHPDnn3qK0tPSDxXsft27dwpIlS+Dn5wcnJycEBQVh/vz5qKio+Efy+beytUj+8ccfMW3aNPTt25cFKxERWDAREfV606dPR1NTExobG7F161Z8//33WLt2bZd9X758CQBQqVRwc3P7YDkolUqo1eoPFs9WFRUVGDduHG7evIm8vDzU1taioKAAw4YNQ2pq6v89n49Be3s7IiMjkZmZ+U+nQkT0r8CCiYiol3NycoKPjw/8/f2xYMECLFy4EMePHwfwdqvcvn37MGjQIDg5OUEI8c5qQ2BgILZt24bExES4ublh4MCByM/Ptxjn3r17iI+Ph0qlgkKhQHh4OPR6vcU4byQkJCAuLg4ZGRnw8vKCu7s7vvjiC7x48ULqc/r0aUyaNAkeHh5Qq9WYOXMmGhoabP7cQggkJCRgyJAhuHDhAmJjYxEcHIwxY8ZAp9OhsLBQ6ltTU4MpU6bAxcUFarUay5Ytg8lkeiffbdu2wdvbGx4eHsjIyEBHRwfS0tKgUqng5+eHffv2Sde82TJ4+PBhTJw4Ec7OzhgxYgTOnTtnkWdZWRnGjx8PJycn+Pr6YsOGDejo6JDOT548GV999RXWrVsHlUoFHx8fbN682SLGo0ePsGzZMmkup0yZgurqaun8m/k/ePAgAgMD0adPH8THx+PJkyfS5ysrK0NOTo60Imk0Gruc10WLFmHTpk2YOnWqzd8FEdHHjAUTEdFHxsXFRVpJAl5vWTt69CiOHTvW7faq7OxshIeHo6qqCitWrMDy5ctRX18PADCZTIiOjsb9+/dx4sQJVFdXY926dTCbzVbjlZaWoq6uDmfPnsWhQ4dQUFCAjIwM6Xx7eztSUlJw5coVlJaWQi6XY+7cud3G7MxgMOD69etITU2FXP7unzMPDw8AwNOnTzF9+nR4enriypUr+OGHH/DLL79g5cqVFv3PnDmD+/fv4/z58/juu++wefNmzJw5E56entDr9UhOTkZycjLu3r1rcV1aWhpSU1NRVVWFiRMnYvbs2WhtbQUA/P7775gxYwYiIiJQXV2N3Nxc7N27F1u3brWIceDAASgUCuj1enzzzTfYsmULfv75ZwCvC8PY2Fg0NzejuLgYlZWVGDt2LGJiYtDW1ibFaGhowPHjx1FUVISioiKUlZVJq0Q5OTnQarVISkpCU1MTmpqa4O/vb9M8ExH95wkiIuq1Fi9eLObMmSO19Xq9UKvVYt68eUIIIXQ6nXBwcBAtLS0W10VHR4vVq1dL7YCAAPH5559LbbPZLLy8vERubq4QQoi8vDzh5uYmWltbu8xDp9MJjUZjkZdKpRLt7e3SsdzcXKFUKsWrV6+6jNHS0iIAiJqaGiGEELdv3xYARFVVVZf9jxw5IgCIq1evdnn+jfz8fOHp6SlMJpN07OTJk0Iul4vm5mYp34CAAIvchg4dKj755BOp3dHRIRQKhTh06JBFfpmZmVKfly9fCj8/P5GVlSWEEGLjxo1i6NChwmw2S3127dplMQ/R0dFi0qRJFjlHRESI9evXCyGEKC0tFe7u7uL58+cWfYKDg0VeXp4Q4vX8u7q6isePH0vn09LSxIQJE6T2n7/znvQ0/0RE/xVcYSIi6uWKioqgVCrh7OwMrVaLqKgo7NixQzofEBCAfv369Rhn9OjR0nuZTAYfHx+0tLQAeL2aExYWBpVKZXNeGo0Grq6uUlur1cJkMkkrNA0NDViwYAEGDRoEd3d3BAUFAQDu3LljU3whhJRrd+rq6qDRaKBQKKRjkZGRMJvNuHHjhnRsxIgRFitV3t7eGDVqlNS2s7ODWq2W5qTz53rD3t4e4eHhqKurk8bWarUWOUZGRsJkMuHevXvSsc5zDwC+vr7SOJWVlTCZTFCr1VAqldLr9u3bFlsYAwMDLe5L6xyDiIj+Ovt/OgEiIvp7Pv30U+Tm5sLBwQH9+/eHg4ODxfnOhUJ3/nydTCaTtse5uLh8mGTxtsCZNWsW/P39sWfPHvTv3x9msxkjR460uM+pOyEhIQBeFyXdPdJcCGG1qOp8vKvP392cdOdN3K7G7qrQ624cs9kMX1/fd+6NAt5uO+wpBhER/XVcYSIi6uUUCgUGDx6MgICAd/5p/lBGjx4Ng8Fgcc9MT6qrq/Hs2TOpfenSJSiVSvj5+aG1tRV1dXVIT09HTEwMhg8fjgcPHrxXTmPGjEFoaCiys7O7LAwePnwIAAgNDYXBYLB41PrFixchl8ulouvvuHTpkvS+o6MDlZWVGDZsmDR2eXm5VCQBQHl5Odzc3DBgwACb4o8dOxbNzc2wt7fH4MGDLV59+/a1OU9HR0e8evXK5v5ERPQaCyYiIurR/Pnz4ePjg7i4OFy8eBGNjY04duwYfv31V6vXvHjxAkuXLkVtbS1OnToFnU6HlStXQi6Xw9PTE2q1Gvn5+bh16xbOnDmDlJSU98pJJpNh//79uHnzJqKiolBcXIzGxkZcu3YNX3/9NebMmQMAWLhwIZydnbF48WL89ttvOHv2LFatWoVFixbB29v7b80LAOzatQsFBQWor6/Hl19+iQcPHiAxMREAsGLFCty9exerVq1CfX09CgsLodPpkJKS0uWDKroydepUaLVaxMXFoaSkBEajEeXl5UhPT3+v35oKDAyEXq+H0WjEH3/8YXX1qa2tDQaDAbW1tQCAGzduwGAwoLm52eaxiIg+JiyYiIioR46Ojvjpp5/g5eWFGTNmYNSoUcjMzISdnZ3Va2JiYjBkyBBERUVh3rx5mDVrlvS4bLlcjsOHD6OyshIjR47EmjVr8O233753XuPHj0dFRQWCg4ORlJSE4cOHY/bs2bh+/Tq2b98OAHB1dUVJSQna2toQERGBzz77DDExMdi5c+dfmYp3ZGZmIisrCxqNBhcuXEBhYaG08jNgwAAUFxfj8uXL0Gg0SE5OxtKlS5Genm5zfJlMhuLiYkRFRSExMREhISGIj4+H0Wh8r4Jv7dq1sLOzQ2hoKPr162f1XrETJ04gLCwMsbGxAID4+HiEhYVh9+7dNo9FRPQxkYnO+wSIiIg+gISEBDx8+FD6PaiPkdFoRFBQEKqqqrq9h4qIiHo3rjARERERERFZwYKJiIiIiIjICm7JIyIiIiIisoIrTERERERERFawYCIiIiIiIrKCBRMREREREZEVLJiIiIiIiIisYMFERERERERkBQsmIiIiIiIiK1gwERERERERWcGCiYiIiIiIyIr/Ac+QOk2dIl6wAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 16:03:45,526 - INFO - Decision boundary plot displayed successfully.\n",
      "2025-01-09 16:03:45,533 - INFO - 📌 Tuning hyperparameters for Decision Tree...\n",
      "2025-01-09 16:03:45,534 - INFO - Starting hyperparameter tuning for Decision Tree...\n",
      "2025-01-09 16:03:45,537 - INFO - Parameter space: {'max_depth': Integer(low=2, high=50, prior='uniform', transform='identity'), 'min_samples_split': Integer(low=2, high=20, prior='uniform', transform='identity'), 'min_samples_leaf': Integer(low=1, high=10, prior='uniform', transform='identity'), 'criterion': Categorical(categories=('gini', 'entropy'), prior=None), 'splitter': Categorical(categories=('best', 'random'), prior=None)}\n",
      "c:\\Users\\ghadf\\anaconda3\\envs\\data_science_ml_preprocessor\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point ['gini', 50, 9, 2, 'random'] before, using random point ['entropy', 30, 4, 19, 'best']\n",
      "  warnings.warn(\n",
      "c:\\Users\\ghadf\\anaconda3\\envs\\data_science_ml_preprocessor\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point ['gini', 50, 9, 2, 'random'] before, using random point ['entropy', 11, 7, 8, 'random']\n",
      "  warnings.warn(\n",
      "c:\\Users\\ghadf\\anaconda3\\envs\\data_science_ml_preprocessor\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point ['entropy', 24, 8, 20, 'random'] before, using random point ['entropy', 15, 3, 6, 'best']\n",
      "  warnings.warn(\n",
      "2025-01-09 16:04:28,477 - INFO - Best parameters found: OrderedDict([('criterion', 'entropy'), ('max_depth', 3), ('min_samples_leaf', 8), ('min_samples_split', 20), ('splitter', 'random')])\n",
      "2025-01-09 16:04:28,478 - INFO - Best cross-validation score: -0.6167987475602181\n",
      "2025-01-09 16:04:28,478 - INFO - ✅ Decision Tree tuning done. Best Params: OrderedDict([('criterion', 'entropy'), ('max_depth', 3), ('min_samples_leaf', 8), ('min_samples_split', 20), ('splitter', 'random')]), Best CV Score: -0.6167987475602181\n",
      "2025-01-09 16:04:28,479 - INFO - Evaluating model...\n",
      "2025-01-09 16:04:28,481 - INFO - Predicted probabilities: [0.41176471 0.41176471 0.9        0.75       0.75       0.75\n",
      " 0.41176471 0.44444444 0.08695652 0.08695652 0.86666667 0.44444444\n",
      " 0.75       0.9        0.44444444 0.86666667 0.9        0.44444444\n",
      " 0.44444444 0.75       0.9        0.9        0.9        0.9\n",
      " 0.9       ]\n",
      "2025-01-09 16:04:28,486 - INFO - Evaluation Metrics: {'accuracy': 0.56, 'precision': 0.612, 'recall': 0.56, 'f1_score': 0.5788235294117647, 'roc_auc': 0.4563492063492064, 'log_loss': 0.8345673551170053}\n",
      "2025-01-09 16:04:28,490 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.43      0.35         7\n",
      "           1       0.73      0.61      0.67        18\n",
      "\n",
      "    accuracy                           0.56        25\n",
      "   macro avg       0.52      0.52      0.51        25\n",
      "weighted avg       0.61      0.56      0.58        25\n",
      "\n",
      "2025-01-09 16:04:28,491 - INFO - Classification report saved to C:\\Users\\ghadf\\vscode_projects\\docker_projects\\ml_preprocessor\\examples\\preprocessor\\models\\classification_report.txt\n",
      "2025-01-09 16:04:28,558 - INFO - Confusion matrix saved to 'C:\\Users\\ghadf\\vscode_projects\\docker_projects\\ml_preprocessor\\examples\\preprocessor\\models\\confusion_matrix.png'\n",
      "2025-01-09 16:04:28,559 - INFO - Original X shape: (25, 14)\n",
      "2025-01-09 16:04:28,559 - INFO - X has more than 2 features, applying PCA for visualization.\n",
      "2025-01-09 16:04:28,561 - INFO - PCA explained variance ratios: [0.45925915 0.23948802]\n",
      "2025-01-09 16:04:28,562 - INFO - Transformed X shape for plotting: (25, 2)\n",
      "2025-01-09 16:04:28,568 - INFO - Mesh grid created with shape xx: (1375, 1319), yy: (1375, 1319)\n",
      "2025-01-09 16:04:28,575 - INFO - Grid points in 2D PCA space shape: (1813625, 2)\n",
      "2025-01-09 16:04:28,576 - INFO - Inverse transforming grid points back to original feature space for prediction.\n",
      "2025-01-09 16:04:28,663 - INFO - Grid points in original feature space shape: (1813625, 14)\n",
      "c:\\Users\\ghadf\\anaconda3\\envs\\data_science_ml_preprocessor\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-01-09 16:04:28,740 - INFO - Decision boundary predictions reshaped to: (1375, 1319)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 16:04:28,924 - INFO - Decision boundary plot displayed successfully.\n",
      "2025-01-09 16:04:28,931 - INFO - ✅ Best model is Decision Tree with Log Loss=0.8345673551170053\n",
      "2025-01-09 16:04:28,933 - INFO - Model saved to C:\\Users\\ghadf\\vscode_projects\\docker_projects\\ml_preprocessor\\examples\\preprocessor\\models\\Decision_Tree\\trained_model.pkl\n",
      "2025-01-09 16:04:28,934 - INFO - ✅ Model 'Decision Tree' saved successfully in 'C:\\Users\\ghadf\\vscode_projects\\docker_projects\\ml_preprocessor\\examples\\preprocessor\\models'.\n",
      "2025-01-09 16:04:28,935 - INFO - ✅ Tuning results saved to C:\\Users\\ghadf\\vscode_projects\\docker_projects\\ml_preprocessor\\examples\\preprocessor\\models\\tuning_results.json.\n",
      "2025-01-09 16:04:28,935 [INFO] ✅ Training workflow completed successfully.\n",
      "2025-01-09 16:04:28,935 - INFO - ✅ Training workflow completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import json\n",
    "from typing import Any, Dict\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import joblib  # Ensure joblib is imported\n",
    "\n",
    "# Local imports - Adjust the import paths based on your project structure\n",
    "# from datapreprocessor import DataPreprocessor\n",
    "# from train_utils.train_utils import (\n",
    "#     evaluate_model, save_model, load_model, plot_decision_boundary,\n",
    "#     tune_random_forest, tune_xgboost, tune_decision_tree\n",
    "# )\n",
    "# from model_factory import get_model\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_config(config_path: Path) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Load configuration from a YAML file.\n",
    "\n",
    "    Args:\n",
    "        config_path (Path): Path to the configuration file.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: Configuration dictionary.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with config_path.open('r') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "        logger.info(f\"✅ Configuration loaded from {config_path}.\")\n",
    "        return config\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Failed to load configuration: {e}\")\n",
    "        raise\n",
    "\n",
    "def bayes_best_model_train(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: pd.Series,\n",
    "    selection_metric: str,\n",
    "    model_save_dir: Path,\n",
    "    classification_save_path: Path,\n",
    "    tuning_results_save: Path,\n",
    "    selected_models: Any,\n",
    "    use_pca: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    A streamlined function that:\n",
    "      1) Tunes and trains models using Bayesian optimization.\n",
    "      2) Evaluates the best model.\n",
    "      3) Saves the tuning results and best model.\n",
    "\n",
    "    Args:\n",
    "        X_train, y_train: Training features and labels.\n",
    "        X_test, y_test: Test features and labels.\n",
    "        selection_metric (str): Metric to select best model (e.g., \"Log Loss\", \"accuracy\").\n",
    "        model_save_dir (Path): Directory to save the best model.\n",
    "        classification_save_path (Path): Path to save classification report.\n",
    "        tuning_results_save (Path): Path to save tuning results in JSON format.\n",
    "        selected_models (list|str): List of models (e.g. [\"XGBoost\", \"Random Forest\"]) or a single string.\n",
    "        use_pca (bool): If True, uses PCA for boundary plotting. Typically False for tree-based models.\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting the Bayesian hyperparameter tuning process...\")\n",
    "\n",
    "    # Scoring metric selection\n",
    "    scoring_metric = \"neg_log_loss\" if selection_metric.lower() == \"log loss\" else \"accuracy\"\n",
    "\n",
    "    # Prepare model registry\n",
    "    model_registry = {\n",
    "        # \"XGBoost\": tune_xgboost,\n",
    "        \"Random Forest\": tune_random_forest,\n",
    "        \"Decision Tree\": tune_decision_tree\n",
    "    }\n",
    "\n",
    "    # Normalize selected_models input\n",
    "    if isinstance(selected_models, str):\n",
    "        selected_models = [selected_models]\n",
    "    elif not selected_models:\n",
    "        selected_models = list(model_registry.keys())\n",
    "        logger.info(f\"No models specified. Using all available: {selected_models}\")\n",
    "\n",
    "    tuning_results = {}\n",
    "    best_model_name = None\n",
    "    best_model = None\n",
    "    best_metric_value = None\n",
    "\n",
    "    # Ensure model_save_dir exists\n",
    "    model_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    logger.debug(f\"Ensured that the model save directory '{model_save_dir}' exists.\")\n",
    "\n",
    "    # Loop over requested models\n",
    "    for model_name in selected_models:\n",
    "        if model_name not in model_registry:\n",
    "            logger.warning(f\"Unsupported model: {model_name}. Skipping.\")\n",
    "            continue\n",
    "        try:\n",
    "            logger.info(f\"📌 Tuning hyperparameters for {model_name}...\")\n",
    "            tuner_func = model_registry[model_name]\n",
    "\n",
    "            best_params, best_score, best_estimator = tuner_func(\n",
    "                X_train, y_train, scoring_metric=scoring_metric\n",
    "            )\n",
    "            logger.info(f\"✅ {model_name} tuning done. Best Params: {best_params}, Best CV Score: {best_score}\")\n",
    "\n",
    "            # Evaluate on X_test\n",
    "            metrics = evaluate_model(best_estimator, X_test, y_test, save_path=classification_save_path)\n",
    "            metric_key = selection_metric.lower().replace(\" \", \"_\")\n",
    "            metric_value = metrics.get(metric_key)\n",
    "\n",
    "            if metric_value is not None:\n",
    "                logger.debug(f\"Metric value for {selection_metric}: {metric_value}\")\n",
    "                if best_metric_value is None:\n",
    "                    best_metric_value = metric_value\n",
    "                    best_model_name = model_name\n",
    "                    best_model = best_estimator\n",
    "                    logger.debug(f\"Best model set to {best_model_name} with {selection_metric}={best_metric_value}\")\n",
    "                else:\n",
    "                    # For log loss, lower is better\n",
    "                    if selection_metric.lower() == \"log loss\" and metric_value < best_metric_value:\n",
    "                        best_metric_value = metric_value\n",
    "                        best_model_name = model_name\n",
    "                        best_model = best_estimator\n",
    "                        logger.debug(f\"Best model updated to {best_model_name} with {selection_metric}={best_metric_value}\")\n",
    "                    # For other metrics (accuracy, f1, etc.), higher is better\n",
    "                    elif selection_metric.lower() != \"log loss\" and metric_value > best_metric_value:\n",
    "                        best_metric_value = metric_value\n",
    "                        best_model_name = model_name\n",
    "                        best_model = best_estimator\n",
    "                        logger.debug(f\"Best model updated to {best_model_name} with {selection_metric}={best_metric_value}\")\n",
    "            else:\n",
    "                logger.debug(f\"Metric value for {selection_metric} is None. Best model not updated.\")\n",
    "\n",
    "            # Save partial results\n",
    "            tuning_results[model_name] = {\n",
    "                \"Best Params\": best_params,\n",
    "                \"Best CV Score\": best_score,\n",
    "                \"Evaluation Metrics\": metrics,\n",
    "            }\n",
    "\n",
    "            # Plot boundary (optional for tree-based with PCA)\n",
    "            try:\n",
    "                plot_decision_boundary(best_estimator, X_test, y_test, f\"{model_name} Decision Boundary\", use_pca=use_pca)\n",
    "            except ValueError as e:\n",
    "                logger.warning(f\"Skipping decision boundary plot for {model_name}: {e}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"❌ Error tuning {model_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Save best model information\n",
    "    if best_model_name:\n",
    "        logger.info(f\"✅ Best model is {best_model_name} with {selection_metric}={best_metric_value}\")\n",
    "        try:\n",
    "            save_model(best_model, best_model_name, save_dir=model_save_dir)\n",
    "            logger.info(f\"✅ Model '{best_model_name}' saved successfully in '{model_save_dir}'.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"❌ Failed to save best model {best_model_name}: {e}\")\n",
    "            raise  # Ensure the exception is propagated\n",
    "\n",
    "        # Add Best Model info to tuning_results\n",
    "        tuning_results[\"Best Model\"] = {\n",
    "            \"model_name\": best_model_name,\n",
    "            \"metric_value\": best_metric_value,\n",
    "            \"path\": str(Path(model_save_dir) / best_model_name.replace(\" \", \"_\") / 'trained_model.pkl')\n",
    "        }\n",
    "    else:\n",
    "        logger.warning(\"⚠️ No best model was selected. Tuning might have failed for all models.\")\n",
    "\n",
    "    # Save tuning results\n",
    "    try:\n",
    "        with tuning_results_save.open(\"w\") as f:\n",
    "            json.dump(tuning_results, f, indent=4)\n",
    "        logger.info(f\"✅ Tuning results saved to {tuning_results_save}.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Error saving tuning results: {e}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # ----------------------------\n",
    "    # 1. Load Configuration\n",
    "    # ----------------------------\n",
    "    config = load_config(Path('../../dataset/test/preprocessor_config/preprocessor_config.yaml'))\n",
    "\n",
    "    # Extract paths from configuration\n",
    "    paths_config = config.get('paths', {})\n",
    "    base_data_dir = Path(paths_config.get('data_dir', '../../dataset/test/data')).resolve()\n",
    "    raw_data_file = base_data_dir / paths_config.get('raw_data', 'final_ml_dataset.csv')\n",
    "    processed_data_dir = base_data_dir / paths_config.get('processed_data_dir', 'preprocessor/processed')\n",
    "    features_metadata_file = base_data_dir / paths_config.get('features_metadata_file', 'features_info/features_metadata.pkl')\n",
    "    predictions_output_dir = base_data_dir / paths_config.get('predictions_output_dir', 'preprocessor/predictions')\n",
    "    config_file = Path(paths_config.get('config_file', 'preprocessor_config/preprocessor_config.yaml')).resolve()\n",
    "\n",
    "    # Output directories\n",
    "    log_dir = Path(paths_config.get('log_dir', '../preprocessor/logs')).resolve()\n",
    "    model_save_base_dir = Path(paths_config.get('model_save_base_dir', '../preprocessor/models')).resolve()\n",
    "    transformers_save_base_dir = Path(paths_config.get('transformers_save_base_dir', '../preprocessor/transformers')).resolve()\n",
    "    plots_output_dir = Path(paths_config.get('plots_output_dir', '../preprocessor/plots')).resolve()\n",
    "    training_output_dir = Path(paths_config.get('training_output_dir', '../preprocessor/training_output')).resolve()\n",
    "\n",
    "    # Initialize Paths for saving\n",
    "    MODEL_SAVE_DIR = model_save_base_dir\n",
    "    MODEL_SAVE_DIR.mkdir(parents=True, exist_ok=True)  # Ensure the directory exists\n",
    "    CLASSIFICATION_REPORT_PATH = MODEL_SAVE_DIR / \"classification_report.txt\"\n",
    "    TUNING_RESULTS_SAVE_PATH = MODEL_SAVE_DIR / \"tuning_results.json\"\n",
    "\n",
    "\n",
    "    LOG_FILE = 'training.log'\n",
    "\n",
    "    SELECTED_MODELS = [\"Random Forest\"]  # For testing, select a single model\n",
    "    SELECTION_METRIC = \"accuracy\"  # Change to \"Log Loss\" if needed\n",
    "\n",
    "    # Extract model-related config\n",
    "    selected_models = config.get('models', {}).get('selected_models', [\"XGBoost\", \"Random Forest\", \"Decision Tree\"])\n",
    "    selection_metric = config.get('models', {}).get('selection_metric', \"Log Loss\")\n",
    "\n",
    "    # Extract Tree Based Classifier options from config\n",
    "    tree_classifier_options = config.get('models', {}).get('Tree Based Classifier', {})\n",
    "\n",
    "    # ----------------------------\n",
    "    # 2. Setup Logging\n",
    "    # ----------------------------\n",
    "    logger = setup_logging(log_dir, LOG_FILE)\n",
    "    logger.info(\"✅ Starting the training module.\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # 3. Load Data\n",
    "    # ----------------------------\n",
    "    try:\n",
    "        filtered_df = pd.read_csv(raw_data_file)\n",
    "        logger.info(f\"✅ Loaded dataset from {raw_data_file}. Shape: {filtered_df.shape}\")\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"❌ Dataset not found at {raw_data_file}.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Failed to load dataset: {e}\")\n",
    "        return\n",
    "\n",
    "    # Extract feature assets\n",
    "    features_config = config.get('features', {})\n",
    "    column_assets = {\n",
    "        'y_variable': features_config.get('y_variable', []),\n",
    "        'ordinal_categoricals': features_config.get('ordinal_categoricals', []),\n",
    "        'nominal_categoricals': features_config.get('nominal_categoricals', []),\n",
    "        'numericals': features_config.get('numericals', [])\n",
    "    }\n",
    "\n",
    "    # ----------------------------\n",
    "    # 4. Initialize DataPreprocessor\n",
    "    # ----------------------------\n",
    "    # Assuming a supervised classification use case: \"Tree Based Classifier\"\n",
    "    preprocessor = DataPreprocessor(\n",
    "        model_type=\"Tree Based Classifier\",\n",
    "        y_variable=column_assets.get('y_variable', []),\n",
    "        ordinal_categoricals=column_assets.get('ordinal_categoricals', []),\n",
    "        nominal_categoricals=column_assets.get('nominal_categoricals', []),\n",
    "        numericals=column_assets.get('numericals', []), \n",
    "        mode='train',\n",
    "        options=tree_classifier_options,  # The options from config for \"Tree Based Classifier\"\n",
    "        debug=config.get('logging', {}).get('debug', False),  # or config-based\n",
    "        normalize_debug=config.get('execution', {}).get('train', {}).get('normalize_debug', False),\n",
    "        normalize_graphs_output=config.get('execution', {}).get('train', {}).get('normalize_graphs_output', False),\n",
    "        graphs_output_dir=plots_output_dir,\n",
    "        transformers_dir=transformers_save_base_dir\n",
    "    )\n",
    "\n",
    "    # ----------------------------\n",
    "    # 5. Execute Preprocessing\n",
    "    # ----------------------------\n",
    "    try:\n",
    "        # Execute preprocessing by passing the entire filtered_df\n",
    "        X_train, X_test, y_train, y_test, recommendations, X_test_inverse = preprocessor.final_preprocessing(filtered_df)\n",
    "        print(\"types of all variables starting with X_train\", type(X_train), \"X_test type\", type(X_test), \"y_train type =\", type(y_train), \"y_test type =\", type(y_test),\"X_test_inverse type =\", type(X_test_inverse))\n",
    "        logger.info(f\"✅ Preprocessing complete. X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Error during preprocessing: {e}\")\n",
    "        return\n",
    "\n",
    "    # ----------------------------\n",
    "    # 6. Train & Tune the Model\n",
    "    # ----------------------------\n",
    "    try:\n",
    "        bayes_best_model_train(\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            X_test=X_test,\n",
    "            y_test=y_test,\n",
    "            selection_metric=selection_metric,\n",
    "            model_save_dir=MODEL_SAVE_DIR,\n",
    "            classification_save_path=CLASSIFICATION_REPORT_PATH,\n",
    "            tuning_results_save=TUNING_RESULTS_SAVE_PATH,\n",
    "            selected_models=selected_models,\n",
    "            use_pca=True  \n",
    "        )\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Model training/tuning failed: {e}\")\n",
    "        return\n",
    "\n",
    "    # ----------------------------\n",
    "    # 7. Completion Message\n",
    "    # ----------------------------\n",
    "    logger.info(\"✅ Training workflow completed successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 16:04:28,983 [INFO] ✅ Starting prediction module.\n",
      "2025-01-09 16:04:28,983 - INFO - ✅ Starting prediction module.\n",
      "2025-01-09 16:04:28,992 [INFO] Best model identified: Decision Tree\n",
      "2025-01-09 16:04:28,992 - INFO - Best model identified: Decision Tree\n",
      "2025-01-09 16:04:28,998 [INFO] ✅ Prediction input data loaded from 'C:\\Users\\ghadf\\vscode_projects\\docker_projects\\ml_preprocessor\\dataset\\test\\data\\final_ml_dataset.csv'.\n",
      "2025-01-09 16:04:28,998 - INFO - ✅ Prediction input data loaded from 'C:\\Users\\ghadf\\vscode_projects\\docker_projects\\ml_preprocessor\\dataset\\test\\data\\final_ml_dataset.csv'.\n",
      "2025-01-09 16:04:29,000 [INFO] Starting: Final Preprocessing Pipeline in 'predict' mode.\n",
      "2025-01-09 16:04:29,000 - INFO - Starting: Final Preprocessing Pipeline in 'predict' mode.\n",
      "2025-01-09 16:04:29,001 [INFO] Step: filter_columns\n",
      "2025-01-09 16:04:29,001 - INFO - Step: filter_columns\n",
      "2025-01-09 16:04:29,002 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 14)\n",
      "2025-01-09 16:04:29,002 - INFO - ✅ Filtered DataFrame to include only specified features. Shape: (125, 14)\n",
      "2025-01-09 16:04:29,003 [INFO] ✅ Column filtering completed successfully.\n",
      "2025-01-09 16:04:29,003 - INFO - ✅ Column filtering completed successfully.\n",
      "2025-01-09 16:04:29,004 [INFO] Step: Preprocess Predict\n",
      "2025-01-09 16:04:29,004 - INFO - Step: Preprocess Predict\n",
      "2025-01-09 16:04:29,005 [INFO] Step: Load Transformers\n",
      "2025-01-09 16:04:29,005 - INFO - Step: Load Transformers\n",
      "2025-01-09 16:04:29,007 [INFO] Transformers loaded successfully from 'C:\\Users\\ghadf\\vscode_projects\\docker_projects\\ml_preprocessor\\examples\\preprocessor\\transformers\\transformers.pkl'.\n",
      "2025-01-09 16:04:29,007 - INFO - Transformers loaded successfully from 'C:\\Users\\ghadf\\vscode_projects\\docker_projects\\ml_preprocessor\\examples\\preprocessor\\transformers\\transformers.pkl'.\n",
      "2025-01-09 16:04:29,008 [INFO] Step: filter_columns\n",
      "2025-01-09 16:04:29,008 - INFO - Step: filter_columns\n",
      "2025-01-09 16:04:29,009 [INFO] ✅ Filtered DataFrame to include only specified features. Shape: (125, 14)\n",
      "2025-01-09 16:04:29,009 - INFO - ✅ Filtered DataFrame to include only specified features. Shape: (125, 14)\n",
      "2025-01-09 16:04:29,010 [INFO] Step: Handle Missing Values\n",
      "2025-01-09 16:04:29,010 - INFO - Step: Handle Missing Values\n",
      "2025-01-09 16:04:29,030 [INFO] Step: Generate Preprocessor Recommendations\n",
      "2025-01-09 16:04:29,030 - INFO - Step: Generate Preprocessor Recommendations\n",
      "2025-01-09 16:04:29,031 [INFO] Preprocessing Recommendations generated.\n",
      "2025-01-09 16:04:29,031 - INFO - Preprocessing Recommendations generated.\n",
      "2025-01-09 16:04:29,032 [INFO] Step 'Generate Preprocessor Recommendations' completed: Recommendations generated.\n",
      "2025-01-09 16:04:29,032 - INFO - Step 'Generate Preprocessor Recommendations' completed: Recommendations generated.\n",
      "2025-01-09 16:04:29,033 [INFO] ✅ Preprocessing completed successfully in predict mode.\n",
      "2025-01-09 16:04:29,033 - INFO - ✅ Preprocessing completed successfully in predict mode.\n",
      "2025-01-09 16:04:29,034 [INFO] ✅ Preprocessing completed successfully in predict mode.\n",
      "2025-01-09 16:04:29,034 - INFO - ✅ Preprocessing completed successfully in predict mode.\n",
      "2025-01-09 16:04:29,043 - INFO - Model loaded from C:\\Users\\ghadf\\vscode_projects\\docker_projects\\ml_preprocessor\\examples\\preprocessor\\models\\Decision_Tree\\trained_model.pkl\n",
      "2025-01-09 16:04:29,044 [INFO] ✅ Trained model loaded from 'C:\\Users\\ghadf\\vscode_projects\\docker_projects\\ml_preprocessor\\examples\\preprocessor\\models\\Decision_Tree\\trained_model.pkl'.\n",
      "2025-01-09 16:04:29,044 - INFO - ✅ Trained model loaded from 'C:\\Users\\ghadf\\vscode_projects\\docker_projects\\ml_preprocessor\\examples\\preprocessor\\models\\Decision_Tree\\trained_model.pkl'.\n",
      "2025-01-09 16:04:29,046 [INFO] ✅ Predictions made successfully.\n",
      "2025-01-09 16:04:29,046 - INFO - ✅ Predictions made successfully.\n",
      "2025-01-09 16:04:29,047 [INFO] ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 16:04:29,047 - INFO - ✅ Predictions attached to inversed data successfully.\n",
      "2025-01-09 16:04:29,050 [INFO] ✅ Predictions saved to 'C:\\Users\\ghadf\\vscode_projects\\docker_projects\\ml_preprocessor\\examples\\notebooks\\preprocessor\\predictions\\predictions_Decision_Tree.csv'.\n",
      "2025-01-09 16:04:29,050 - INFO - ✅ Predictions saved to 'C:\\Users\\ghadf\\vscode_projects\\docker_projects\\ml_preprocessor\\examples\\notebooks\\preprocessor\\predictions\\predictions_Decision_Tree.csv'.\n",
      "2025-01-09 16:04:29,051 [INFO] ✅ All prediction tasks completed successfully for model 'Decision Tree'.\n",
      "2025-01-09 16:04:29,051 - INFO - ✅ All prediction tasks completed successfully for model 'Decision Tree'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_new_preprocessed type =  <class 'pandas.core.frame.DataFrame'> X_new_inverse type =  <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# src/ml/predict.py\n",
    "\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "import yaml\n",
    "import joblib\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict\n",
    "\n",
    "# Local imports - Adjust based on your project structure\n",
    "# from train_utils.train_utils import load_model  # Ensure correct import path\n",
    "# from datapreprocessor.datapreprocessor import DataPreprocessor  # Uncomment and adjust as necessary\n",
    "\n",
    "def load_dataset(path: Path) -> pd.DataFrame:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Dataset not found at {path}\")\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def load_config(config_path: Path) -> Dict[str, Any]:\n",
    "    if not config_path.exists():\n",
    "        raise FileNotFoundError(f\"Configuration file not found at {config_path}\")\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "def setup_logging(log_dir: Path, log_filename: str = 'prediction.log') -> logging.Logger:\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    log_path = log_dir / log_filename\n",
    "\n",
    "    logger = logging.getLogger('model_prediction')\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    # Clear existing handlers to prevent duplicate logs\n",
    "    if logger.hasHandlers():\n",
    "        logger.handlers.clear()\n",
    "\n",
    "    # Create handlers\n",
    "    f_handler = logging.FileHandler(log_path)\n",
    "    f_handler.setLevel(logging.INFO)\n",
    "    c_handler = logging.StreamHandler()\n",
    "    c_handler.setLevel(logging.INFO)\n",
    "\n",
    "    # Create formatters and add them to handlers\n",
    "    formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s')\n",
    "    f_handler.setFormatter(formatter)\n",
    "    c_handler.setFormatter(formatter)\n",
    "\n",
    "    # Add handlers to the logger\n",
    "    logger.addHandler(f_handler)\n",
    "    logger.addHandler(c_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "def main():\n",
    "    # ----------------------------\n",
    "    # Step 1: Load Configuration\n",
    "    # ----------------------------\n",
    "    config_path = Path('../../dataset/test/preprocessor_config/preprocessor_config.yaml')  # Adjust as needed\n",
    "    try:\n",
    "        config = load_config(config_path)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to load configuration: {e}\")\n",
    "        return  # Exit if config loading fails\n",
    "\n",
    "    # ----------------------------\n",
    "    # Step 2: Extract Paths from Configuration\n",
    "    # ----------------------------\n",
    "    paths = config.get('paths', {})\n",
    "    data_dir = Path(paths.get('base_data_dir', '../../dataset/test/data')).resolve()\n",
    "    raw_data_path = data_dir / paths.get('raw_data_file', 'final_ml_dataset.csv')  # Corrected key\n",
    "    processed_data_dir = data_dir / paths.get('processed_data_dir', 'preprocessor/processed')\n",
    "    transformers_dir = Path(paths.get('transformers_save_base_dir', '../preprocessor/transformers')).resolve()  # Corrected key\n",
    "    predictions_output_dir = Path(paths.get('predictions_output_dir', 'preprocessor/predictions')).resolve()\n",
    "    log_dir = Path(paths.get('log_dir', '../preprocessor/logs')).resolve()\n",
    "    model_save_dir = Path(paths.get('model_save_base_dir', '../preprocessor/models')).resolve()  # Corrected key\n",
    "    log_file = paths.get('log_file', 'prediction.log')  # Ensure this key exists in config\n",
    "\n",
    "    # ----------------------------\n",
    "    # Step 3: Setup Logging\n",
    "    # ----------------------------\n",
    "    logger = setup_logging(log_dir, log_file)\n",
    "    logger.info(\"✅ Starting prediction module.\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # Step 4: Extract Feature Assets\n",
    "    # ----------------------------\n",
    "    features_config = config.get('features', {})\n",
    "    column_assets = {\n",
    "        'y_variable': features_config.get('y_variable', []),\n",
    "        'ordinal_categoricals': features_config.get('ordinal_categoricals', []),\n",
    "        'nominal_categoricals': features_config.get('nominal_categoricals', []),\n",
    "        'numericals': features_config.get('numericals', [])\n",
    "    }\n",
    "\n",
    "    # ----------------------------\n",
    "    # Step 5: Load Tuning Results to Find Best Model\n",
    "    # ----------------------------\n",
    "    tuning_results_path = model_save_dir / \"tuning_results.json\"\n",
    "    if not tuning_results_path.exists():\n",
    "        logger.error(f\"❌ Tuning results not found at '{tuning_results_path}'. Cannot determine the best model.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with open(tuning_results_path, 'r') as f:\n",
    "            tuning_results = json.load(f)\n",
    "        best_model_info = tuning_results.get(\"Best Model\")\n",
    "        if not best_model_info:\n",
    "            logger.error(\"❌ Best model information not found in tuning results.\")\n",
    "            return\n",
    "        best_model_name = best_model_info.get(\"model_name\")\n",
    "        if not best_model_name:\n",
    "            logger.error(\"❌ Best model name not found in tuning results.\")\n",
    "            return\n",
    "        logger.info(f\"Best model identified: {best_model_name}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Failed to load tuning results: {e}\")\n",
    "        return\n",
    "\n",
    "    # ----------------------------\n",
    "    # Step 6: Preprocess the Data\n",
    "    # ----------------------------\n",
    "    # Load Prediction Dataset\n",
    "    if not raw_data_path.exists():\n",
    "        logger.error(f\"❌ Prediction input dataset not found at '{raw_data_path}'.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        df_predict = load_dataset(raw_data_path)\n",
    "        logger.info(f\"✅ Prediction input data loaded from '{raw_data_path}'.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Failed to load prediction input data: {e}\")\n",
    "        return\n",
    "\n",
    "    # Initialize DataPreprocessor\n",
    "    preprocessor = DataPreprocessor(\n",
    "        model_type=\"Tree Based Classifier\",  # Or dynamically set based on best_model_name if necessary\n",
    "        y_variable=column_assets.get('y_variable', []),\n",
    "        ordinal_categoricals=column_assets.get('ordinal_categoricals', []),\n",
    "        nominal_categoricals=column_assets.get('nominal_categoricals', []),\n",
    "        numericals=column_assets.get('numericals', []),\n",
    "        mode='predict',\n",
    "        options={},  # Adjust based on config or load from somewhere\n",
    "        debug=False,  # Can be parameterized\n",
    "        normalize_debug=False,  # As per hardcoded paths\n",
    "        normalize_graphs_output=False,  # As per hardcoded paths\n",
    "        graphs_output_dir=Path(paths.get('plots_output_dir', '../preprocessor/plots')).resolve(),\n",
    "        transformers_dir=transformers_dir\n",
    "    )\n",
    "\n",
    "    # Execute Preprocessing for Prediction\n",
    "    try:\n",
    "        X_preprocessed, recommendations, X_inversed = preprocessor.final_preprocessing(df_predict)\n",
    "        print(\"X_new_preprocessed type = \", type(X_preprocessed), \"X_new_inverse type = \", type(X_inversed))\n",
    "        logger.info(\"✅ Preprocessing completed successfully in predict mode.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Preprocessing failed in predict mode: {e}\")\n",
    "        return\n",
    "\n",
    "    # ----------------------------\n",
    "    # Step 7: Load the Best Model\n",
    "    # ----------------------------\n",
    "    try:\n",
    "        trained_model = load_model(best_model_name, model_save_dir)\n",
    "        logger.info(f\"✅ Trained model loaded from '{model_save_dir / best_model_name.replace(' ', '_') / 'trained_model.pkl'}'.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Failed to load the best model '{best_model_name}': {e}\")\n",
    "        return\n",
    "\n",
    "    # ----------------------------\n",
    "    # Step 8: Make Predictions\n",
    "    # ----------------------------\n",
    "    try:\n",
    "        predictions = trained_model.predict(X_preprocessed)\n",
    "        logger.info(\"✅ Predictions made successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Prediction failed: {e}\")\n",
    "        return\n",
    "\n",
    "    # ----------------------------\n",
    "    # Step 9: Attach Predictions to Inversed Data\n",
    "    # ----------------------------\n",
    "    if X_inversed is not None:\n",
    "        if len(predictions) == len(X_inversed):\n",
    "            X_inversed['predictions'] = predictions\n",
    "            logger.info(\"✅ Predictions attached to inversed data successfully.\")\n",
    "        else:\n",
    "            logger.error(\"❌ Predictions length does not match inversed data length.\")\n",
    "            return\n",
    "    else:\n",
    "        logger.error(\"❌ Inversed data is None. Cannot attach predictions.\")\n",
    "        return\n",
    "\n",
    "    # ----------------------------\n",
    "    # Step 10: Save Predictions\n",
    "    # ----------------------------\n",
    "    try:\n",
    "        predictions_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        predictions_filename = predictions_output_dir / f'predictions_{best_model_name.replace(\" \", \"_\")}.csv'\n",
    "        X_inversed.to_csv(predictions_filename, index=False)\n",
    "        logger.info(f\"✅ Predictions saved to '{predictions_filename}'.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Failed to save predictions: {e}\")\n",
    "        return\n",
    "\n",
    "    logger.info(f\"✅ All prediction tasks completed successfully for model '{best_model_name}'.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science_ml_preprocessor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
